[
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "Aranda-Díaz, Andrés, Eric Neubauer Vickers, Kathryn Murie, Brian Palmer, Nicholas Hathaway, Inna Gerlovina, Simone Boene, et al. 2025. “Sensitive and Modular Amplicon Sequencing of Plasmodium Falciparum Diversity and Resistance for Research and Public Health.” Sci. Rep. 15 (March): 10737.\n\n\nCrystal-Ornelas, Robert, Charuleka Varadharajan, Dylan O’Ryan, Kathleen Beilsmith, Benjamin Bond-Lamberty, Kristin Boye, Madison Burrus, et al. 2022. “Enabling FAIR Data in Earth and Environmental Science with Community-Centric (Meta)data Reporting Formats.” Sci Data 9 (1): 700.\n\n\nJacob, Christopher G, Nguyen Thuy-Nhien, Mayfong Mayxay, Richard J Maude, Huynh Hong Quang, Bouasy Hongvanthong, Viengxay Vanisaveth, et al. 2021. “Genetic Surveillance in the Greater Mekong Subregion and South Asia to Support Malaria Control and Elimination.” Elife 10 (August).\n\n\nKattenberg Johanna Helena, Fernandez-Miñope Carlos, van Dijk Norbert J., Llacsahuanga Allcca Lidia, Guetens Pieter, Valdivia Hugo O., Van geertruyden Jean-Pierre, et al. 2023. “Malaria Molecular Surveillance in the Peruvian Amazon with a Novel Highly Multiplexed Plasmodium Falciparum AmpliSeq Assay.” Microbiology Spectrum 0 (0): e00960–22.\n\n\nLaVerriere, Emily, Philipp Schwabl, Manuela Carrasquilla, Aimee R Taylor, Zachary M Johnson, Meg Shieh, Ruchit Panchal, et al. 2022. “Design and Implementation of Multiplexed Amplicon Sequencing Panels to Serve Genomic Epidemiology of Infectious Disease: A Malaria Case Study.” Mol. Ecol. Resour. 22 (6): 2285–2303.\n\n\nOldoni, Fabio, Kenneth K Kidd, and Daniele Podini. 2019. “Microhaplotypes in Forensic Genetics.” Forensic Sci. Int. Genet. 38 (January): 54–69.\n\n\nSadler, Jacob M, Alfred Simkin, Valery P K Tchuenkam, Isabela Gerdes Gyuricza, Abebe A Fola, Kevin Wamae, Ashenafi Assefa, et al. 2024. “Application of a New Highly Multiplexed Amplicon Sequencing Tool to Evaluate Plasmodium Falciparum Antimalarial Resistance and Relatedness in Individual and Pooled Samples from Dschang, Cameroon.” Front. Parasitol. 3: 1509261.\n\n\n“SRA Metadata and Submission Overview.” n.d. https://www.ncbi.nlm.nih.gov/sra/docs/submitmeta/.\n\n\nTessema, Sofonias K, Nicholas J Hathaway, Noam B Teyssier, Maxwell Murphy, Anna Chen, Ozkan Aydemir, Elias M Duarte, et al. 2022. “Sensitive, Highly Multiplexed Sequencing of Microhaplotypes from the Plasmodium Falciparum Heterozygome.” J. Infect. Dis. 225 (April): 1227–37.\n\n\nVangay Pajau, Burgin Josephine, Johnston Anjanette, Beck Kristen L., Berrios Daniel C., Blumberg Kai, Canon Shane, et al. 2021. “Microbiome Metadata Standards: Report of the National Microbiome Data Collaborative’s Workshop and Follow-On Activities.” mSystems 6 (1): e01194–20.\n\n\nWeisenhorn, Pamela, and Kathleen Beilsmith. 2022. “ESS-DIVE Reporting Format for Amplicon Abundance Table.” Environmental System Science Data Infrastructure for a Virtual Ecosystem; Environmental Systems Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE).\n\n\nYilmaz, Pelin, Renzo Kottmann, Dawn Field, Rob Knight, James R Cole, Linda Amaral-Zettler, Jack A Gilbert, et al. 2011. “Minimum Information about a Marker Gene Sequence (MIMARKS) and Minimum Information about Any (x) Sequence (MIxS) Specifications.” Nat. Biotechnol. 29 (5): 415–20."
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html",
    "title": "Getting basic info out of a PMO",
    "section": "",
    "text": "Code\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\npmo = PMOReader.read_in_pmo(\"../format/moz2018_PMO.json.gz\")"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-sample-counts-per-target",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-sample-counts-per-target",
    "title": "Getting basic info out of a PMO",
    "section": "Getting sample counts per target",
    "text": "Getting sample counts per target\n\n\nCode\n# get counts of the samples per target\ncounts_df = PMOExtractor.count_samples_per_target(pmo)\n\nprint(counts_df)\n\n\n   tar_amp_bioinformatics_info_id target_id sample_number\n0         Mozambique2018-SeekDeep        t1           119\n0         Mozambique2018-SeekDeep       t10           117\n0         Mozambique2018-SeekDeep      t100           124\n0         Mozambique2018-SeekDeep       t11           120\n0         Mozambique2018-SeekDeep       t12           119\n..                            ...       ...           ...\n0         Mozambique2018-SeekDeep       t96           119\n0         Mozambique2018-SeekDeep       t97           122\n0         Mozambique2018-SeekDeep       t98           122\n0         Mozambique2018-SeekDeep       t99           120\n0         Mozambique2018-SeekDeep       t76            32\n\n[100 rows x 3 columns]"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-target-counts-per-sample",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-target-counts-per-sample",
    "title": "Getting basic info out of a PMO",
    "section": "Getting target counts per sample",
    "text": "Getting target counts per sample\n\n\nCode\n# get counts of the samples per target\ntarget_counts_df = PMOExtractor.count_targets_per_sample(pmo)\nprint(target_counts_df)\n\n\n   tar_amp_bioinformatics_info_id experiment_sample_id target_number\n0         Mozambique2018-SeekDeep           8025874217            99\n0         Mozambique2018-SeekDeep           8025874231            99\n0         Mozambique2018-SeekDeep           8025874234            97\n0         Mozambique2018-SeekDeep           8025874237            99\n0         Mozambique2018-SeekDeep           8025874250            98\n..                            ...                  ...           ...\n0         Mozambique2018-SeekDeep           SS1-10K-C1            98\n0         Mozambique2018-SeekDeep           SS2-10K-C1            98\n0         Mozambique2018-SeekDeep           SS3-10K-C1            98\n0         Mozambique2018-SeekDeep           SS4-10K-C1            99\n0         Mozambique2018-SeekDeep           SS5-10K-C1            97\n\n[124 rows x 3 columns]"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "To get simple counts of number of targets with sample counts, samples with target counts, the counts of meta fields\nMost of these basic info extractor can be found underneath extract_basic_info_from_pmo\n\nCodepmotools-python\n\n\n\n\npmotools-python v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (PMO) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert Excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to a JSON file\n    terra_amp_output_to_json - Convert Terra output to JSON sequence table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract samples + haplotypes using selected meta\n    extract_pmo_with_select_specimen_names - Extract specific samples from the specimens table\n    extract_pmo_with_select_library_sample_names - Extract experiment sample names from experiment_info table\n    extract_pmo_with_select_targets - Extract specific targets\n    extract_pmo_with_read_filter - Extract with a read filter\n    extract_allele_table - Extract allele tables for tools like dcifer or moire\n    extract_insert_of_panels - Extract inserts of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract ref_seq of panel inserts from a PMO\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple PMOs of the same panel\n\nextract_basic_info_from_pmo\n    list_library_sample_names_per_specimen_name - List experiment_sample_ids per specimen_id\n    list_specimen_meta_fields - List specimen meta fields in the specimen_info section\n    list_bioinformatics_run_names - List all tar_amp_bioinformatics_info_ids in a PMO\n    count_specimen_meta - Count values of selected specimen meta fields\n    count_targets_per_library_sample - Count number of targets per sample\n    count_library_samples_per_target - Count number of samples per target\n\nvalidation\n    validate_pmo - Validate a PMO file against a JSON Schema\n\n\nGetting files for examples\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nThis will list all the meta fields within the specimen_infos section of a PMO file. Since not all meta fields are always present in all specimens, this will list the count of samples each field appears in and the number of total specimens\n\nCodepmotools-python list_specimen_meta_fields -h \n\nusage: pmotools-python list_specimen_meta_fields [-h] --file FILE\n                                                 [--output OUTPUT]\n                                                 [--delim DELIM] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_specimen_meta_fields script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_specimen_meta_fields.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_specimen_meta_fields():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_specimen_meta_fields():\n    args = parse_args_list_specimen_meta_fields()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    counts_df = PMOProcessor.count_specimen_per_meta_fields(pmo)\n\n    # output\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    list_specimen_meta_fields()\n\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz\n\nfield   present_in_specimens_count  total_specimen_count\ncollection_country  124 124\ncollection_date 124 124\ngeo_admin3  124 124\nhost_taxon_id   124 124\nlat_lon 124 124\nparasite_density_info   123 124\nproject_id  124 124\nspecimen_collect_device 124 124\nspecimen_name   124 124\nspecimen_store_loc  124 124\nspecimen_taxon_id   124 124\nstorage_plate_info  81  124\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz --output spec_fields_moz2018_PMO.tsv --overwrite\n\n\n\nThis will list all the meta values (and the combinations) for the meta fields within the specimen_infos section of a PMO file.\n\nCodepmotools-python count_specimen_meta -h \n\nusage: pmotools-python count_specimen_meta [-h] --file FILE [--output OUTPUT]\n                                           [--delim DELIM] [--overwrite]\n                                           --meta_fields META_FIELDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --meta_fields META_FIELDS\n                        the fields to count the subfields of, can supply\n                        multiple separated by commas, e.g. --meta_fields\n                        collection_country,collection_date\n\n\nThe python code for count_specimen_meta script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_specimen_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--meta_fields\",\n        type=str,\n        required=True,\n        help=\"the fields to count the subfields of, can supply multiple separated by commas, e.g. --meta_fields collection_country,collection_date\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_specimen_meta():\n    args = parse_args_count_specimen_meta()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # process the meta_fields argument\n    meta_fields_toks = args.meta_fields.split(\",\")\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count sub-fields\n    counts_df = PMOProcessor.count_specimen_by_field_value(pmo, meta_fields_toks)\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_specimen_meta()\n\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country\n\ncollection_country  specimens_count specimens_freq  total_specimen_count\nMozambique  81  0.6532258064516129  124\nNA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country --overwrite --output collection_country_count_moz2018_PMO.tsv.gz \n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country,geo_admin3\n\ncollection_country  geo_admin3  specimens_count specimens_freq  total_specimen_count\nMozambique  Inhassoro   27  0.21774193548387097 124\nMozambique  Mandlakazi  28  0.22580645161290322 124\nMozambique  Namaacha    26  0.20967741935483872 124\nNA  NA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz --meta_fields collection_country,collection_date | head\n\ncollection_country  collection_date specimens_count specimens_freq  total_specimen_count\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    8   0.0004116708691401225   19433\nBangladesh  2012-04-19  1   5.145885864251531e-05   19433\nBangladesh  2012-06-05  2   0.00010291771728503062  19433\nBangladesh  2012-06-13  1   5.145885864251531e-05   19433\nBangladesh  2012-06-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-23  1   5.145885864251531e-05   19433\nTraceback (most recent call last):\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/bin/pmotools-python\", line 8, in &lt;module&gt;\n    sys.exit(main())\n             ^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/cli.py\", line 382, in main\n    handler()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\", line 61, in count_specimen_meta\n    counts_df.to_csv(\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/core/generic.py\", line 3967, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/format.py\", line 1014, in to_csv\n    csv_formatter.save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 270, in save\n    self._save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 275, in _save\n    self._save_body()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 313, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 324, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"writers.pyx\", line 73, in pandas._libs.writers.write_csv_rows\nBrokenPipeError: [Errno 32] Broken pipe\nException ignored in: &lt;_io.TextIOWrapper name='&lt;stdout&gt;' mode='w' encoding='utf-8'&gt;\nBrokenPipeError: [Errno 32] Broken pipe\n\n\n\nSpecimens can have multiple library sample names, so it might be helpful to list out all the library_names per specimens\n\nCodepmotools-python list_library_sample_names_per_specimen_name -h \n\nusage: pmotools-python list_library_sample_names_per_specimen_name\n       [-h] --file FILE [--output OUTPUT] [--delim DELIM] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_library_sample_names_per_specimen_name script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_library_sample_names_per_specimen_name.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_library_sample_names_per_specimen_name():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_library_sample_names_per_specimen_name():\n    args = parse_args_list_library_sample_names_per_specimen_name()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    info_df = PMOProcessor.list_library_sample_names_per_specimen_name(pmo)\n\n    # output\n    info_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    list_library_sample_names_per_specimen_name()\n\n\n\n\nCodecd example \npmotools-python list_library_sample_names_per_specimen_name --file ../../format/moz2018_PMO.json.gz \n\nspecimen_name   library_sample_name library_sample_count\n8025874217  8025874217  1\n8025874237  8025874237  1\n8025874250  8025874250  1\n8025874300  8025874300  1\n8025874321  8025874321  1\n8025874349  8025874349  1\n8025874366  8025874366  1\n8025874377  8025874377  1\n8025874411  8025874411  1\n8025874421  8025874421  1\n8025874463  8025874463  1\n8025874482  8025874482  1\n8025874507  8025874507  1\n8025874578  8025874578  1\n8025874627  8025874627  1\n8025874637  8025874637  1\n8025874665  8025874665  1\n8025874669  8025874669  1\n8025874714  8025874714  1\n8025874729  8025874729  1\n8025874809  8025874809  1\n8025874865  8025874865  1\n8025874899  8025874899  1\n8025874940  8025874940  1\n8034209589  8034209589  1\n8034209790  8034209790  1\n8034209228  8034209228  1\n8025874253  8025874253  1\n8025874261  8025874261  1\n8025874382  8025874382  1\n8025874457  8025874457  1\n8025874502  8025874502  1\n8025874526  8025874526  1\n8025874537  8025874537  1\n8025874586  8025874586  1\n8025874589  8025874589  1\n8025874636  8025874636  1\n8025874829  8025874829  1\n8025874849  8025874849  1\n8025874875  8025874875  1\n8025874975  8025874975  1\n8025874988  8025874988  1\n8025875052  8025875052  1\n8025875059  8025875059  1\n8025875140  8025875140  1\n8025875144  8025875144  1\n8025875145  8025875145  1\n8025875146  8025875146  1\n8025875166  8025875166  1\n8034209115  8034209115  1\n8034209281  8034209281  1\n8034209465  8034209465  1\n8034209834  8034209834  1\n8025874494  8025874494  1\n8025874536  8025874536  1\n8025874266  8025874266  1\n8025874271  8025874271  1\n8025874316  8025874316  1\n8025874330  8025874330  1\n8025874340  8025874340  1\n8025874357  8025874357  1\n8025874376  8025874376  1\n8025874380  8025874380  1\n8025874387  8025874387  1\n8025874419  8025874419  1\n8025874435  8025874435  1\n8025874447  8025874447  1\n8025874672  8025874672  1\n8025874706  8025874706  1\n8025874738  8025874738  1\n8025874928  8025874928  1\n8025874933  8025874933  1\n8025874973  8025874973  1\n8025875029  8025875029  1\n8025875042  8025875042  1\n8025875121  8025875121  1\n8025875170  8025875170  1\n8034209773  8034209773  1\n8034209803  8034209803  1\n8034209818  8034209818  1\n8025874297  8025874297  1\n8025874231  8025874231  1\n8025874234  8025874234  1\n8025874286  8025874286  1\n8025874343  8025874343  1\n8025874348  8025874348  1\n8025874352  8025874352  1\n8025874396  8025874396  1\n8025874405  8025874405  1\n8025874437  8025874437  1\n8025874452  8025874452  1\n8025874454  8025874454  1\n8025874484  8025874484  1\n8025874491  8025874491  1\n8025874499  8025874499  1\n8025874568  8025874568  1\n8025874585  8025874585  1\n8025874591  8025874591  1\n8025874613  8025874613  1\n8025874662  8025874662  1\n8025874675  8025874675  1\n8025874676  8025874676  1\n8025874701  8025874701  1\n8025874705  8025874705  1\n8025874720  8025874720  1\n8025874872  8025874872  1\n8025874877  8025874877  1\n8025874878  8025874878  1\n8025874879  8025874879  1\n8025874886  8025874886  1\n8025874888  8025874888  1\n8025874903  8025874903  1\n8025874931  8025874931  1\n8025874948  8025874948  1\n8025874956  8025874956  1\n8025875065  8025875065  1\n8025875112  8025875112  1\n8025875165  8025875165  1\nSS1-10K-C1  SS1-10K-C1  1\nSS2-10K-C1  SS2-10K-C1  1\nSS3-10K-C1  SS3-10K-C1  1\nSS4-10K-C1  SS4-10K-C1  1\nSS5-10K-C1  SS5-10K-C1  1\n8025875168  8025875168  1\n\n\n\nCodecd example \npmotools-python list_library_sample_names_per_specimen_name --file ../../format/moz2018_PMO.json.gz --overwrite --output library_samples_per_specimen_moz2018_PMO.tsv.gz \n\n\n\nThis will simply list out all the analyses (all the bioinformatics_run_namess) stored within a PMO\n\nCodepmotools-python list_bioinformatics_run_names -h \n\nusage: pmotools-python list_bioinformatics_run_names [-h] --file FILE\n                                                     [--output OUTPUT]\n                                                     [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_bioinformatics_run_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_bioinformatics_run_names.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_bioinformatics_run_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_bioinformatics_run_names():\n    args = parse_args_list_bioinformatics_run_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract all bio run names\n    bio_run_names = PMOProcessor.get_bioinformatics_run_names(pmo)\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\n\".join(bio_run_names) + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    list_bioinformatics_run_names()\n\n\n\n\nCodecd example \npmotools-python list_bioinformatics_run_names --file ../../format/moz2018_PMO.json.gz  \n\nMozambique2018-SeekDeep\n\n\n\nCodecd example \npmotools-python list_bioinformatics_run_names --file ../../format/PathWeaverHeome1_PMO.json.gz \n\nPathWeaver-Heome1\n\n\nThis can be helpful after combining PMOs\n\nCodecd example \n\npmotools-python combine_pmos --pmo_files ../../format/moz2018_PMO.json.gz,../../format/PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\npmotools-python list_bioinformatics_run_names --file combined_Heome1_PMO.json.gz \n\n\n\n\nMozambique2018-SeekDeep\nPathWeaver-Heome1\n\n\n\nCount up the number targets each library_sample_id has. A read filter can be applied to see how targets would be kept if such a filter was applied\n\nCodepmotools-python count_targets_per_library_sample -h \n\nusage: pmotools-python count_targets_per_library_sample [-h] --file FILE\n                                                        [--output OUTPUT]\n                                                        [--delim DELIM]\n                                                        [--overwrite]\n                                                        [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_targets_per_library_sample script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_targets_per_library_sample.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_targets_per_library_sample():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=False,\n        help=\"the minimum read count (inclusive) to be counted as covered by sample\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_targets_per_library_sample():\n    args = parse_args_count_targets_per_library_sample()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOProcessor.count_targets_per_library_sample(\n        pmo, args.read_count_minimum\n    )\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_targets_per_library_sample()\n\n\n\n\nCodecd example \n\npmotools-python count_targets_per_library_sample --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   library_sample_name target_number\n0   8025875168  47\n0   8025874536  10\n0   8025874494  23\n0   8025874297  8\n0   SS4-10K-C1  99\n0   SS3-10K-C1  98\n0   SS2-10K-C1  98\n0   8034209818  99\n0   8034209790  98\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-python count_targets_per_library_sample --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   library_sample_name target_number\n0   8025875168  0\n0   8025874536  0\n0   8025874494  0\n0   8025874297  0\n0   SS4-10K-C1  97\n0   SS3-10K-C1  96\n0   SS2-10K-C1  97\n0   8034209818  97\n0   8034209790  97\n\n\n\nCount up the number of library_sample_ids each target has. A read filter can be applied to see how many samples a taget would have if a filter was applied\n\nCodepmotools-python count_library_samples_per_target -h \n\nusage: pmotools-python count_library_samples_per_target [-h] --file FILE\n                                                        [--output OUTPUT]\n                                                        [--delim DELIM]\n                                                        [--overwrite]\n                                                        [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_library_samples_per_target script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_library_samples_per_target.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_library_samples_per_target():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=False,\n        help=\"the minimum read count (inclusive) to be counted as covered by sample\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_library_samples_per_target():\n    args = parse_args_count_library_samples_per_target()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOProcessor.count_library_samples_per_target(\n        pmo, args.read_count_minimum\n    )\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_library_samples_per_target()\n\n\n\n\nCodecd example \n\npmotools-python count_library_samples_per_target --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   target_name sample_count\n0   t1  119\n0   t10 117\n0   t100    124\n0   t11 120\n0   t12 119\n0   t13 124\n0   t14 118\n0   t15 119\n0   t16 121\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-python count_library_samples_per_target --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   target_name sample_count\n0   t1  108\n0   t10 107\n0   t100    107\n0   t11 111\n0   t12 104\n0   t13 105\n0   t14 110\n0   t15 110\n0   t16 106"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_specimen_meta_fields",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_specimen_meta_fields",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will list all the meta fields within the specimen_infos section of a PMO file. Since not all meta fields are always present in all specimens, this will list the count of samples each field appears in and the number of total specimens\n\nCodepmotools-python list_specimen_meta_fields -h \n\nusage: pmotools-python list_specimen_meta_fields [-h] --file FILE\n                                                 [--output OUTPUT]\n                                                 [--delim DELIM] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_specimen_meta_fields script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_specimen_meta_fields.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_specimen_meta_fields():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_specimen_meta_fields():\n    args = parse_args_list_specimen_meta_fields()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    counts_df = PMOProcessor.count_specimen_per_meta_fields(pmo)\n\n    # output\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    list_specimen_meta_fields()\n\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz\n\nfield   present_in_specimens_count  total_specimen_count\ncollection_country  124 124\ncollection_date 124 124\ngeo_admin3  124 124\nhost_taxon_id   124 124\nlat_lon 124 124\nparasite_density_info   123 124\nproject_id  124 124\nspecimen_collect_device 124 124\nspecimen_name   124 124\nspecimen_store_loc  124 124\nspecimen_taxon_id   124 124\nstorage_plate_info  81  124\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz --output spec_fields_moz2018_PMO.tsv --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_specimen_meta",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_specimen_meta",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will list all the meta values (and the combinations) for the meta fields within the specimen_infos section of a PMO file.\n\nCodepmotools-python count_specimen_meta -h \n\nusage: pmotools-python count_specimen_meta [-h] --file FILE [--output OUTPUT]\n                                           [--delim DELIM] [--overwrite]\n                                           --meta_fields META_FIELDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --meta_fields META_FIELDS\n                        the fields to count the subfields of, can supply\n                        multiple separated by commas, e.g. --meta_fields\n                        collection_country,collection_date\n\n\nThe python code for count_specimen_meta script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_specimen_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--meta_fields\",\n        type=str,\n        required=True,\n        help=\"the fields to count the subfields of, can supply multiple separated by commas, e.g. --meta_fields collection_country,collection_date\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_specimen_meta():\n    args = parse_args_count_specimen_meta()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # process the meta_fields argument\n    meta_fields_toks = args.meta_fields.split(\",\")\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count sub-fields\n    counts_df = PMOProcessor.count_specimen_by_field_value(pmo, meta_fields_toks)\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_specimen_meta()\n\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country\n\ncollection_country  specimens_count specimens_freq  total_specimen_count\nMozambique  81  0.6532258064516129  124\nNA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country --overwrite --output collection_country_count_moz2018_PMO.tsv.gz \n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country,geo_admin3\n\ncollection_country  geo_admin3  specimens_count specimens_freq  total_specimen_count\nMozambique  Inhassoro   27  0.21774193548387097 124\nMozambique  Mandlakazi  28  0.22580645161290322 124\nMozambique  Namaacha    26  0.20967741935483872 124\nNA  NA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz --meta_fields collection_country,collection_date | head\n\ncollection_country  collection_date specimens_count specimens_freq  total_specimen_count\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    8   0.0004116708691401225   19433\nBangladesh  2012-04-19  1   5.145885864251531e-05   19433\nBangladesh  2012-06-05  2   0.00010291771728503062  19433\nBangladesh  2012-06-13  1   5.145885864251531e-05   19433\nBangladesh  2012-06-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-23  1   5.145885864251531e-05   19433\nTraceback (most recent call last):\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/bin/pmotools-python\", line 8, in &lt;module&gt;\n    sys.exit(main())\n             ^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/cli.py\", line 382, in main\n    handler()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\", line 61, in count_specimen_meta\n    counts_df.to_csv(\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/core/generic.py\", line 3967, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/format.py\", line 1014, in to_csv\n    csv_formatter.save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 270, in save\n    self._save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 275, in _save\n    self._save_body()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 313, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 324, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"writers.pyx\", line 73, in pandas._libs.writers.write_csv_rows\nBrokenPipeError: [Errno 32] Broken pipe\nException ignored in: &lt;_io.TextIOWrapper name='&lt;stdout&gt;' mode='w' encoding='utf-8'&gt;\nBrokenPipeError: [Errno 32] Broken pipe"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_library_sample_names_per_specimen_name",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_library_sample_names_per_specimen_name",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "Specimens can have multiple library sample names, so it might be helpful to list out all the library_names per specimens\n\nCodepmotools-python list_library_sample_names_per_specimen_name -h \n\nusage: pmotools-python list_library_sample_names_per_specimen_name\n       [-h] --file FILE [--output OUTPUT] [--delim DELIM] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_library_sample_names_per_specimen_name script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_library_sample_names_per_specimen_name.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_library_sample_names_per_specimen_name():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_library_sample_names_per_specimen_name():\n    args = parse_args_list_library_sample_names_per_specimen_name()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    info_df = PMOProcessor.list_library_sample_names_per_specimen_name(pmo)\n\n    # output\n    info_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    list_library_sample_names_per_specimen_name()\n\n\n\n\nCodecd example \npmotools-python list_library_sample_names_per_specimen_name --file ../../format/moz2018_PMO.json.gz \n\nspecimen_name   library_sample_name library_sample_count\n8025874217  8025874217  1\n8025874237  8025874237  1\n8025874250  8025874250  1\n8025874300  8025874300  1\n8025874321  8025874321  1\n8025874349  8025874349  1\n8025874366  8025874366  1\n8025874377  8025874377  1\n8025874411  8025874411  1\n8025874421  8025874421  1\n8025874463  8025874463  1\n8025874482  8025874482  1\n8025874507  8025874507  1\n8025874578  8025874578  1\n8025874627  8025874627  1\n8025874637  8025874637  1\n8025874665  8025874665  1\n8025874669  8025874669  1\n8025874714  8025874714  1\n8025874729  8025874729  1\n8025874809  8025874809  1\n8025874865  8025874865  1\n8025874899  8025874899  1\n8025874940  8025874940  1\n8034209589  8034209589  1\n8034209790  8034209790  1\n8034209228  8034209228  1\n8025874253  8025874253  1\n8025874261  8025874261  1\n8025874382  8025874382  1\n8025874457  8025874457  1\n8025874502  8025874502  1\n8025874526  8025874526  1\n8025874537  8025874537  1\n8025874586  8025874586  1\n8025874589  8025874589  1\n8025874636  8025874636  1\n8025874829  8025874829  1\n8025874849  8025874849  1\n8025874875  8025874875  1\n8025874975  8025874975  1\n8025874988  8025874988  1\n8025875052  8025875052  1\n8025875059  8025875059  1\n8025875140  8025875140  1\n8025875144  8025875144  1\n8025875145  8025875145  1\n8025875146  8025875146  1\n8025875166  8025875166  1\n8034209115  8034209115  1\n8034209281  8034209281  1\n8034209465  8034209465  1\n8034209834  8034209834  1\n8025874494  8025874494  1\n8025874536  8025874536  1\n8025874266  8025874266  1\n8025874271  8025874271  1\n8025874316  8025874316  1\n8025874330  8025874330  1\n8025874340  8025874340  1\n8025874357  8025874357  1\n8025874376  8025874376  1\n8025874380  8025874380  1\n8025874387  8025874387  1\n8025874419  8025874419  1\n8025874435  8025874435  1\n8025874447  8025874447  1\n8025874672  8025874672  1\n8025874706  8025874706  1\n8025874738  8025874738  1\n8025874928  8025874928  1\n8025874933  8025874933  1\n8025874973  8025874973  1\n8025875029  8025875029  1\n8025875042  8025875042  1\n8025875121  8025875121  1\n8025875170  8025875170  1\n8034209773  8034209773  1\n8034209803  8034209803  1\n8034209818  8034209818  1\n8025874297  8025874297  1\n8025874231  8025874231  1\n8025874234  8025874234  1\n8025874286  8025874286  1\n8025874343  8025874343  1\n8025874348  8025874348  1\n8025874352  8025874352  1\n8025874396  8025874396  1\n8025874405  8025874405  1\n8025874437  8025874437  1\n8025874452  8025874452  1\n8025874454  8025874454  1\n8025874484  8025874484  1\n8025874491  8025874491  1\n8025874499  8025874499  1\n8025874568  8025874568  1\n8025874585  8025874585  1\n8025874591  8025874591  1\n8025874613  8025874613  1\n8025874662  8025874662  1\n8025874675  8025874675  1\n8025874676  8025874676  1\n8025874701  8025874701  1\n8025874705  8025874705  1\n8025874720  8025874720  1\n8025874872  8025874872  1\n8025874877  8025874877  1\n8025874878  8025874878  1\n8025874879  8025874879  1\n8025874886  8025874886  1\n8025874888  8025874888  1\n8025874903  8025874903  1\n8025874931  8025874931  1\n8025874948  8025874948  1\n8025874956  8025874956  1\n8025875065  8025875065  1\n8025875112  8025875112  1\n8025875165  8025875165  1\nSS1-10K-C1  SS1-10K-C1  1\nSS2-10K-C1  SS2-10K-C1  1\nSS3-10K-C1  SS3-10K-C1  1\nSS4-10K-C1  SS4-10K-C1  1\nSS5-10K-C1  SS5-10K-C1  1\n8025875168  8025875168  1\n\n\n\nCodecd example \npmotools-python list_library_sample_names_per_specimen_name --file ../../format/moz2018_PMO.json.gz --overwrite --output library_samples_per_specimen_moz2018_PMO.tsv.gz"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_bioinformatics_run_names",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_bioinformatics_run_names",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will simply list out all the analyses (all the bioinformatics_run_namess) stored within a PMO\n\nCodepmotools-python list_bioinformatics_run_names -h \n\nusage: pmotools-python list_bioinformatics_run_names [-h] --file FILE\n                                                     [--output OUTPUT]\n                                                     [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_bioinformatics_run_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/list_bioinformatics_run_names.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_bioinformatics_run_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef list_bioinformatics_run_names():\n    args = parse_args_list_bioinformatics_run_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract all bio run names\n    bio_run_names = PMOProcessor.get_bioinformatics_run_names(pmo)\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\n\".join(bio_run_names) + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    list_bioinformatics_run_names()\n\n\n\n\nCodecd example \npmotools-python list_bioinformatics_run_names --file ../../format/moz2018_PMO.json.gz  \n\nMozambique2018-SeekDeep\n\n\n\nCodecd example \npmotools-python list_bioinformatics_run_names --file ../../format/PathWeaverHeome1_PMO.json.gz \n\nPathWeaver-Heome1\n\n\nThis can be helpful after combining PMOs\n\nCodecd example \n\npmotools-python combine_pmos --pmo_files ../../format/moz2018_PMO.json.gz,../../format/PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\npmotools-python list_bioinformatics_run_names --file combined_Heome1_PMO.json.gz \n\n\n\n\nMozambique2018-SeekDeep\nPathWeaver-Heome1"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_targets_per_library_sample",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_targets_per_library_sample",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "Count up the number targets each library_sample_id has. A read filter can be applied to see how targets would be kept if such a filter was applied\n\nCodepmotools-python count_targets_per_library_sample -h \n\nusage: pmotools-python count_targets_per_library_sample [-h] --file FILE\n                                                        [--output OUTPUT]\n                                                        [--delim DELIM]\n                                                        [--overwrite]\n                                                        [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_targets_per_library_sample script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_targets_per_library_sample.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_targets_per_library_sample():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=False,\n        help=\"the minimum read count (inclusive) to be counted as covered by sample\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_targets_per_library_sample():\n    args = parse_args_count_targets_per_library_sample()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOProcessor.count_targets_per_library_sample(\n        pmo, args.read_count_minimum\n    )\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_targets_per_library_sample()\n\n\n\n\nCodecd example \n\npmotools-python count_targets_per_library_sample --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   library_sample_name target_number\n0   8025875168  47\n0   8025874536  10\n0   8025874494  23\n0   8025874297  8\n0   SS4-10K-C1  99\n0   SS3-10K-C1  98\n0   SS2-10K-C1  98\n0   8034209818  99\n0   8034209790  98\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-python count_targets_per_library_sample --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   library_sample_name target_number\n0   8025875168  0\n0   8025874536  0\n0   8025874494  0\n0   8025874297  0\n0   SS4-10K-C1  97\n0   SS3-10K-C1  96\n0   SS2-10K-C1  97\n0   8034209818  97\n0   8034209790  97"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_library_samples_per_target",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_library_samples_per_target",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "Count up the number of library_sample_ids each target has. A read filter can be applied to see how many samples a taget would have if a filter was applied\n\nCodepmotools-python count_library_samples_per_target -h \n\nusage: pmotools-python count_library_samples_per_target [-h] --file FILE\n                                                        [--output OUTPUT]\n                                                        [--delim DELIM]\n                                                        [--overwrite]\n                                                        [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_library_samples_per_target script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_library_samples_per_target.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_library_samples_per_target():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter\",\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=False,\n        help=\"the minimum read count (inclusive) to be counted as covered by sample\",\n    )\n\n    return parser.parse_args()\n\n\ndef count_library_samples_per_target():\n    args = parse_args_count_library_samples_per_target()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=args.output.endswith(\".gz\")\n    )\n    args.output = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOProcessor.count_library_samples_per_target(\n        pmo, args.read_count_minimum\n    )\n\n    # write out\n    counts_df.to_csv(\n        sys.stdout if \"STDOUT\" == args.output else args.output,\n        sep=output_delim,\n        index=False,\n    )\n\n\nif __name__ == \"__main__\":\n    count_library_samples_per_target()\n\n\n\n\nCodecd example \n\npmotools-python count_library_samples_per_target --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   target_name sample_count\n0   t1  119\n0   t10 117\n0   t100    124\n0   t11 120\n0   t12 119\n0   t13 124\n0   t14 118\n0   t15 119\n0   t16 121\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-python count_library_samples_per_target --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\nbioinformatics_run_id   target_name sample_count\n0   t1  108\n0   t10 107\n0   t100    107\n0   t11 111\n0   t12 104\n0   t13 105\n0   t14 110\n0   t15 110\n0   t16 106"
  },
  {
    "objectID": "pmotools-python-usages/handling_multiple_pmos.html",
    "href": "pmotools-python-usages/handling_multiple_pmos.html",
    "title": "Handling multiple PMOs pmotools-python",
    "section": "",
    "text": "pmotools-python combine_pmos\nCan download multiple PMOs here\nhttps://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nhttps://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\nCodepmotools-python combine_pmos --help\n\nusage: pmotools-python combine_pmos [-h] --pmo_files PMO_FILES --output OUTPUT\n                                    [--overwrite]\n\noptions:\n  -h, --help            show this help message and exit\n  --pmo_files PMO_FILES\n                        a list of PMO files to combine into 1 PMO file, must\n                        be from same amplicon panel\n  --output OUTPUT       Output new combined PMO file\n  --overwrite           If output file exists, overwrite it\n\n\nThe list of PMO files can be given comma separated to their relative paths from where you run the script or in a file where each line is a different file to combine\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\npmotools-python combine_pmos --pmo_files moz2018_PMO.json.gz,PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\n\nThe python code for combine_pmos script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/pmo_utils/combine_pmos.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\n\n\ndef parse_args_combine_pmos():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--pmo_files\",\n        type=str,\n        required=True,\n        help=\"a list of PMO files to combine into 1 PMO file, must be from same amplicon panel\",\n    )\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output new combined PMO file\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n\n    return parser.parse_args()\n\n\ndef combine_pmos():\n    args = parse_args_combine_pmos()\n\n    # set up output\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.output.endswith(\".gz\")\n    )\n    Utils.outputfile_check(args.output, args.overwrite)\n\n    # check if at least 2 PMO files supplied\n    pmo_files_list = Utils.parse_delimited_input_or_file(args.pmo_files, \",\")\n    if len(pmo_files_list) &lt; 2:\n        raise Exception(\n            \"Only supplied \"\n            + str(len(pmo_files_list))\n            + \" but multiple PMO files were expected\"\n        )\n\n    # read in the PMOs\n    pmos = PMOReader.read_in_pmos(pmo_files_list)\n\n    # combine PMOs\n    pmo_out = PMOReader.combine_multiple_pmos(pmos)\n\n    # write\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    combine_pmos()"
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html",
    "href": "pmotools-python-usages/extracting_allele_tables.html",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "To extract allele table information from a PMO the command line interactive script with pmotools-python extract_allele_table can be used\n\npmotools-python extract_allele_table\n\nRequired arguments\n\n\n--file - the PMO file to extract from\n\n--output - the output stub of the files to be created\n\n\nOptional arguments\n\nBy default only 3 fields are extracted by this extractor, 1) sampleID (library_sample_sample_name), 2) locus (target_name), and 3) allele (microhaplotype_id) with those default column names. This can be controlled by --default_base_col_names and if you supply 3 comma separated values you can change the default header.\nYou can also add to the table any values from the other portions of the PMO file by using the following arguments\n\nadding fields arguments\n\n\n--specimen_info_meta_fields - Meta Fields if any to include from the specimen table\n\n--library_sample_info_meta_fields - Meta Fields if any to include from the library_sample table\n\n--microhap_fields - additional optional fields from the detected microhaplotype object to include\n\n--representative_haps_fields - additional optional fields from the detected representative object to include\n\n\n\nOther optional arguments have to do with the ouput file over writing and delimiter being used, use -h to see all arguments\n\nCodepmotools-python extract_allele_table -h\n\nusage: pmotools-python extract_allele_table [-h] --file FILE\n                                            [--jsonschema JSONSCHEMA]\n                                            [--delim DELIM] --output OUTPUT\n                                            [--overwrite]\n                                            [--allele_freqs_output ALLELE_FREQS_OUTPUT]\n                                            [--specimen_info_meta_fields SPECIMEN_INFO_META_FIELDS]\n                                            [--library_sample_info_meta_fields LIBRARY_SAMPLE_INFO_META_FIELDS]\n                                            [--microhap_fields MICROHAP_FIELDS]\n                                            [--representative_haps_fields REPRESENTATIVE_HAPS_FIELDS]\n                                            [--default_base_col_names DEFAULT_BASE_COL_NAMES]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --jsonschema JSONSCHEMA\n                        the jsonschema to check the PMO against\n  --delim DELIM         the delimiter of the input text file, examples\n                        tab,comma\n  --output OUTPUT       Output allele table file name path\n  --overwrite           If output file exists, overwrite it\n  --allele_freqs_output ALLELE_FREQS_OUTPUT\n                        if also writing out allele frequencies, write to this\n                        file\n  --specimen_info_meta_fields SPECIMEN_INFO_META_FIELDS\n                        Meta Fields if any to include from the specimen table\n  --library_sample_info_meta_fields LIBRARY_SAMPLE_INFO_META_FIELDS\n                        Meta Fields if any to include from the library sample\n                        table\n  --microhap_fields MICROHAP_FIELDS\n                        additional optional fields from the detected\n                        microhaplotype object to include\n  --representative_haps_fields REPRESENTATIVE_HAPS_FIELDS\n                        additional optional fields from the detected\n                        representative object to include\n  --default_base_col_names DEFAULT_BASE_COL_NAMES\n                        default base column names, must be length 3\n\n\nThe python code for extract_allele_table script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_allele_table.py\n\n#!/usr/bin/env python3\n\nimport argparse\nimport json\nimport os\n\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\nfrom pmotools.pmo_engine.pmo_checker import PMOChecker\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools import __version__ as __pmotools_version__\n\n\ndef parse_args_extract_for_allele_table():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--jsonschema\",\n        default=os.path.join(\n            os.path.dirname(\n                os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n            ),\n            \"schemas/\",\n            f\"portable_microhaplotype_object_v{__pmotools_version__}.schema.json\",\n        ),\n        type=str,\n        required=False,\n        help=\"the jsonschema to check the PMO against\",\n    )\n\n    parser.add_argument(\n        \"--delim\",\n        default=\"tab\",\n        type=str,\n        required=False,\n        help=\"the delimiter of the input text file, examples tab,comma\",\n    )\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output allele table file name path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--allele_freqs_output\",\n        type=str,\n        help=\"if also writing out allele frequencies, write to this file\",\n    )\n\n    parser.add_argument(\n        \"--specimen_info_meta_fields\",\n        type=str,\n        required=False,\n        help=\"Meta Fields if any to include from the specimen table\",\n    )\n    parser.add_argument(\n        \"--library_sample_info_meta_fields\",\n        type=str,\n        required=False,\n        help=\"Meta Fields if any to include from the library sample table\",\n    )\n    parser.add_argument(\n        \"--microhap_fields\",\n        type=str,\n        required=False,\n        help=\"additional optional fields from the detected microhaplotype object to include\",\n    )\n    parser.add_argument(\n        \"--representative_haps_fields\",\n        type=str,\n        required=False,\n        help=\"additional optional fields from the detected representative object to include\",\n    )\n    parser.add_argument(\n        \"--default_base_col_names\",\n        type=str,\n        required=False,\n        default=\"library_sample_name,target_name,mhap_id\",\n        help=\"default base column names, must be length 3\",\n    )\n\n    return parser.parse_args()\n\n\ndef extract_for_allele_table():\n    args = parse_args_extract_for_allele_table()\n    compressed_output = (\n        \".\" not in args.output and args.file.endswith(\".gz\")\n    ) or args.output.endswith(\".gz\")\n\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(\n        args.delim, gzip=compressed_output\n    )\n\n    allele_per_sample_table_out_fnp = (\n        args.output\n        if \"STDOUT\" == args.output\n        else Utils.appendStrAsNeeded(args.output, output_extension)\n    )\n    Utils.inputOutputFileCheck(\n        args.file, allele_per_sample_table_out_fnp, args.overwrite\n    )\n\n    allele_freq_output = \"\"\n    if args.allele_freqs_output is not None:\n        allele_freq_output = Utils.appendStrAsNeeded(\n            args.allele_freqs_output, output_extension\n        )\n        Utils.inputOutputFileCheck(args.file, allele_freq_output, args.overwrite)\n\n    pmodata = PMOReader.read_in_pmo(args.file)\n    with open(args.jsonschema, \"r\") as f:\n        schema_dict = json.load(f)\n        checker = PMOChecker(schema_dict)\n        # make sure PMO is valid\n        checker.validate_pmo_json(pmodata)\n\n    if args.specimen_info_meta_fields is not None:\n        args.specimen_info_meta_fields = Utils.parse_delimited_input_or_file(\n            args.specimen_info_meta_fields, \",\"\n        )\n    if args.microhap_fields is not None:\n        args.microhap_fields = Utils.parse_delimited_input_or_file(\n            args.microhap_fields, \",\"\n        )\n    if args.library_sample_info_meta_fields is not None:\n        args.library_sample_info_meta_fields = Utils.parse_delimited_input_or_file(\n            args.library_sample_info_meta_fields, \",\"\n        )\n    if args.representative_haps_fields is not None:\n        args.representative_haps_fields = Utils.parse_delimited_input_or_file(\n            args.representative_haps_fields, \",\"\n        )\n\n    allele_table = PMOProcessor.extract_alleles_per_sample_table(\n        pmodata,\n        additional_specimen_info_fields=args.specimen_info_meta_fields,\n        additional_library_sample_info_fields=args.library_sample_info_meta_fields,\n        additional_microhap_fields=args.microhap_fields,\n        additional_representative_info_fields=args.representative_haps_fields,\n        default_base_col_names=args.default_base_col_names.split(\",\"),\n    )\n    with Utils.smart_open_write(allele_per_sample_table_out_fnp) as f:\n        allele_table.to_csv(f, sep=output_delim, index=False)\n\n    if args.allele_freqs_output is not None:\n        allele_freqs = PMOProcessor.extract_allele_counts_freq_from_pmo(pmodata)\n        with Utils.smart_open_write(allele_freq_output) as f:\n            allele_freqs.to_csv(f, sep=output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    extract_for_allele_table()\n\n\n\nCan download example PMOs here\n\nCodewget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite\n\n\n\nCodecd example \n\n# changing default column names  \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --default_base_col_names sample,target,hapid\n\n\nChanging the output file delimiter\n\nCodecd example \n\npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --delim ,\n\n\nAdding on additional columns from the specimen_infos section\n\nCodecd example \n\n# adding other PMO fields \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output STDOUT --specimen_info_meta_fields collection_country,collection_date | head  \n\n\n\n\nbioinformatics_run_name library_sample_name target_name mhap_id collection_country  collection_date\nMozambique2018-SeekDeep 8025875168  t99 3   NA  NA\nMozambique2018-SeekDeep 8025875168  t99 0   NA  NA\nMozambique2018-SeekDeep 8025875168  t97 0   NA  NA\nMozambique2018-SeekDeep 8025875168  t97 3   NA  NA\nMozambique2018-SeekDeep 8025875168  t94 1   NA  NA\nMozambique2018-SeekDeep 8025875168  t94 0   NA  NA\nMozambique2018-SeekDeep 8025875168  t90 2   NA  NA\nMozambique2018-SeekDeep 8025875168  t90 0   NA  NA\nMozambique2018-SeekDeep 8025875168  t85 0   NA  NA\n\n\nCan continue to add on more columns from other sections\n\nCodecd example \n\n# adding other PMO fields including seq field \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output STDOUT --specimen_info_meta_fields collection_country,collection_date --representative_haps_fields seq | head \n\n\n\n\nbioinformatics_run_name library_sample_name target_name mhap_id collection_country  collection_date seq\nMozambique2018-SeekDeep 8025875168  t99 3   NA  NA  ATGGAAAAATGGAATATGAAGTATTAAGTGATGATAAAATAGTGTATGAAAATATACAACATGATTTATTAAAAACAATAGAAGATGGTGAAGAAATGTTAAAAGGAACTGAAAGGAAGGATAATATAGATATACTGAGGACTCCTGGAAGGGGAGAATATAATATGTGGTCTACTTCTGGACTAGGGTTCTATGAAT\nMozambique2018-SeekDeep 8025875168  t99 0   NA  NA  ATGGAAAAATGGAATATGAAGTATTAAGTGATGATAAAATAGTGTATGAAAATATACAACATGATTTATTAAAAACAATAGAAGATGATGACGAAATGTTAAAAGGAACTGAAAGGAAGGATAATATAGATATACTGAGGACTCCTGGAAGGGGAGAATATAATATGTGGTCTACTTCTGGACTAGGGTTCTATGAAT\nMozambique2018-SeekDeep 8025875168  t97 0   NA  NA  TAAACACCAGTACCATTTTTTTCTGATAAATTAATATTTTTTTGTATAACATCATATTTATCCCTTTTCGTGGTAAGTGCAGTATCCTGTTTTATTATTATATTATCGAATTCATCATGGTGTATATTTCTTTCT\nMozambique2018-SeekDeep 8025875168  t97 3   NA  NA  TAATCACCAGTACCATTTTTTTCTGATAAATTAATATTTTTTTGTATAACATCATATTTATCCCTTTTCGTGGTAAGTGCAGTATCCTGTTTTATTATTATATTATCGAATTCATCATGGTGTATATTTCTTTCA\nMozambique2018-SeekDeep 8025875168  t94 1   NA  NA  TATTAAAACTTTTTTTTCTTTCTGTAAAGTTTGTACATTATGTTTTGATGAGTTTTTATTATCTTCATAAAACTTTATATATTTATAAAAATTATTTTGTATAAAATCATTTAATAAAGGTAACATAATTTTTTTAGCTTGATTCAATTCACTACATGAATGTATAT\nMozambique2018-SeekDeep 8025875168  t94 0   NA  NA  TATTAAAACTTTTTTTTCTTTCTGTAAAGTTTGTACATTATGTTTTGATGAGTTTTGATTATCTTCATAAAACTTTATATATTTATAAAAATTATTTTGTATAAAATCATTTAATAAAGGTAACATAATTTTTTTAGCTTGATTCAATTCACTACATGAATGTATAT\nMozambique2018-SeekDeep 8025875168  t90 2   NA  NA  TTACAATGTTCTTCGCATTCGAAATTTTTTTCAGGATTACTTGAAAAGCCTTGTGGACAATTACAATATTCATATCCATGAGCATTCTTACAAACACCTTTTCCACAATTTAAAAAACATTTTTCTTCATTTAA\nMozambique2018-SeekDeep 8025875168  t90 0   NA  NA  TTACAATGTTCTTCGCATTCGAAATTTTTTTCAGGATTACTTGAAAAGCCTTCTGGACAATTACAATATTCATATCCATGAACATTCTTACAAACACCTTTTCCACAATTTAAAAAACATTTTTCTTCATTTAA\nMozambique2018-SeekDeep 8025875168  t85 0   NA  NA  AACATTTTTTTAACATCTTTACCTTTTTGACTTGGTTCTTCATCATAATTCTGTTGTTCTGCAGAATCAGCATTTACTTCAGTTTCTTCTTTATTTTGAAAAGTGTTTGATTCTACATGAGAATTGGAAGATGAACGTCTATGTTTTACTTCTGTATAACTAGTACGTTCTCCAGTATGATGAGCCTTAAGGTTTACATCTTCAGTTTCTT\n\n\n\nMOIRE is a program that can be used to estimate COI and other population estimates from a population. See it’s github for full usage.\n\nCodemkdir -p example\ncd example \n\n# default table is all moire needs \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite\n\n\n\nCodedf &lt;- read.csv(\"example/extraction_allele_table.tsv\", sep = \"\\t\")\n\ndata &lt;- load_long_form_data(df)\n\n# With data in appropriate format, run MCMC as follows\nmcmc_results &lt;- moire::run_mcmc(data, is_missing = data$is_missing)\n\n\n\ndcifer is a program that can estimate IBD even from mixed infections. See it’s github for full usage\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --delim ,\n\n# dcifer can calculate allele frequencies if not provided or you can have extract_allele_table write them as well \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --allele_freqs_output allele_freqs_extraction --delim ,\n\n\n\nCodedsmp &lt;- readDat(\"example/extraction_allele_table.csv\", svar = \"sampleID\", lvar = \"locus\", avar = \"allele\")\n\nlrank &lt;- 2\ncoi   &lt;- getCOI(dsmp, lrank = lrank)\n\nafreq &lt;- calcAfreq(dsmp, coi, tol = 1e-5) \n\ndres0 &lt;- ibdDat(dsmp, coi, afreq, pval = TRUE, confint = TRUE, rnull = 0, \n                alpha = 0.05, nr = 1e3)"
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-moire",
    "href": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-moire",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "MOIRE is a program that can be used to estimate COI and other population estimates from a population. See it’s github for full usage.\n\nCodemkdir -p example\ncd example \n\n# default table is all moire needs \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite\n\n\n\nCodedf &lt;- read.csv(\"example/extraction_allele_table.tsv\", sep = \"\\t\")\n\ndata &lt;- load_long_form_data(df)\n\n# With data in appropriate format, run MCMC as follows\nmcmc_results &lt;- moire::run_mcmc(data, is_missing = data$is_missing)"
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-dcifer",
    "href": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-dcifer",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "dcifer is a program that can estimate IBD even from mixed infections. See it’s github for full usage\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --delim ,\n\n# dcifer can calculate allele frequencies if not provided or you can have extract_allele_table write them as well \npmotools-python extract_allele_table --file ../../format/moz2018_PMO.json.gz --output extraction --overwrite --allele_freqs_output allele_freqs_extraction --delim ,\n\n\n\nCodedsmp &lt;- readDat(\"example/extraction_allele_table.csv\", svar = \"sampleID\", lvar = \"locus\", avar = \"allele\")\n\nlrank &lt;- 2\ncoi   &lt;- getCOI(dsmp, lrank = lrank)\n\nafreq &lt;- calcAfreq(dsmp, coi, tol = 1e-5) \n\ndres0 &lt;- ibdDat(dsmp, coi, afreq, pval = TRUE, confint = TRUE, rnull = 0, \n                alpha = 0.05, nr = 1e3)"
  },
  {
    "objectID": "Tools_Installation/pmotools-python_installation.html",
    "href": "Tools_Installation/pmotools-python_installation.html",
    "title": "pmotools-python installation",
    "section": "",
    "text": "pmotools-python is a tool base for interacting with the PMO format file in python. It provides both code to include in your python package as well as a command line interface to run some basic scripts on PMO files.\n\npmotools-python code can be found on github https://github.com/PlasmoGenEpi/pmotools-python/tree/develop and is available via pypi\n\nCodepip install pmotools \n\n\n\nTo install the developmental version, you can download the code from github\n\nDownloading repo\n\nCodegit clone git@github.com:PlasmoGenEpi/pmotools-python.git\n\n\nCurrently (as 2025-09) majority of code is currently still in develop branch\n\nCodecd pmotools-python\ngit checkout develop\n\n\n\nTo set up a conda environment that has all the python libraries that would be needed by pmotools-python\n\nCodeconda env create -f envs/pmotools-env.yml \n\nconda active pmotools\n\n\n\nFrom within repo can install with pip in a virtual environment\n\nCodepip install -e . \n\n\n\nTo enable bash auto-completion for pmotools-python, add the following to your ~/.bash_completion and make sure it’s being loaded as part of your .bashrc and/or ~/.bash_profile (on MacOS) or ~/.profile (on ubuntu)\n\nCode_pmotools_python_complete()\n{\n    local cur prev\n    COMPREPLY=()\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"\n\n    # 1) Completing the command name (1st arg): list all commands\n    if [[ ${COMP_CWORD} -eq 1 ]]; then\n        # Our CLI prints machine-friendly list via --list-plain:\n        # \"&lt;command&gt;\\t&lt;group&gt;\\t&lt;help&gt;\"\n        local lines cmds\n        lines=\"$(${COMP_WORDS[0]} --list-plain 2&gt;/dev/null)\"\n        cmds=\"$(printf '%s\\n' \"${lines}\" | awk -F'\\t' '{print $1}')\"\n        COMPREPLY=( $(compgen -W \"${cmds}\" -- \"${cur}\") )\n        return 0\n    fi\n\n    # 2) Completing flags for a leaf command: scrape leaf -h\n    if [[ \"${cur}\" == -* ]]; then\n        local helps opts\n        helps=\"$(${COMP_WORDS[0]} ${COMP_WORDS[1]} -h 2&gt;/dev/null)\"\n        # Pull out flag tokens and split comma-separated forms\n        opts=\"$(printf '%s\\n' \"${helps}\" \\\n            | sed -n 's/^[[:space:]]\\{0,\\}\\(-[-[:alnum:]][-[:alnum:]]*\\)\\(, *-[[:alnum:]][-[:alnum:]]*\\)\\{0,\\}.*/\\1/p' \\\n            | sed 's/, / /g')\"\n        COMPREPLY=( $(compgen -W \"${opts}\" -- \"${cur}\") )\n        return 0\n    fi\n\n    # 3) Otherwise, fall back to filename completion for positional args\n    COMPREPLY=( $(compgen -f -- \"${cur}\") )\n    return 0\n}\n\ncomplete -F _pmotools_python_complete pmotools-python\n\n\nThe above can also be found within the repo in the etc/ folder."
  },
  {
    "objectID": "Tools_Installation/pmotools-python_installation.html#installation",
    "href": "Tools_Installation/pmotools-python_installation.html#installation",
    "title": "pmotools-python installation",
    "section": "",
    "text": "pmotools-python code can be found on github https://github.com/PlasmoGenEpi/pmotools-python/tree/develop and is available via pypi\n\nCodepip install pmotools \n\n\n\nTo install the developmental version, you can download the code from github\n\nDownloading repo\n\nCodegit clone git@github.com:PlasmoGenEpi/pmotools-python.git\n\n\nCurrently (as 2025-09) majority of code is currently still in develop branch\n\nCodecd pmotools-python\ngit checkout develop\n\n\n\nTo set up a conda environment that has all the python libraries that would be needed by pmotools-python\n\nCodeconda env create -f envs/pmotools-env.yml \n\nconda active pmotools\n\n\n\nFrom within repo can install with pip in a virtual environment\n\nCodepip install -e . \n\n\n\nTo enable bash auto-completion for pmotools-python, add the following to your ~/.bash_completion and make sure it’s being loaded as part of your .bashrc and/or ~/.bash_profile (on MacOS) or ~/.profile (on ubuntu)\n\nCode_pmotools_python_complete()\n{\n    local cur prev\n    COMPREPLY=()\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"\n\n    # 1) Completing the command name (1st arg): list all commands\n    if [[ ${COMP_CWORD} -eq 1 ]]; then\n        # Our CLI prints machine-friendly list via --list-plain:\n        # \"&lt;command&gt;\\t&lt;group&gt;\\t&lt;help&gt;\"\n        local lines cmds\n        lines=\"$(${COMP_WORDS[0]} --list-plain 2&gt;/dev/null)\"\n        cmds=\"$(printf '%s\\n' \"${lines}\" | awk -F'\\t' '{print $1}')\"\n        COMPREPLY=( $(compgen -W \"${cmds}\" -- \"${cur}\") )\n        return 0\n    fi\n\n    # 2) Completing flags for a leaf command: scrape leaf -h\n    if [[ \"${cur}\" == -* ]]; then\n        local helps opts\n        helps=\"$(${COMP_WORDS[0]} ${COMP_WORDS[1]} -h 2&gt;/dev/null)\"\n        # Pull out flag tokens and split comma-separated forms\n        opts=\"$(printf '%s\\n' \"${helps}\" \\\n            | sed -n 's/^[[:space:]]\\{0,\\}\\(-[-[:alnum:]][-[:alnum:]]*\\)\\(, *-[[:alnum:]][-[:alnum:]]*\\)\\{0,\\}.*/\\1/p' \\\n            | sed 's/, / /g')\"\n        COMPREPLY=( $(compgen -W \"${opts}\" -- \"${cur}\") )\n        return 0\n    fi\n\n    # 3) Otherwise, fall back to filename completion for positional args\n    COMPREPLY=( $(compgen -f -- \"${cur}\") )\n    return 0\n}\n\ncomplete -F _pmotools_python_complete pmotools-python\n\n\nThe above can also be found within the repo in the etc/ folder."
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html",
    "href": "format/FormatOverviewAdvanced.html",
    "title": "Format Overview For Developers",
    "section": "",
    "text": "Linkml generates a datamodel file with all classes: https://github.com/PlasmoGenEpi/portable-micorhaplotype-object/blob/main/src/plasmo_tar_amp_schema/datamodel/plasmo_tar_amp_schema.py"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#portablemicrohaplotypeobject",
    "href": "format/FormatOverviewAdvanced.html#portablemicrohaplotypeobject",
    "title": "Format Overview For Developers",
    "section": "PortableMicrohaplotypeObject",
    "text": "PortableMicrohaplotypeObject\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PortableMicrohaplotypeObject/\nRequired\n\nlibrary_sample_info (type=list of LibrarySampleInfo)\n\na list of libraries of all the seq/amp of the specimens within this project\n\n\n\nspecimen_info (type=list of SpecimenInfo)\n\na list of all the specimens within this project\n\n\n\nsequencing_info (type=list of SequencingInfo)\n\na list of sequencing info for this project\n\n\n\npanel_info (type=list of PanelInfo)\n\na list of info on the panels\n\n\n\ntarget_info (type=list of TargetInfo)\n\na list of info on the targets\n\n\n\ntargeted_genomes (type=list of GenomeInfo)\n\na list of genomes that the targets in TargetInfo refer to\n\n\n\nrepresentative_microhaplotypes (type=RepresentativeMicrohaplotypes)\n\na list of the information on the representative microhaplotypes\n\n\n\nbioinformatics_methods_info (type=list of BioinformaticsMethodInfo)\n\nthe bioinformatics pipeline/methods used to generated the amplicon analysis for this project\n\n\n\nbioinformatics_run_info (type=list of BioinformaticsRunInfo)\n\nthe runtime info for the bioinformatics pipeline used to generated the amplicon analysis for this project\n\n\n\ndetected_microhaplotypes (type=list of DetectedMicrohaplotypes)\n\nthe microhaplotypes detected in this projects\n\n\n\nproject_info (type=list of ProjectInfo)\n\nthe information about the projects stored in this PMO\n\n\n\npmo_header (type=PmoHeader)\n\nthe PMO information for this file including version etc\n\n\nOptional\n\nread_counts_by_stage (type=list of ReadCountsByStage)\n\nthe read counts for different stages of the pipeline\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#biomethod",
    "href": "format/FormatOverviewAdvanced.html#biomethod",
    "title": "Format Overview For Developers",
    "section": "BioMethod",
    "text": "BioMethod\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioMethod/ Show BioMethod fields  \n\n\nRequired\n\nprogram_version (type=string)\n\nthe version of generation method, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\n\nprogram (type=string)\n\nname of the program used for this portion of the pipeline\n\n\nOptional\n\nadditional_argument (type=list of string)\n\nany additional arguments that differ from the default\n\n\n\nprogram_description (type=string)\n\na short description of what this method does\n\n\n\nprogram_url (type=string)\n\na url pointing to code base of a program, e.g. a github link\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#bioinformaticsmethodinfo",
    "href": "format/FormatOverviewAdvanced.html#bioinformaticsmethodinfo",
    "title": "Format Overview For Developers",
    "section": "BioinformaticsMethodInfo",
    "text": "BioinformaticsMethodInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioinformaticsMethodInfo/ Show BioinformaticsMethodInfo fields  \n\n\nRequired\n\nmethods (type=list of BioMethod)\n\nmethodology used to generate the amplicon data stored in this PMO, e.g. demultiplexing method, denosing method\n\n\nOptional\n\npipeline (type=BioMethod)\n\nwhat the main method info for the collection of methods is called, e.g. a pipeline name\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#bioinformaticsruninfo",
    "href": "format/FormatOverviewAdvanced.html#bioinformaticsruninfo",
    "title": "Format Overview For Developers",
    "section": "BioinformaticsRunInfo",
    "text": "BioinformaticsRunInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioinformaticsRunInfo/ Show BioinformaticsRunInfo fields  \n\n\nRequired\n\nbioinformatics_methods_id (type=integer)\n\nthe index into the bioinformatics_methods_info list\n\n\n\nbioinformatics_run_name (type=string)\n\na name to for this run, needs to be unique to each run\n\n\nOptional\n\nrun_date (type=string)\n\nthe date when the run was done, should be YYYY-MM-DD\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypes",
    "href": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypes",
    "title": "Format Overview For Developers",
    "section": "DetectedMicrohaplotypes",
    "text": "DetectedMicrohaplotypes\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/DetectedMicrohaplotypes/ Show DetectedMicrohaplotypes fields  \n\n\nRequired\n\nbioinformatics_run_id (type=integer)\n\nthe index into bioinformatics_run_info list\n\n\n\nlibrary_samples (type=list of DetectedMicrohaplotypesForSample)\n\na list of the microhaplotypes detected for a sample by targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypesforsample",
    "href": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypesforsample",
    "title": "Format Overview For Developers",
    "section": "DetectedMicrohaplotypesForSample",
    "text": "DetectedMicrohaplotypesForSample\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/DetectedMicrohaplotypesForSample/ Show DetectedMicrohaplotypesForSample fields  \n\n\nRequired\n\nlibrary_sample_id (type=integer)\n\nthe index into the library_sample_info list\n\n\n\ntarget_results (type=list of DetectedMicrohaplotypesForTarget)\n\na list of the microhaplotypes detected for a list of targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypesfortarget",
    "href": "format/FormatOverviewAdvanced.html#detectedmicrohaplotypesfortarget",
    "title": "Format Overview For Developers",
    "section": "DetectedMicrohaplotypesForTarget",
    "text": "DetectedMicrohaplotypesForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/DetectedMicrohaplotypesForTarget/ Show DetectedMicrohaplotypesForTarget fields  \n\n\nRequired\n\nmhaps_target_id (type=integer)\n\nthe index for a target in the representative_microhaplotypes list\n\n\n\nmhaps (type=list of MicrohaplotypeForTarget)\n\na list of the microhaplotypes detected for this target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#genomeinfo",
    "href": "format/FormatOverviewAdvanced.html#genomeinfo",
    "title": "Format Overview For Developers",
    "section": "GenomeInfo",
    "text": "GenomeInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/GenomeInfo/ Show GenomeInfo fields  \n\n\nRequired\n\nname (type=string)\n\nname of the genome\n\n\n\ngenome_version (type=string)\n\nthe genome version\n\n\n\ntaxon_id (type= list of integer)\n\nthe NCBI taxonomy number, can be a list of values\n\n\n\nurl (type=string)\n\na link to the where this genome file could be downloaded\n\n\nOptional\n\nchromosomes (type=list of string)\n\na list of chromosomes found within this genome\n\n\n\ngff_url (type=string)\n\na link to the where this genome’s annotation file could be downloaded\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#genomiclocation",
    "href": "format/FormatOverviewAdvanced.html#genomiclocation",
    "title": "Format Overview For Developers",
    "section": "GenomicLocation",
    "text": "GenomicLocation\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/GenomicLocation/ Show GenomicLocation fields  \n\n\nRequired\n\ngenome_id (type=integer)\n\nthe index to the genome in the targeted_genomes list that this location refers to\n\n\n\nchrom (type=string)\n\nthe chromosome name\n\n\n\nstart (type=integer)\n\nthe start of the location, 0-based positioning\n\n\n\nend (type=integer)\n\nthe end of the location, 0-based positioning\n\n\nOptional\n\nalt_seq (type=string)\n\na possible alternative sequence of this genomic location\n\n\n\nref_seq (type=string)\n\nthe reference sequence of this genomic location\n\n\n\nstrand (type=string)\n\nwhich strand the location is, either + for plus strand or - for negative strand\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#librarysampleinfo",
    "href": "format/FormatOverviewAdvanced.html#librarysampleinfo",
    "title": "Format Overview For Developers",
    "section": "LibrarySampleInfo",
    "text": "LibrarySampleInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/LibrarySampleInfo/ Show LibrarySampleInfo fields  \n\n\nRequired\n\nsequencing_info_id (type=integer)\n\nthe index into the sequencing_info list\n\n\n\nspecimen_id (type=integer)\n\nthe index into the specimen_info list\n\n\n\npanel_id (type=integer)\n\nthe index into the panel_info list\n\n\n\nlibrary_sample_name (type=string)\n\na unique identifier for this sequence/amplification run on a specimen_name\n\n\nOptional\n\nalternate_identifiers (type=list of string)\n\na list of optional alternative names\n\n\n\nexperiment_accession (type=string)\n\nERA/SRA experiment accession number for the sample if it was submitted\n\n\n\nfastqs_loc (type=string)\n\nthe location (url or filename path) of the fastqs for a library run\n\n\n\nlibrary_prep_plate_info (type=PlateInfo)\n\nplate location of where library was prepared for sequencing\n\n\n\nqpcr_parasite_density_info (type=list of ParasiteDensity)\n\nqpcr parasite density measurement for this extracted sample\n\n\n\nrun_accession (type=string)\n\nERA/SRA run accession number for the sample if it was submitted\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#markerofinterest",
    "href": "format/FormatOverviewAdvanced.html#markerofinterest",
    "title": "Format Overview For Developers",
    "section": "MarkerOfInterest",
    "text": "MarkerOfInterest\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MarkerOfInterest/ Show MarkerOfInterest fields  \n\n\nRequired\n\nmarker_location (type=GenomicLocation)\n\nthe genomic location\n\n\nOptional\n\nassociations (type=list of string)\n\na list of associations with this marker, e.g. SP resistance, etc\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#maskinginfo",
    "href": "format/FormatOverviewAdvanced.html#maskinginfo",
    "title": "Format Overview For Developers",
    "section": "MaskingInfo",
    "text": "MaskingInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MaskingInfo/ Show MaskingInfo fields  \n\n\nRequired\n\nseq_start (type=integer)\n\nthe start of the masking\n\n\n\nseq_segment_size (type=integer)\n\nthe size of the masking\n\n\n\nreplacement_size (type=integer)\n\nthe size of replacement mask\n\n\nOptional\n\nmasking_generation_description (type=string)\n\na description of how the masking information was generated\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#microhaplotypefortarget",
    "href": "format/FormatOverviewAdvanced.html#microhaplotypefortarget",
    "title": "Format Overview For Developers",
    "section": "MicrohaplotypeForTarget",
    "text": "MicrohaplotypeForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MicrohaplotypeForTarget/ Show MicrohaplotypeForTarget fields  \n\n\nRequired\n\nmhap_id (type=integer)\n\nthe index for a microhaplotype for a target in the representative_microhaplotypes list, e.g. representative_microhaplotypes[mhaps_target_id][mhap_id]\n\n\n\nreads (type=integer)\n\nthe read count associated with this microhaplotype\n\n\nOptional\n\numis (type=integer)\n\nthe unique molecular identifier (umi) count associated with this microhaplotype\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#panelinfo",
    "href": "format/FormatOverviewAdvanced.html#panelinfo",
    "title": "Format Overview For Developers",
    "section": "PanelInfo",
    "text": "PanelInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PanelInfo/ Show PanelInfo fields  \n\n\nRequired\n\nreactions (type=list of ReactionInfo)\n\na list of 1 or more reactions that this panel contains, each reactions list the targets that were amplified in that reaction, e.g. pool1, pool2\n\n\n\npanel_name (type=string)\n\na name for the panel\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#parasitedensity",
    "href": "format/FormatOverviewAdvanced.html#parasitedensity",
    "title": "Format Overview For Developers",
    "section": "ParasiteDensity",
    "text": "ParasiteDensity\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ParasiteDensity/ Show ParasiteDensity fields  \n\n\nRequired\n\nparasite_density_method (type=string)\n\nthe method of how this density was obtained\n\n\n\nparasite_density (type=number)\n\nthe density in microliters\n\n\nOptional\n\ndate_measured (type=string)\n\nthe date the qpcr was performed, can be YYYY, YYYY-MM, or YYYY-MM-DD\n\n\n\ndensity_method_comments (type=string)\n\nadditional comments about how the density was performed\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#plateinfo",
    "href": "format/FormatOverviewAdvanced.html#plateinfo",
    "title": "Format Overview For Developers",
    "section": "PlateInfo",
    "text": "PlateInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PlateInfo/ Show PlateInfo fields  \n\n\nRequired\nOptional\n\nplate_col (type=integer)\n\nthe column the specimen was in\n\n\n\nplate_name (type=string)\n\na name of plate the specimen was in\n\n\n\nplate_row (type=string)\n\nthe row the specimen was in\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#pmogenerationmethod",
    "href": "format/FormatOverviewAdvanced.html#pmogenerationmethod",
    "title": "Format Overview For Developers",
    "section": "PmoGenerationMethod",
    "text": "PmoGenerationMethod\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PmoGenerationMethod/ Show PmoGenerationMethod fields  \n\n\nRequired\n\nprogram_version (type=string)\n\nthe version of generation method, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\n\nprogram_name (type=string)\n\nthe name of the program\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#pmoheader",
    "href": "format/FormatOverviewAdvanced.html#pmoheader",
    "title": "Format Overview For Developers",
    "section": "PmoHeader",
    "text": "PmoHeader\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PmoHeader/ Show PmoHeader fields  \n\n\nRequired\n\npmo_version (type=string)\n\nthe version of the PMO file, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\nOptional\n\ncreation_date (type=string)\n\nthe date of when the PMO file was created or modified, should be YYYY-MM-DD\n\n\n\ngeneration_method (type=PmoGenerationMethod)\n\nthe generation method to create this PMO\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#primerinfo",
    "href": "format/FormatOverviewAdvanced.html#primerinfo",
    "title": "Format Overview For Developers",
    "section": "PrimerInfo",
    "text": "PrimerInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PrimerInfo/ Show PrimerInfo fields  \n\n\nRequired\n\nseq (type=string)\n\nthe DNA sequence\n\n\nOptional\n\nlocation (type=GenomicLocation)\n\nwhat the intended genomic location of the primer is\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#projectinfo",
    "href": "format/FormatOverviewAdvanced.html#projectinfo",
    "title": "Format Overview For Developers",
    "section": "ProjectInfo",
    "text": "ProjectInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ProjectInfo/ Show ProjectInfo fields  \n\n\nRequired\n\nproject_name (type=string)\n\na name for the project, should be unique if multiple projects listed\n\n\n\nproject_description (type=string)\n\na short description of the project\n\n\nOptional\n\nBioProject_accession (type=string)\n\nan SRA bioproject accession e.g. PRJNA33823\n\n\n\nproject_collector_chief_scientist (type=string)\n\ncan be collection of names separated by a semicolon if multiple people involved or can just be the name of the primary person managing the specimen\n\n\n\nproject_contributors (type=list of string)\n\na list of collaborators who contributed to this project\n\n\n\nproject_type (type=string)\n\nthe type of project conducted, e.g. TES vs surveillance vs transmission\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#proteinvariant",
    "href": "format/FormatOverviewAdvanced.html#proteinvariant",
    "title": "Format Overview For Developers",
    "section": "ProteinVariant",
    "text": "ProteinVariant\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ProteinVariant/ Show ProteinVariant fields  \n\n\nRequired\n\nprotein_location (type=GenomicLocation)\n\nthe position within the protein, the chromosome in this case would be the transcript name\n\n\nOptional\n\nalternative_gene_name (type=string)\n\nan alternative gene name\n\n\n\ncodon_genomic_location (type=GenomicLocation)\n\nthe position within the genomic sequence of the codon\n\n\n\ngene_name (type=string)\n\nan identifier of the gene, if any, is being covered with this targeted\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#pseudocigar",
    "href": "format/FormatOverviewAdvanced.html#pseudocigar",
    "title": "Format Overview For Developers",
    "section": "Pseudocigar",
    "text": "Pseudocigar\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/Pseudocigar/ Show Pseudocigar fields  \n\n\nRequired\n\npseudocigar_seq (type=string)\n\nthe pseudocigar itself\n\n\n\nref_loc (type=GenomicLocation)\n\nthe genomic location the pseudocigar is in reference to\n\n\nOptional\n\npseudocigar_generation_description (type=string)\n\na description of how the pseudocigar information was generated\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#reactioninfo",
    "href": "format/FormatOverviewAdvanced.html#reactioninfo",
    "title": "Format Overview For Developers",
    "section": "ReactionInfo",
    "text": "ReactionInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReactionInfo/ Show ReactionInfo fields  \n\n\nRequired\n\npanel_targets (type= list of integer)\n\na list of the target indexes in the target_info list\n\n\n\nreaction_name (type=string)\n\na name for this reaction\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#readcountsbystage",
    "href": "format/FormatOverviewAdvanced.html#readcountsbystage",
    "title": "Format Overview For Developers",
    "section": "ReadCountsByStage",
    "text": "ReadCountsByStage\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStage/ Show ReadCountsByStage fields  \n\n\nRequired\n\nbioinformatics_run_id (type=integer)\n\nthe index into bioinformatics_run_info list\n\n\n\nread_counts_by_library_sample_by_stage (type=list of ReadCountsByStageForLibrarySample)\n\na list by library_sample for the counts at each stage\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#readcountsbystageforlibrarysample",
    "href": "format/FormatOverviewAdvanced.html#readcountsbystageforlibrarysample",
    "title": "Format Overview For Developers",
    "section": "ReadCountsByStageForLibrarySample",
    "text": "ReadCountsByStageForLibrarySample\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStageForLibrarySample/ Show ReadCountsByStageForLibrarySample fields  \n\n\nRequired\n\nlibrary_sample_id (type=integer)\n\nthe index into the library_sample_info list\n\n\n\ntotal_raw_count (type=integer)\n\nthe raw counts off the sequencing machine that a sample began with\n\n\nOptional\n\nread_counts_for_targets (type=list of ReadCountsByStageForTarget)\n\na list of counts by stage for a target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#readcountsbystagefortarget",
    "href": "format/FormatOverviewAdvanced.html#readcountsbystagefortarget",
    "title": "Format Overview For Developers",
    "section": "ReadCountsByStageForTarget",
    "text": "ReadCountsByStageForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStageForTarget/ Show ReadCountsByStageForTarget fields  \n\n\nRequired\n\ntarget_id (type=integer)\n\nthe index into the target_info list\n\n\n\nstages (type=list of StageReadCounts)\n\nthe read counts by each stage\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#representativemicrohaplotype",
    "href": "format/FormatOverviewAdvanced.html#representativemicrohaplotype",
    "title": "Format Overview For Developers",
    "section": "RepresentativeMicrohaplotype",
    "text": "RepresentativeMicrohaplotype\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotype/ Show RepresentativeMicrohaplotype fields  \n\n\nRequired\n\nseq (type=string)\n\nthe DNA sequence\n\n\nOptional\n\nalt_annotations (type=list of string)\n\na list of additional annotations associated with this microhaplotype, e.g. wildtype\n\n\n\nassociated_protein_variants (type=list of ProteinVariant)\n\na list of associated protein variants with this haplotype, e.g. amino acid changes/INDELS\n\n\n\nassociated_seq_variants (type=list of GenomicLocation)\n\na list of associated sequence variants with this haplotype, e.g. SNPS, indels\n\n\n\nmasking (type=list of MaskingInfo)\n\nmasking info for the sequence\n\n\n\nmicrohaplotype_name (type=string)\n\nan optional name for this microhaplotype\n\n\n\npseudocigar (type=Pseudocigar)\n\nthe pseudocigar of the haplotype\n\n\n\nquality (type=string)\n\nthe ansi fastq per base quality score for this sequence, this is optional\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#representativemicrohaplotypes",
    "href": "format/FormatOverviewAdvanced.html#representativemicrohaplotypes",
    "title": "Format Overview For Developers",
    "section": "RepresentativeMicrohaplotypes",
    "text": "RepresentativeMicrohaplotypes\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotypes/ Show RepresentativeMicrohaplotypes fields  \n\n\nRequired\n\ntargets (type=list of RepresentativeMicrohaplotypesForTarget)\n\na list of the microhaplotype for each targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#representativemicrohaplotypesfortarget",
    "href": "format/FormatOverviewAdvanced.html#representativemicrohaplotypesfortarget",
    "title": "Format Overview For Developers",
    "section": "RepresentativeMicrohaplotypesForTarget",
    "text": "RepresentativeMicrohaplotypesForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotypesForTarget/ Show RepresentativeMicrohaplotypesForTarget fields  \n\n\nRequired\n\ntarget_id (type=integer)\n\nthe index into the target_info list\n\n\n\nmicrohaplotypes (type=list of RepresentativeMicrohaplotype)\n\na list of the microhaplotypes detected for a target\n\n\nOptional\n\nmhap_location (type=GenomicLocation)\n\na genomic location that was analyzed for this target info, this allows listing location that may be different from the full target location (e.g 1 base in from the full)\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#sequencinginfo",
    "href": "format/FormatOverviewAdvanced.html#sequencinginfo",
    "title": "Format Overview For Developers",
    "section": "SequencingInfo",
    "text": "SequencingInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/SequencingInfo/ Show SequencingInfo fields  \n\n\nRequired\n\nsequencing_info_name (type=string)\n\na name of for the sequencing done, e.g. batch1\n\n\n\nseq_platform (type=string)\n\nthe sequencing technology used to sequence the run, e.g. ILLUMINA, NANOPORE, PACBIO\n\n\n\nseq_instrument_model (type=string)\n\nthe sequencing instrument model used to sequence the run, e.g. NextSeq 2000, MinION, Revio\n\n\n\nlibrary_layout (type=string)\n\nSpecify the configuration of reads, e.g. paired-end, single\n\n\n\nlibrary_strategy (type=string)\n\nwhat the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\n\n\n\nlibrary_source (type=string)\n\nSource of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\n\n\n\nlibrary_selection (type=string)\n\nhow amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\n\n\nOptional\n\nlibrary_kit (type=string)\n\nName, version, and applicable cell or cycle numbers for the kit used to prepare libraries and load cells or chips for sequencing. If possible, include a part number, e.g. MiSeq Reagent Kit v3 (150-cycle), MS-102-3001\n\n\n\nlibrary_screen (type=string)\n\nDescribe enrichment, screening, or normalization methods applied during amplification or library preparation, e.g. size selection 390bp, diluted to 1 ng DNA/sample\n\n\n\nnucl_acid_amp (type=string)\n\nLink to a reference or kit that describes the enzymatic amplification of nucleic acids\n\n\n\nnucl_acid_amp_date (type=string)\n\nthe date of the nucleoacid amplification\n\n\n\nnucl_acid_ext (type=string)\n\nLink to a reference or kit that describes the recovery of nucleic acids from the sample\n\n\n\nnucl_acid_ext_date (type=string)\n\nthe date of the nucleoacid extraction\n\n\n\npcr_cond (type=string)\n\nthe method/conditions for PCR, List PCR cycles used to amplify the target\n\n\n\nseq_center (type=string)\n\nName of facility where sequencing was performed (lab, core facility, or company)\n\n\n\nseq_date (type=string)\n\nthe date of sequencing, should be YYYY-MM or YYYY-MM-DD\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#specimeninfo",
    "href": "format/FormatOverviewAdvanced.html#specimeninfo",
    "title": "Format Overview For Developers",
    "section": "SpecimenInfo",
    "text": "SpecimenInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/SpecimenInfo/ Show SpecimenInfo fields  \n\n\nRequired\n\nspecimen_name (type=string)\n\nan identifier for the specimen, should be unique within this sample set\n\n\n\nspecimen_taxon_id (type= list of integer)\n\nthe NCBI taxonomy number of the organism in specimen, can list multiple if a mixed sample\n\n\n\nhost_taxon_id (type=integer)\n\nthe NCBI taxonomy number of the host that the specimen was collected from\n\n\n\ncollection_date (type=string)\n\nthe date of the specimen collection, can be YYYY, YYYY-MM, or YYYY-MM-DD\n\n\n\ncollection_country (type=string)\n\nthe name of country collected in, would be the same as admin level 0\n\n\n\nproject_id (type=integer)\n\nthe index into the project_info list\n\n\nOptional\n\nalternate_identifiers (type=list of string)\n\na list of optional alternative names\n\n\n\nblood_meal (type=boolean)\n\nwhether host specimen has had a recent blood meal\n\n\n\ndrug_usage (type=list of string)\n\nAny drug used by subject and the frequency of usage; can include multiple drugs used\n\n\n\nenv_broad_scale (type=string)\n\nthe broad environment from which the specimen was collected, e.g. highlands, lowlands, mountainous region\n\n\n\nenv_local_scale (type=string)\n\nthe local environment from which the specimen was collected, e.g. jungle, urban, rural\n\n\n\nenv_medium (type=string)\n\nthe environment medium from which the specimen was collected from\n\n\n\ngeo_admin1 (type=string)\n\ngeographical admin level 1, the secondary large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin2 (type=string)\n\ngeographical admin level 2, the third large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin3 (type=string)\n\ngeographical admin level 3, the third large demarcation of a nation (nation = admin level 0)\n\n\n\ngravid (type=boolean)\n\nwhether host specimen is currently pregnant\n\n\n\ngravidity (type=integer)\n\nthe gravidity of the specimen host (number of previous pregnancies)\n\n\n\nhas_travel_out_six_month (type=boolean)\n\nhas travelled out from local region in the last six months\n\n\n\nhost_age (type=number)\n\nif specimen is from a person, the age in years of the person, can be float value so for 3 month old put 0.25\n\n\n\nhost_sex (type=string)\n\nif specimen is from a person, the sex listed for that person\n\n\n\nhost_subject_id (type=integer)\n\nan identifier for the individual a specimen was collected from\n\n\n\nlat_lon (type=string)\n\nthe latitude and longitude of a specific site\n\n\n\nparasite_density_info (type=list of ParasiteDensity)\n\none or more parasite densities in microliters for this specimen\n\n\n\nspecimen_accession (type=string)\n\nif specimen is deposited in a database, what accession is it associated with\n\n\n\nspecimen_collect_device (type=string)\n\nthe way the specimen was collected, e.g. whole blood, dried blood spot\n\n\n\nspecimen_comments (type=list of string)\n\nany additional comments about the specimen\n\n\n\nspecimen_store_loc (type=string)\n\nthe specimen store site, address or facility name\n\n\n\nspecimen_type (type=string)\n\nwhat type of specimen this is, e.g. negative_control, positive_control, field_sample\n\n\n\nstorage_plate_info (type=PlateInfo)\n\nplate location of where specimen is stored if stored in a plate\n\n\n\ntravel_out_six_month (type=list of TravelInfo)\n\nSpecification of the countries travelled in the last six months; can include multiple travels\n\n\n\ntreatment_status (type=list of string)\n\nIf person has been treated with drugs, what was the treatment outcome\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#stagereadcounts",
    "href": "format/FormatOverviewAdvanced.html#stagereadcounts",
    "title": "Format Overview For Developers",
    "section": "StageReadCounts",
    "text": "StageReadCounts\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/StageReadCounts/ Show StageReadCounts fields  \n\n\nRequired\n\nreads (type=integer)\n\nthe read counts for this stage\n\n\n\nstage (type=string)\n\nthe stage of the pipeline, e.g. demultiplexed, denoised, etc\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#targetinfo",
    "href": "format/FormatOverviewAdvanced.html#targetinfo",
    "title": "Format Overview For Developers",
    "section": "TargetInfo",
    "text": "TargetInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/TargetInfo/ Show TargetInfo fields  \n\n\nRequired\n\ntarget_name (type=string)\n\nan identifier for this target\n\n\n\nforward_primer (type=PrimerInfo)\n\nthe forward primer associated with this target\n\n\n\nreverse_primer (type=PrimerInfo)\n\nthe reverse primer associated with this target\n\n\nOptional\n\ngene_name (type=string)\n\nan identifier of the gene, if any, is being covered with this targeted\n\n\n\ninsert_location (type=GenomicLocation)\n\nthe intended genomic location of the insert of the amplicon (the location between the end of the forward primer and the beginning of the reverse primer)\n\n\n\nmarkers_of_interest (type=list of MarkerOfInterest)\n\na list of covered markers of interest\n\n\n\ntarget_attributes (type=list of string)\n\na list of classification type for the primer target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html#travelinfo",
    "href": "format/FormatOverviewAdvanced.html#travelinfo",
    "title": "Format Overview For Developers",
    "section": "TravelInfo",
    "text": "TravelInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/TravelInfo/ Show TravelInfo fields  \n\n\nRequired\n\ntravel_country (type=string)\n\nthe name of country, would be the same as admin level 0\n\n\n\ntravel_start_date (type=string)\n\nthe date of the start of travel, can be approximate, should be YYYY-MM or YYYY-MM-DD (preferred)\n\n\n\ntravel_end_date (type=string)\n\nthe date of the end of travel, can be approximate, should be YYYY-MM or YYYY-MM-DD (preferred)\n\n\nOptional\n\nbed_net_usage (type=number)\n\napproximate usage of bed net while traveling, 1 = 100% nights with bed net, 0 = 0% no bed net usage\n\n\n\ngeo_admin1 (type=string)\n\ngeographical admin level 1, the secondary large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin2 (type=string)\n\ngeographical admin level 2, the third large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin3 (type=string)\n\ngeographical admin level 3, the third large demarcation of a nation (nation = admin level 0)\n\n\n\nlat_lon (type=string)\n\nthe latitude and longitude of a specific site\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html",
    "href": "format/FormatOverview.html",
    "title": "PMO fields overview",
    "section": "",
    "text": "The design goal behind PMO\nThe format was created while attempting to stay consistent with previous standards like MIxS standards. These are the standards that the short read archive (SRA) use to validate metadata upon submission. This also helps to keep data standards to adhere to FAIR (Findable, Accessible, Interoperable, and Reusable).\nThe format was developed in order to achieve an efficient/low-weight format that contains the minimum amount of information about a targeted amplicon analysis without losing any important data. Tools are generated around this table to generate certain fields that are important but not necessary to keep constantly stored in this base class (e.g. aggreated SNP/INDEL calls, aggregated allele frequencies). To increase portability and to keep data internally consistent, format was designed to be contained within a singular file in JSON format which removes the limitation of storing data only in a tabular format. Though output generated from this file can still be a table for downstream usage in other tools but by storing in the flexible JSON format this allows storage in non-redundant organization (e.g. storing the sequennce only once while storing other data in lists).\nFormat is defined by utilizing LinkML to generate a general data scheme which creates various validation outputs like JSON Schema for validation tools. LinkML generates a website for viewing all fields defined in the format, https://github.com/PlasmoGenEpi/portable-microhaplotype-object.\nOther notable users of LinkML/MIxS National Microbiome Data Collaborative Schema\nFormat shcema\nA json-schema for the format\n\nportable_microhaplotype_object.schema.json\n\nTop Level Schematic\n (A) Schematic of the top-level tables within PMO. Green boxes indicate tables that will commonly be reused across datasets. Pink dashed boxes highlight tables that are input collectively into pmotools-python or the PMO app via a single input table. (B) Illustration comparing current approaches to microhaplotype storage with storage within PMO. Current storage solutions often rely on long-form microhaplotype storage, with repeated listing of full nucleotide sequences, as shown on the left of panel B. In contrast, PMO replaces this with two efficiently linked tables, eliminating redundancy, as shown on the right of panel B.\nTable describing fields"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "",
    "text": "Multiplexed targeted sequencing is now widely used to generate data for the most informative genomic regions of organisms, but the lack of an appropriate data standard has hindered data sharing, reuse, and downstream analysis. Here, we provide details for an extensible standard and related convenience utilities to store lossless, compact representations of phased, processed target sequences (microhaplotypes) along with an efficient relational ontology in a portable JSON file."
  },
  {
    "objectID": "index.html#why-targeted-sequencing-needs-a-data-standard",
    "href": "index.html#why-targeted-sequencing-needs-a-data-standard",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Why targeted sequencing needs a data standard",
    "text": "Why targeted sequencing needs a data standard\nTargeted amplicon sequencing is now established as a sensitive and efficient means of obtaining relevant information about a wide variety of organisms. Applications are broad and expanding, including microbiome analysis, pathogen identification, detection of antimicrobial resistance, and tracking the spread of viruses, bacteria, and eukaryotic pathogens.\nMany of these applications utilize the full sequences provided by individual reads because they contain multiple, phased variants (microhaplotypes)(Oldoni, Kidd, and Podini 2019) - information that is lost when decomposing these data into independent variants such as SNPs. This information is particularly valuable when sequencing samples containing organisms with more than one sequence per target, such as mixed bacterial samples, commonly polyclonal pathogens (e.g., Plasmodium) (Tessema et al. 2022),(LaVerriere et al. 2022),(Jacob et al. 2021),(Kattenberg Johanna Helena et al. 2023),(Aranda-Díaz et al. 2025),(Sadler et al. 2024), and diploid or polyploid organisms. Thus, data formats designed for small variants that do not preserve full sequences, such as the popular variant call format (VCF), are not well suited to store microhaplotype data."
  },
  {
    "objectID": "index.html#goals-of-the-pmo-data-standard",
    "href": "index.html#goals-of-the-pmo-data-standard",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Goals of the PMO data standard",
    "text": "Goals of the PMO data standard\n\nProvide a structured and flexible framework to help individual researchers and groups to organize their data in a findable and accessible way.\nCreate a standard for data sharing, including for repositories, academic reports, and public health entities, to aid in interoperability, transparency, and reproducibility\nMaximize data reuse by lowering the barriers for making data publicly available in a standardized format.\nProvide a consistent format to allow harmonization of downstream analysis tools across data sets and minimize the need for tedious and error-prone tasks such as data reshaping"
  },
  {
    "objectID": "index.html#our-approach-to-development",
    "href": "index.html#our-approach-to-development",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Our approach to development",
    "text": "Our approach to development\nThe microbiome community has created data standards for a single locus, including BIOM and ESS-DIVE. Here, we extend these standards to an arbitrary number of loci in a framework extensible to any type of targeted sequence data. The format is lossless, allowing recovery of full sequence data, while achieving data compression of ~6x and up to ~80x with additional compression using standard tools (e.g., gzip). Optional fields allow data generators with domain expertise to include additionally processed sequence data such as variants with masked domains, e.g. for highly error prone areas such as tandem repeats. Notably, the framework provides a robust relational ontology for sample, laboratory, and bioinformatic metadata in addition to sequence data, mitigating the common problem of partially or completely orphaned data. A full ontology has been built out for Plasmodium, leveraging existing fields where available, and the modular structure can be flexibly extended to other biological systems, including those containing multiple types of organisms. All data are encoded in a standard JSON file, enhancing portability and ease-of-interpretation. The end result is a design which is efficient, lightweight, and flexible, organizing metadata together with genetic data. Finally, we have created a set of convenience utilities to make it easy to create, manipulate, share, import, and export PMO files."
  },
  {
    "objectID": "format/FormatExample.html#from-pf7-data-for-the-same-panel-above",
    "href": "format/FormatExample.html#from-pf7-data-for-the-same-panel-above",
    "title": "PMO Examples",
    "section": "From Pf7+ data for the same panel above",
    "text": "From Pf7+ data for the same panel above\nGlobal data microhaplotypes were constructed by PathWeaver for the same targeted amplicon panel above. This includes approximately 1900 samples.\n\nPathWeaverHeome1_PMO.json.gz"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html",
    "href": "format/DevelopmentOfFormat.html",
    "title": "Development of Format",
    "section": "",
    "text": "The meta fields for the sample and sequencing are based on NCBI naming schemes especially from SRA submission portal for human-associated pathogen. Depending on which reporting standard is selected at the time of submission, these are derived and vlided via the the MiXS standards set by the Genomics Standards Consortium (GSC)\n\nWhen submitting sample meta data to SRA, you have to choose a reporting standard to validate your meta data against\n\nThere are 4 reporting standards that one might pick for targeted amplicon sequencing of a pathogen\n\n\nMIGS.eu.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMIMARKS.specimen.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMicrobe.1.0 (non-MiXS derived, SRA discourages usage)\n\nPathogen.cl.1.0 (non-MiXS derived, SRA discourages usage)\n\nMIGS.eu.human-associated.6.0 and MIMARKS.specimen.human-associated.6.0 have the same required fields and only differ with a handful of different fields\nDetermining difference between MIGS.eu.human-associated and MIMARKS.specimen.human-associated\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\nMIMARKS_specimen_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip= 12)\n\ncolname_compared = set_decompose(colnames(MIGS_eu_human_associated), colnames(MIMARKS_specimen_human_associated))\n\nlist(\"Only in MIGS_eu_human_associated\" = colname_compared$only_in_vectorA, \n     \"Only in MIMARKS_specimen_human_associated\" = colname_compared$only_in_vectorB)\n\n$`Only in MIGS_eu_human_associated`\n[1] \"estimated_size\"  \"host_taxid\"      \"num_replicons\"   \"pathogenicity\"   \"ploidy\"          \"propagation\"     \"ref_biomaterial\"\n\n$`Only in MIMARKS_specimen_human_associated`\n[1] \"rel_to_oxygen\"\n\n\nSite describing all BioSample Attributes at the SRA https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?package-0=MIGS.eu.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIGS.eu.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=MIMARKS.specimen&package-1=MIMARKS.specimen.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIMARKS.specimen.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Microbe.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMicrobe.1.0.xlsx\n\n\nCodeMicrobe = readxl::read_excel(\"sra_standards/Microbe.1.0.xlsx\", skip = 12)\ncreate_dt(Microbe)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nsample_type (non MixS standard) - Sample type, such as cell culture, mixed culture, tissue sample, whole organism, single cell, metagenomic assembly\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nOne of the following\n\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Pathogen&package-1=Pathogen.cl.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nPathogen.cl.1.0.xlsx\n\n\nCodePathogen = readxl::read_excel(\"sra_standards/Pathogen.cl.1.0.xlsx\", skip = 12)\ncreate_dt(Pathogen)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\ncollected_by - Name of persons or institute who collected the sample\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\nhost_disease (non-MixS field) - Name of relevant disease, e.g. Salmonella gastroenteritis. Controlled vocabulary, http://bioportal.bioontology.org/ontologies/1009 or http://www.ncbi.nlm.nih.gov/mesh\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nAdditonal fields not in GSC or SRA submission but are often found in downloads from SRAs. This is because the geo_loc_name can be country followed by several more details, these columns allow for listing only the country and continent\n\ngeo_loc_name_country\ngeo_loc_name_country_continent\n\nInfo about the sequencing of the samples above, details can be found below link:\nSRA sequencing meta: https://www.ncbi.nlm.nih.gov/sra/docs/submitportal/#6-sra-metadata\nExample file for SRA submission\n\nSRA_metadata.xlsx\n\n\nCodeSRA_sequencing_metadata = readxl::read_excel(\"sra_standards/SRA_metadata.xlsx\", sheet = 2)\ncreate_dt(SRA_sequencing_metadata)\n\n\n\n\n\n\nDetails about the requirments\n\nIf you created samples previously, provide accessions in the form of SAMN# in the column sample_accession. Otherwise provide the sample name used in the BioSample attributes spreadsheet.\nEach row in the template represents a sequencing library with a unique combination of sample + library + sequencing strategy + layout + instrument model. Each row should have a unique library_id that is short and meaningful (like an ID you might use in lab).\nWhen libraries are indeed identical (same combination of sample + library + strategy + layout + instrument model), all files should be placed in the same row To do this simply enter the file names consecutively in the same row by adding more columns with headers filename2, filename3, etc…. PAIRED files must always be listed in the same row.\nsample_name - must match exactly the sample_name in the tables above\nlibrary_id - each must be unique, should be short like what is in a samplesheet\ntitle - Short description that will identify the dataset on public pages. A clear and concise formula for the title would be like: {methodology} of {organism}: {sample info} _e.g. RNA-Seq of mus musculus:adult female spleen\nlibrary_strategy - what the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\nlibrary_source - Source of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\nlibrary_selection - how amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\nlibrary_layout (MixS equivalent lib_layout) - Specify whether to expect single, paired, or other configuration of reads\nplatform (MixS equivalent is part of seq_meth) - Machine used to sequence data, should be one from https://ontobee.org/ontology/OBI?iri=http://purl.obolibrary.org/obo/OBI_0400103\ninstrument_model (MixS equivalent is part of seq_meth) - The specific model of the machine above\ndesign_description - A short description of how sequencing was done, paragraph style\nfiletype and filenames - the type of file and the names of the files associated with the sequencing\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002/\n\nCodeMigsEu_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MigsEu_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MigsEu_v6.2.0_fields)\n\n\n\n\nCodeMigsEu_v6.2.0_fields  = MigsEu_v6.2.0_fields%&gt;% \n  mutate(in_MigsEu_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0016003/\n\nCodeHumanAssociated_v6.2.0_fields = readr::read_tsv(\"mixs_standards/HumanAssociated_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(HumanAssociated_v6.2.0_fields)\n\n\n\n\nCodeHumanAssociated_v6.2.0_fields  = HumanAssociated_v6.2.0_fields%&gt;% \n  mutate(in_HumanAssociated_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009/\n\nCodeMimarksC_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MimarksC_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MimarksC_v6.2.0_fields)\n\n\n\n\nCodeMimarksC_v6.2.0_fields  = MimarksC_v6.2.0_fields%&gt;% \n  mutate(in_MimarksC_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\n\n\nCodeall_mixs_fields = MigsEu_v6.2.0_fields %&gt;% \n  full_join(MimarksC_v6.2.0_fields) %&gt;% \n  full_join(HumanAssociated_v6.2.0_fields) %&gt;% \n  arrange(fields) %&gt;% \n  mutate(in_both_MigsEu_MimarksC = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0)%&gt;% \n  mutate(in_all_three = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0 & in_HumanAssociated_v6.2.0)\ncreate_dt(all_mixs_fields)\n\n\n\n\n\n\nThe fields choices for PMO took into consideration the Mixs standards, SRA standards, and from other similar amplicon standards (which are also based on Mixs standards), Environmental System Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE) and National Microbiome Data Collaborative (NMDC)\nThe SRA takes two tables, one defining bio samples and one defining sequencing experiment libraries done on those bio samples of which there could be multiple sequencing experiments. Therefore the decision was made to also create two separate data sections for defining a biosample (specimen_info) and one defining experiments on those specimens (library_sample_info), this allows the mirroring of SRA as well as allowing for storing replicates of a single specimen. A 3rd section was created to store redundant sequencing info (sequencing_info).\n\nComparing the specimen_info fields to the MIXS standard and SRA. Please see specimen_info in FormatOverview for short description of each pmo field and above for the SRA fields\n\nCodecreate_dt(readr::read_tsv(\"specimen_info_field_comparison.tsv\"))\n\n\n\n\n\n\nComparing the sequencing_info and library_sample_info fields to the Mixs standards and the data required for SRA submission above\n\nCodecreate_dt(readr::read_tsv(\"library_and_sequencing_field_comparison.tsv\"))"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#sra-sample-fields",
    "href": "format/DevelopmentOfFormat.html#sra-sample-fields",
    "title": "Development of Format",
    "section": "",
    "text": "When submitting sample meta data to SRA, you have to choose a reporting standard to validate your meta data against\n\nThere are 4 reporting standards that one might pick for targeted amplicon sequencing of a pathogen\n\n\nMIGS.eu.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMIMARKS.specimen.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMicrobe.1.0 (non-MiXS derived, SRA discourages usage)\n\nPathogen.cl.1.0 (non-MiXS derived, SRA discourages usage)\n\nMIGS.eu.human-associated.6.0 and MIMARKS.specimen.human-associated.6.0 have the same required fields and only differ with a handful of different fields\nDetermining difference between MIGS.eu.human-associated and MIMARKS.specimen.human-associated\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\nMIMARKS_specimen_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip= 12)\n\ncolname_compared = set_decompose(colnames(MIGS_eu_human_associated), colnames(MIMARKS_specimen_human_associated))\n\nlist(\"Only in MIGS_eu_human_associated\" = colname_compared$only_in_vectorA, \n     \"Only in MIMARKS_specimen_human_associated\" = colname_compared$only_in_vectorB)\n\n$`Only in MIGS_eu_human_associated`\n[1] \"estimated_size\"  \"host_taxid\"      \"num_replicons\"   \"pathogenicity\"   \"ploidy\"          \"propagation\"     \"ref_biomaterial\"\n\n$`Only in MIMARKS_specimen_human_associated`\n[1] \"rel_to_oxygen\"\n\n\nSite describing all BioSample Attributes at the SRA https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?package-0=MIGS.eu.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIGS.eu.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=MIMARKS.specimen&package-1=MIMARKS.specimen.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIMARKS.specimen.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Microbe.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMicrobe.1.0.xlsx\n\n\nCodeMicrobe = readxl::read_excel(\"sra_standards/Microbe.1.0.xlsx\", skip = 12)\ncreate_dt(Microbe)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nsample_type (non MixS standard) - Sample type, such as cell culture, mixed culture, tissue sample, whole organism, single cell, metagenomic assembly\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nOne of the following\n\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Pathogen&package-1=Pathogen.cl.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nPathogen.cl.1.0.xlsx\n\n\nCodePathogen = readxl::read_excel(\"sra_standards/Pathogen.cl.1.0.xlsx\", skip = 12)\ncreate_dt(Pathogen)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\ncollected_by - Name of persons or institute who collected the sample\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\nhost_disease (non-MixS field) - Name of relevant disease, e.g. Salmonella gastroenteritis. Controlled vocabulary, http://bioportal.bioontology.org/ontologies/1009 or http://www.ncbi.nlm.nih.gov/mesh\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nAdditonal fields not in GSC or SRA submission but are often found in downloads from SRAs. This is because the geo_loc_name can be country followed by several more details, these columns allow for listing only the country and continent\n\ngeo_loc_name_country\ngeo_loc_name_country_continent"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#sra-sequencing-fields",
    "href": "format/DevelopmentOfFormat.html#sra-sequencing-fields",
    "title": "Development of Format",
    "section": "",
    "text": "Info about the sequencing of the samples above, details can be found below link:\nSRA sequencing meta: https://www.ncbi.nlm.nih.gov/sra/docs/submitportal/#6-sra-metadata\nExample file for SRA submission\n\nSRA_metadata.xlsx\n\n\nCodeSRA_sequencing_metadata = readxl::read_excel(\"sra_standards/SRA_metadata.xlsx\", sheet = 2)\ncreate_dt(SRA_sequencing_metadata)\n\n\n\n\n\n\nDetails about the requirments\n\nIf you created samples previously, provide accessions in the form of SAMN# in the column sample_accession. Otherwise provide the sample name used in the BioSample attributes spreadsheet.\nEach row in the template represents a sequencing library with a unique combination of sample + library + sequencing strategy + layout + instrument model. Each row should have a unique library_id that is short and meaningful (like an ID you might use in lab).\nWhen libraries are indeed identical (same combination of sample + library + strategy + layout + instrument model), all files should be placed in the same row To do this simply enter the file names consecutively in the same row by adding more columns with headers filename2, filename3, etc…. PAIRED files must always be listed in the same row.\nsample_name - must match exactly the sample_name in the tables above\nlibrary_id - each must be unique, should be short like what is in a samplesheet\ntitle - Short description that will identify the dataset on public pages. A clear and concise formula for the title would be like: {methodology} of {organism}: {sample info} _e.g. RNA-Seq of mus musculus:adult female spleen\nlibrary_strategy - what the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\nlibrary_source - Source of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\nlibrary_selection - how amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\nlibrary_layout (MixS equivalent lib_layout) - Specify whether to expect single, paired, or other configuration of reads\nplatform (MixS equivalent is part of seq_meth) - Machine used to sequence data, should be one from https://ontobee.org/ontology/OBI?iri=http://purl.obolibrary.org/obo/OBI_0400103\ninstrument_model (MixS equivalent is part of seq_meth) - The specific model of the machine above\ndesign_description - A short description of how sequencing was done, paragraph style\nfiletype and filenames - the type of file and the names of the files associated with the sequencing"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#gsc-mixs-standards",
    "href": "format/DevelopmentOfFormat.html#gsc-mixs-standards",
    "title": "Development of Format",
    "section": "",
    "text": "https://genomicsstandardsconsortium.github.io/mixs/0010002/\n\nCodeMigsEu_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MigsEu_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MigsEu_v6.2.0_fields)\n\n\n\n\nCodeMigsEu_v6.2.0_fields  = MigsEu_v6.2.0_fields%&gt;% \n  mutate(in_MigsEu_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0016003/\n\nCodeHumanAssociated_v6.2.0_fields = readr::read_tsv(\"mixs_standards/HumanAssociated_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(HumanAssociated_v6.2.0_fields)\n\n\n\n\nCodeHumanAssociated_v6.2.0_fields  = HumanAssociated_v6.2.0_fields%&gt;% \n  mutate(in_HumanAssociated_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009/\n\nCodeMimarksC_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MimarksC_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MimarksC_v6.2.0_fields)\n\n\n\n\nCodeMimarksC_v6.2.0_fields  = MimarksC_v6.2.0_fields%&gt;% \n  mutate(in_MimarksC_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\n\n\nCodeall_mixs_fields = MigsEu_v6.2.0_fields %&gt;% \n  full_join(MimarksC_v6.2.0_fields) %&gt;% \n  full_join(HumanAssociated_v6.2.0_fields) %&gt;% \n  arrange(fields) %&gt;% \n  mutate(in_both_MigsEu_MimarksC = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0)%&gt;% \n  mutate(in_all_three = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0 & in_HumanAssociated_v6.2.0)\ncreate_dt(all_mixs_fields)"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#pmo-sample-and-sequencing-fields",
    "href": "format/DevelopmentOfFormat.html#pmo-sample-and-sequencing-fields",
    "title": "Development of Format",
    "section": "",
    "text": "The fields choices for PMO took into consideration the Mixs standards, SRA standards, and from other similar amplicon standards (which are also based on Mixs standards), Environmental System Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE) and National Microbiome Data Collaborative (NMDC)\nThe SRA takes two tables, one defining bio samples and one defining sequencing experiment libraries done on those bio samples of which there could be multiple sequencing experiments. Therefore the decision was made to also create two separate data sections for defining a biosample (specimen_info) and one defining experiments on those specimens (library_sample_info), this allows the mirroring of SRA as well as allowing for storing replicates of a single specimen. A 3rd section was created to store redundant sequencing info (sequencing_info).\n\nComparing the specimen_info fields to the MIXS standard and SRA. Please see specimen_info in FormatOverview for short description of each pmo field and above for the SRA fields\n\nCodecreate_dt(readr::read_tsv(\"specimen_info_field_comparison.tsv\"))\n\n\n\n\n\n\nComparing the sequencing_info and library_sample_info fields to the Mixs standards and the data required for SRA submission above\n\nCodecreate_dt(readr::read_tsv(\"library_and_sequencing_field_comparison.tsv\"))"
  },
  {
    "objectID": "pmotools-python-usages/pmotools-python.html",
    "href": "pmotools-python-usages/pmotools-python.html",
    "title": "Command line interface to pmotools-python with pmotools-python",
    "section": "",
    "text": "See installation instruction page for how to install pmotools-python which comes with a commandline interface called pmotools-python\n\nCodepmotools-python\n\n\n\n\npmotools-python v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (PMO) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert Excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to a JSON file\n    terra_amp_output_to_json - Convert Terra output to JSON sequence table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract samples + haplotypes using selected meta\n    extract_pmo_with_select_specimen_names - Extract specific samples from the specimens table\n    extract_pmo_with_select_library_sample_names - Extract experiment sample names from experiment_info table\n    extract_pmo_with_select_targets - Extract specific targets\n    extract_pmo_with_read_filter - Extract with a read filter\n    extract_allele_table - Extract allele tables for tools like dcifer or moire\n    extract_insert_of_panels - Extract inserts of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract ref_seq of panel inserts from a PMO\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple PMOs of the same panel\n\nextract_basic_info_from_pmo\n    list_library_sample_names_per_specimen_name - List experiment_sample_ids per specimen_id\n    list_specimen_meta_fields - List specimen meta fields in the specimen_info section\n    list_bioinformatics_run_names - List all tar_amp_bioinformatics_info_ids in a PMO\n    count_specimen_meta - Count values of selected specimen meta fields\n    count_targets_per_library_sample - Count number of targets per sample\n    count_library_samples_per_target - Count number of samples per target\n\nvalidation\n    validate_pmo - Validate a PMO file against a JSON Schema"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html",
    "href": "pmotools-python-usages/subsetting_from_PMO.html",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "There may be some instances were you want to subset a much larger PMO file into a smaller PMO file to focus only one a set of samples and/or targets. There are several ways of doing this.\n\nCan subset to only specific targets by using pmotools-python extract_pmo_with_select_targets\n\nCodepmotools-python extract_pmo_with_select_targets -h\n\nusage: pmotools-python extract_pmo_with_select_targets [-h] --file FILE\n                                                       --output OUTPUT\n                                                       [--overwrite]\n                                                       [--verbose] --targets\n                                                       TARGETS\n\noptions:\n  -h, --help         show this help message and exit\n  --file FILE        PMO file\n  --output OUTPUT    Output json file path\n  --overwrite        If output file exists, overwrite it\n  --verbose          write out various messages about extraction\n  --targets TARGETS  Can either comma separated target_namess, or a plain text\n                     file where each line is a target_namess\n\n\nThe python code for extract_pmo_with_select_targets script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_targets.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_targets():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--targets\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated target_namess, or a plain text file where each line is a target_namess\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_targets():\n    args = parse_args_extract_pmo_with_select_targets()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse target names\n    all_target_names = Utils.parse_delimited_input_or_file(args.targets)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_target_names(pmo, all_target_names)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_targets()\n\n\n\nYou can extract by supplies the desired targets with comma separated values on the command line\n\nCodecd example \n\npmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets t1,t20,t31  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\nYou can also provide a single column file where each line is a desired target\n\nCodecd example \n\necho -e \"t1\\nt20\\nt31\" &gt; select_targets.txt \npmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets select_targets.txt  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\necho -e \"t1\\nt20\\nt31\" | pmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets STDIN --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\n\nYou can subset to just to just select specimen_name, each specimen can have several experiments associated with it, by supplying the specimen_name all associated experiments will also be pulled\nSimilar to above you can supply the specimen_names either as comma separated values or in a plain text file where each line is a specimen_name\n\nCodepmotools-python extract_pmo_with_select_specimen_names -h\n\nusage: pmotools-python extract_pmo_with_select_specimen_names\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --specimen_names SPECIMEN_NAMES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --specimen_names SPECIMEN_NAMES\n                        Can either comma separated specimen_names, or a plain\n                        text file where each line is a specimen_name\n\n\nThe python code for extract_pmo_with_select_specimen_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_specimen_names.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_specimen_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--specimen_names\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated specimen_names, or a plain text file where each line is a specimen_name\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_specimen_names():\n    args = parse_args_extract_pmo_with_select_specimen_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen names\n    all_specimen_names = Utils.parse_delimited_input_or_file(args.specimen_names)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_specimen_names(pmo, all_specimen_names)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_specimen_names()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_select_specimen_names --specimen_names 8025874217,8025875146,8034209589 --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" &gt; select_specimen_names.txt \n\npmotools-python extract_pmo_with_select_specimen_names --specimen_names select_specimen_names.txt --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" | pmotools-python extract_pmo_with_select_specimen_names --specimen_names STDIN --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\n\n\nIf you want just specific library_sample_name you can supply those instead too\nSimilar to above you can supply the library_sample_names either as comma separated values or in a plain text file where each line is a library_sample_name or from standard in (STDIN)\n\nCodepmotools-python extract_pmo_with_select_library_sample_names -h\n\nusage: pmotools-python extract_pmo_with_select_library_sample_names\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --library_sample_names LIBRARY_SAMPLE_NAMES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --library_sample_names LIBRARY_SAMPLE_NAMES\n                        Can either comma separated library_sample_names, or a\n                        plain text file where each line is a\n                        library_sample_name\n\n\nThe python code for extract_pmo_with_select_library_sample_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_library_sample_names.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_library_sample_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--library_sample_names\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated library_sample_names, or a plain text file where each line is a library_sample_name\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_library_sample_names():\n    args = parse_args_extract_pmo_with_select_library_sample_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen names\n    all_library_sample_names = set(\n        Utils.parse_delimited_input_or_file(args.library_sample_names)\n    )\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_library_sample_names(\n        pmo, all_library_sample_names\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_library_sample_names()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_select_library_sample_names --library_sample_names 8025875029,8034209834,8034209115 --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025875029\\n8034209834\\n8034209115\" &gt; select_library_sample_names.txt \n  \npmotools-python extract_pmo_with_select_library_sample_names --library_sample_names select_library_sample_names.txt --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\n\nIf you want to get specific samples that match certain meta fields like specific collection_country or collection_date you can use ``\n\nCodepmotools-python extract_pmo_with_selected_meta -h \n\nusage: pmotools-python extract_pmo_with_selected_meta [-h] --file FILE\n                                                      --output OUTPUT\n                                                      [--overwrite]\n                                                      [--verbose]\n                                                      --metaFieldsValues\n                                                      METAFIELDSVALUES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --metaFieldsValues METAFIELDSVALUES\n                        Meta Fields to include, should either be a table with\n                        columns field, values (and optionally group) or\n                        supplied command line as\n                        field1=value1,value2,value3:field2=value1,value2\n\n\nThe python code for extract_pmo_with_selected_meta script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_selected_meta.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_selected_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--metaFieldsValues\",\n        type=str,\n        required=True,\n        help=\"Meta Fields to include, should either be a table with columns field, values (and optionally group) or supplied command line as field1=value1,value2,value3:field2=value1,value2\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_selected_meta():\n    args = parse_args_extract_pmo_with_selected_meta()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract out of PMO\n    pmo_out, group_counts = PMOProcessor.extract_from_pmo_samples_with_meta_groupings(\n        pmo, args.metaFieldsValues\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n    if args.verbose:\n        sys.stdout.write(\n            \"Extracted the following number of specimens per group:\" + \"\\n\"\n        )\n        group_counts.to_csv(sys.stdout, sep=\"\\t\", index=True)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_selected_meta()\n\n\n\npmotools-python extract_pmo_with_selected_meta is written to allow the extraction on multiple intersecting meta field requirments that can be either supplied in a file or with delimited on the command line\nYou may also want to know what current meta fields are present and how many samples in each. This can be done with pmotools-python list_specimen_meta_fields and pmotools-python count_specimen_meta\n\nCodecd example \nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/PathWeaverHeome1_PMO.json.gz\n\nfield   present_in_specimens_count  total_specimen_count\ncollection_country  19433   19433\ncollection_date 19433   19433\ngeo_admin3  19433   19433\nhost_taxon_id   19433   19433\nproject_id  19433   19433\nspecimen_collect_device 19433   19433\nspecimen_name   19433   19433\nspecimen_store_loc  19433   19433\nspecimen_taxon_id   19433   19433\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz  --meta_fields collection_country,collection_date | head -20\n\ncollection_country  collection_date specimens_count specimens_freq  total_specimen_count\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    8   0.0004116708691401225   19433\nBangladesh  2012-04-19  1   5.145885864251531e-05   19433\nBangladesh  2012-06-05  2   0.00010291771728503062  19433\nBangladesh  2012-06-13  1   5.145885864251531e-05   19433\nBangladesh  2012-06-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-23  1   5.145885864251531e-05   19433\nBangladesh  2012-07-25  1   5.145885864251531e-05   19433\nBangladesh  2012-08-11  1   5.145885864251531e-05   19433\nBangladesh  2012-08-27  1   5.145885864251531e-05   19433\nBangladesh  2012-08-28  1   5.145885864251531e-05   19433\nBangladesh  2012-09-10  1   5.145885864251531e-05   19433\nBangladesh  2012-09-12  1   5.145885864251531e-05   19433\nBangladesh  2012-09-17  1   5.145885864251531e-05   19433\nBangladesh  2012-09-18  1   5.145885864251531e-05   19433\nBangladesh  2012-09-19  1   5.145885864251531e-05   19433\nBangladesh  2012-09-22  1   5.145885864251531e-05   19433\nTraceback (most recent call last):\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/bin/pmotools-python\", line 8, in &lt;module&gt;\n    sys.exit(main())\n             ^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/cli.py\", line 382, in main\n    handler()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\", line 61, in count_specimen_meta\n    counts_df.to_csv(\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/core/generic.py\", line 3967, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/format.py\", line 1014, in to_csv\n    csv_formatter.save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 270, in save\n    self._save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 275, in _save\n    self._save_body()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 313, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 324, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"writers.pyx\", line 73, in pandas._libs.writers.write_csv_rows\nBrokenPipeError: [Errno 32] Broken pipe\nException ignored in: &lt;_io.TextIOWrapper name='&lt;stdout&gt;' mode='w' encoding='utf-8'&gt;\nBrokenPipeError: [Errno 32] Broken pipe\n\n\nExtracting on matching 1 meta field, below will extract just the samples that have collection_country=Bangladesh\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite\n\n\nIf you want to see how many samples were extracted can use --verbose\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite --verbose\n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh  1418\n\n\nCollecting more than 1 matching field separate by comma, for example to extract both Bangladesh,Benin\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin\" --output Bangladesh_Benin_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh,Benin    1576\n\n\nCan add more extraction criteria meta, for example to extract samples with collection_country of Bangladesh or Benin and with collection_date of 2016\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin:collection_date=2016\" --output Bangladesh_Benin_2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh,Benin    2016    933\n\n\nTo get more specific you can group meta field extraction criteria , for example if you wanted samples from Bangladesh from year 2015 but wanted Benin from year 2016 you can separate by a ;\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh:collection_date=2015;collection_country=Benin:collection_date=2016\" --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh  2015    508\n1   Benin   2016    117\n\n\nRather than supplying with the command line a file can be created\n\nCodecd example \n\necho -e \"group\\tfield\\tvalues\" &gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_country\\tBangladesh\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_date\\t2015\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_country\\tBenin\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_date\\t2016\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \n\n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues Bangladesh2015_Benin2016_extractionCriteria.tsv --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\nBangladesh2015  Bangladesh  2015    508\nBenin2016   Benin   2016    117\n\n\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/moz2018_PMO.json.gz --metaFieldsValues \"collection_country=Mozambique:geo_admin3=Inhassoro;collection_country=Mozambique:geo_admin3=Mandlakazi,Namaacha\" --output Mozambique_moz2018_PMO.json.gz  --verbose  --overwrite\n\nExtracted the following number of specimens per group:\ngroup   collection_country  geo_admin3  count\n0   Mozambique  Inhassoro   27\n1   Mozambique  Mandlakazi,Namaacha 54\n\n\n\n\nCodepmotools-python extract_pmo_with_read_filter -h\n\nusage: pmotools-python extract_pmo_with_read_filter [-h] --file FILE --output\n                                                    OUTPUT [--overwrite]\n                                                    --read_count_minimum\n                                                    READ_COUNT_MINIMUM\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) for detected\n                        haplotypes to be kept\n\n\nThe python code for extract_pmo_with_read_filter script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_read_filter.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_read_filter():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=True,\n        help=\"the minimum read count (inclusive) for detected haplotypes to be kept\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_read_filter():\n    args = parse_args_extract_pmo_with_read_filter()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.extract_from_pmo_with_read_filter(\n        pmo, args.read_count_minimum\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_read_filter()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_minReadCount1000.json.gz --overwrite\n\n\n\nThe extraction methods also allow for STDOUT and STDIN piping for example\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\nCan also pipe into other pmotools-python functions like extracting allele tables\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-python extract_allele_table --file STDIN --output alleles_data_t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.tsv.gz --overwrite\n\n\nCan pipe final output to STDOUT as well for further processing\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-python extract_allele_table --file STDIN --output STDOUT  --specimen_info_meta_fields specimen_name,collection_country\n\nbioinformatics_run_name library_sample_name target_name mhap_id specimen_name   collection_country\nMozambique2018-SeekDeep 8034209115  t31 1   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t31 3   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t20 4   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t20 1   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t1  2   8034209115  Mozambique\nMozambique2018-SeekDeep 8025875029  t31 1   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t31 3   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 3   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 5   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 4   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t1  0   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t1  1   8025875029  Mozambique\nMozambique2018-SeekDeep 8034209834  t31 2   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t31 0   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t20 1   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t20 0   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t1  0   8034209834  Mozambique\n\n\nfilter to a read amount and then write allele table\n\nCodecd example \n\npmotools-python extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_allele_table --file STDIN --output moz2018_PMO_minReadCount1000_allele_table.tsv.gz  --microhap_fields reads --representative_haps_fields seq --default_base_col_names specimen_name,target_id,allele --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-targets",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-targets",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "Can subset to only specific targets by using pmotools-python extract_pmo_with_select_targets\n\nCodepmotools-python extract_pmo_with_select_targets -h\n\nusage: pmotools-python extract_pmo_with_select_targets [-h] --file FILE\n                                                       --output OUTPUT\n                                                       [--overwrite]\n                                                       [--verbose] --targets\n                                                       TARGETS\n\noptions:\n  -h, --help         show this help message and exit\n  --file FILE        PMO file\n  --output OUTPUT    Output json file path\n  --overwrite        If output file exists, overwrite it\n  --verbose          write out various messages about extraction\n  --targets TARGETS  Can either comma separated target_namess, or a plain text\n                     file where each line is a target_namess\n\n\nThe python code for extract_pmo_with_select_targets script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_targets.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_targets():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--targets\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated target_namess, or a plain text file where each line is a target_namess\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_targets():\n    args = parse_args_extract_pmo_with_select_targets()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse target names\n    all_target_names = Utils.parse_delimited_input_or_file(args.targets)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_target_names(pmo, all_target_names)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_targets()\n\n\n\nYou can extract by supplies the desired targets with comma separated values on the command line\n\nCodecd example \n\npmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets t1,t20,t31  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\nYou can also provide a single column file where each line is a desired target\n\nCodecd example \n\necho -e \"t1\\nt20\\nt31\" &gt; select_targets.txt \npmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets select_targets.txt  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\necho -e \"t1\\nt20\\nt31\" | pmotools-python extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets STDIN --output t1_t20_t31_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-specimen_names",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-specimen_names",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "You can subset to just to just select specimen_name, each specimen can have several experiments associated with it, by supplying the specimen_name all associated experiments will also be pulled\nSimilar to above you can supply the specimen_names either as comma separated values or in a plain text file where each line is a specimen_name\n\nCodepmotools-python extract_pmo_with_select_specimen_names -h\n\nusage: pmotools-python extract_pmo_with_select_specimen_names\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --specimen_names SPECIMEN_NAMES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --specimen_names SPECIMEN_NAMES\n                        Can either comma separated specimen_names, or a plain\n                        text file where each line is a specimen_name\n\n\nThe python code for extract_pmo_with_select_specimen_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_specimen_names.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_specimen_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--specimen_names\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated specimen_names, or a plain text file where each line is a specimen_name\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_specimen_names():\n    args = parse_args_extract_pmo_with_select_specimen_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen names\n    all_specimen_names = Utils.parse_delimited_input_or_file(args.specimen_names)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_specimen_names(pmo, all_specimen_names)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_specimen_names()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_select_specimen_names --specimen_names 8025874217,8025875146,8034209589 --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" &gt; select_specimen_names.txt \n\npmotools-python extract_pmo_with_select_specimen_names --specimen_names select_specimen_names.txt --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" | pmotools-python extract_pmo_with_select_specimen_names --specimen_names STDIN --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-library_sample_names",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-library_sample_names",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "If you want just specific library_sample_name you can supply those instead too\nSimilar to above you can supply the library_sample_names either as comma separated values or in a plain text file where each line is a library_sample_name or from standard in (STDIN)\n\nCodepmotools-python extract_pmo_with_select_library_sample_names -h\n\nusage: pmotools-python extract_pmo_with_select_library_sample_names\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --library_sample_names LIBRARY_SAMPLE_NAMES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --library_sample_names LIBRARY_SAMPLE_NAMES\n                        Can either comma separated library_sample_names, or a\n                        plain text file where each line is a\n                        library_sample_name\n\n\nThe python code for extract_pmo_with_select_library_sample_names script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_select_library_sample_names.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_library_sample_names():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--library_sample_names\",\n        type=str,\n        required=True,\n        help=\"Can either comma separated library_sample_names, or a plain text file where each line is a library_sample_name\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_select_library_sample_names():\n    args = parse_args_extract_pmo_with_select_library_sample_names()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen names\n    all_library_sample_names = set(\n        Utils.parse_delimited_input_or_file(args.library_sample_names)\n    )\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.filter_pmo_by_library_sample_names(\n        pmo, all_library_sample_names\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_library_sample_names()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_select_library_sample_names --library_sample_names 8025875029,8034209834,8034209115 --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025875029\\n8034209834\\n8034209115\" &gt; select_library_sample_names.txt \n  \npmotools-python extract_pmo_with_select_library_sample_names --library_sample_names select_library_sample_names.txt --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-samples-within-specific-metafields",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-samples-within-specific-metafields",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "If you want to get specific samples that match certain meta fields like specific collection_country or collection_date you can use ``\n\nCodepmotools-python extract_pmo_with_selected_meta -h \n\nusage: pmotools-python extract_pmo_with_selected_meta [-h] --file FILE\n                                                      --output OUTPUT\n                                                      [--overwrite]\n                                                      [--verbose]\n                                                      --metaFieldsValues\n                                                      METAFIELDSVALUES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --metaFieldsValues METAFIELDSVALUES\n                        Meta Fields to include, should either be a table with\n                        columns field, values (and optionally group) or\n                        supplied command line as\n                        field1=value1,value2,value3:field2=value1,value2\n\n\nThe python code for extract_pmo_with_selected_meta script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_selected_meta.py\n\n#!/usr/bin/env python3\nimport argparse\nimport sys\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_selected_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--verbose\",\n        action=\"store_true\",\n        help=\"write out various messages about extraction\",\n    )\n    parser.add_argument(\n        \"--metaFieldsValues\",\n        type=str,\n        required=True,\n        help=\"Meta Fields to include, should either be a table with columns field, values (and optionally group) or supplied command line as field1=value1,value2,value3:field2=value1,value2\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_selected_meta():\n    args = parse_args_extract_pmo_with_selected_meta()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract out of PMO\n    pmo_out, group_counts = PMOProcessor.extract_from_pmo_samples_with_meta_groupings(\n        pmo, args.metaFieldsValues\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n    if args.verbose:\n        sys.stdout.write(\n            \"Extracted the following number of specimens per group:\" + \"\\n\"\n        )\n        group_counts.to_csv(sys.stdout, sep=\"\\t\", index=True)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_selected_meta()\n\n\n\npmotools-python extract_pmo_with_selected_meta is written to allow the extraction on multiple intersecting meta field requirments that can be either supplied in a file or with delimited on the command line\nYou may also want to know what current meta fields are present and how many samples in each. This can be done with pmotools-python list_specimen_meta_fields and pmotools-python count_specimen_meta\n\nCodecd example \nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodecd example \npmotools-python list_specimen_meta_fields --file ../../format/PathWeaverHeome1_PMO.json.gz\n\nfield   present_in_specimens_count  total_specimen_count\ncollection_country  19433   19433\ncollection_date 19433   19433\ngeo_admin3  19433   19433\nhost_taxon_id   19433   19433\nproject_id  19433   19433\nspecimen_collect_device 19433   19433\nspecimen_name   19433   19433\nspecimen_store_loc  19433   19433\nspecimen_taxon_id   19433   19433\n\n\n\nCodecd example \npmotools-python count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz  --meta_fields collection_country,collection_date | head -20\n\ncollection_country  collection_date specimens_count specimens_freq  total_specimen_count\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    8   0.0004116708691401225   19433\nBangladesh  2012-04-19  1   5.145885864251531e-05   19433\nBangladesh  2012-06-05  2   0.00010291771728503062  19433\nBangladesh  2012-06-13  1   5.145885864251531e-05   19433\nBangladesh  2012-06-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-17  1   5.145885864251531e-05   19433\nBangladesh  2012-07-23  1   5.145885864251531e-05   19433\nBangladesh  2012-07-25  1   5.145885864251531e-05   19433\nBangladesh  2012-08-11  1   5.145885864251531e-05   19433\nBangladesh  2012-08-27  1   5.145885864251531e-05   19433\nBangladesh  2012-08-28  1   5.145885864251531e-05   19433\nBangladesh  2012-09-10  1   5.145885864251531e-05   19433\nBangladesh  2012-09-12  1   5.145885864251531e-05   19433\nBangladesh  2012-09-17  1   5.145885864251531e-05   19433\nBangladesh  2012-09-18  1   5.145885864251531e-05   19433\nBangladesh  2012-09-19  1   5.145885864251531e-05   19433\nBangladesh  2012-09-22  1   5.145885864251531e-05   19433\nTraceback (most recent call last):\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/bin/pmotools-python\", line 8, in &lt;module&gt;\n    sys.exit(main())\n             ^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/cli.py\", line 382, in main\n    handler()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/pmotools-python/src/pmotools/scripts/extract_info_from_pmo/count_specimen_meta.py\", line 61, in count_specimen_meta\n    counts_df.to_csv(\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/core/generic.py\", line 3967, in to_csv\n    return DataFrameRenderer(formatter).to_csv(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/format.py\", line 1014, in to_csv\n    csv_formatter.save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 270, in save\n    self._save()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 275, in _save\n    self._save_body()\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 313, in _save_body\n    self._save_chunk(start_i, end_i)\n  File \"/Users/nicholashathaway/projects/plasmodium/falciparum/PMO_Docs_for_deploying/PMO_Docs/env/lib/python3.12/site-packages/pandas/io/formats/csvs.py\", line 324, in _save_chunk\n    libwriters.write_csv_rows(\n  File \"writers.pyx\", line 73, in pandas._libs.writers.write_csv_rows\nBrokenPipeError: [Errno 32] Broken pipe\nException ignored in: &lt;_io.TextIOWrapper name='&lt;stdout&gt;' mode='w' encoding='utf-8'&gt;\nBrokenPipeError: [Errno 32] Broken pipe\n\n\nExtracting on matching 1 meta field, below will extract just the samples that have collection_country=Bangladesh\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite\n\n\nIf you want to see how many samples were extracted can use --verbose\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite --verbose\n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh  1418\n\n\nCollecting more than 1 matching field separate by comma, for example to extract both Bangladesh,Benin\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin\" --output Bangladesh_Benin_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh,Benin    1576\n\n\nCan add more extraction criteria meta, for example to extract samples with collection_country of Bangladesh or Benin and with collection_date of 2016\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin:collection_date=2016\" --output Bangladesh_Benin_2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh,Benin    2016    933\n\n\nTo get more specific you can group meta field extraction criteria , for example if you wanted samples from Bangladesh from year 2015 but wanted Benin from year 2016 you can separate by a ;\n\nCodecd example \n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh:collection_date=2015;collection_country=Benin:collection_date=2016\" --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh  2015    508\n1   Benin   2016    117\n\n\nRather than supplying with the command line a file can be created\n\nCodecd example \n\necho -e \"group\\tfield\\tvalues\" &gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_country\\tBangladesh\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_date\\t2015\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_country\\tBenin\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_date\\t2016\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \n\n\npmotools-python extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues Bangladesh2015_Benin2016_extractionCriteria.tsv --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\nBangladesh2015  Bangladesh  2015    508\nBenin2016   Benin   2016    117\n\n\n\nCodecd example \npmotools-python extract_pmo_with_selected_meta  --file ../../format/moz2018_PMO.json.gz --metaFieldsValues \"collection_country=Mozambique:geo_admin3=Inhassoro;collection_country=Mozambique:geo_admin3=Mandlakazi,Namaacha\" --output Mozambique_moz2018_PMO.json.gz  --verbose  --overwrite\n\nExtracted the following number of specimens per group:\ngroup   collection_country  geo_admin3  count\n0   Mozambique  Inhassoro   27\n1   Mozambique  Mandlakazi,Namaacha 54"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-a-read-filter-for-detected-microhaplotypes",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-a-read-filter-for-detected-microhaplotypes",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "Codepmotools-python extract_pmo_with_read_filter -h\n\nusage: pmotools-python extract_pmo_with_read_filter [-h] --file FILE --output\n                                                    OUTPUT [--overwrite]\n                                                    --read_count_minimum\n                                                    READ_COUNT_MINIMUM\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) for detected\n                        haplotypes to be kept\n\n\nThe python code for extract_pmo_with_read_filter script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extractors_from_pmo/extract_pmo_with_read_filter.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_writer import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_read_filter():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, required=True, help=\"Output json file path\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--read_count_minimum\",\n        default=0.0,\n        type=float,\n        required=True,\n        help=\"the minimum read count (inclusive) for detected haplotypes to be kept\",\n    )\n    return parser.parse_args()\n\n\ndef extract_pmo_with_read_filter():\n    args = parse_args_extract_pmo_with_read_filter()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOProcessor.extract_from_pmo_with_read_filter(\n        pmo, args.read_count_minimum\n    )\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(\n        args.output, args.file.endswith(\".gz\") or args.output.endswith(\".gz\")\n    )\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_read_filter()\n\n\n\n\nCodecd example \n\npmotools-python extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_minReadCount1000.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#piping-together-extraction",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#piping-together-extraction",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "The extraction methods also allow for STDOUT and STDIN piping for example\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\nCan also pipe into other pmotools-python functions like extracting allele tables\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-python extract_allele_table --file STDIN --output alleles_data_t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.tsv.gz --overwrite\n\n\nCan pipe final output to STDOUT as well for further processing\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-python extract_pmo_with_select_library_sample_names --library_sample_names STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-python extract_allele_table --file STDIN --output STDOUT  --specimen_info_meta_fields specimen_name,collection_country\n\nbioinformatics_run_name library_sample_name target_name mhap_id specimen_name   collection_country\nMozambique2018-SeekDeep 8034209115  t31 1   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t31 3   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t20 4   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t20 1   8034209115  Mozambique\nMozambique2018-SeekDeep 8034209115  t1  2   8034209115  Mozambique\nMozambique2018-SeekDeep 8025875029  t31 1   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t31 3   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 3   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 5   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t20 4   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t1  0   8025875029  Mozambique\nMozambique2018-SeekDeep 8025875029  t1  1   8025875029  Mozambique\nMozambique2018-SeekDeep 8034209834  t31 2   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t31 0   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t20 1   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t20 0   8034209834  Mozambique\nMozambique2018-SeekDeep 8034209834  t1  0   8034209834  Mozambique\n\n\nfilter to a read amount and then write allele table\n\nCodecd example \n\npmotools-python extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-python extract_allele_table --file STDIN --output moz2018_PMO_minReadCount1000_allele_table.tsv.gz  --microhap_fields reads --representative_haps_fields seq --default_base_col_names specimen_name,target_id,allele --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/validating_pmos.html",
    "href": "pmotools-python-usages/validating_pmos.html",
    "title": "Validating PMOs pmotools-python",
    "section": "",
    "text": "pmotools-python validate_pmo\nCan download multiple PMOs here\nhttps://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nhttps://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\nCodepmotools-python validate_pmo --help\n\nusage: pmotools-python validate_pmo [-h] --pmo PMO\n                                    [--jsonschema_file JSONSCHEMA_FILE]\n\noptions:\n  -h, --help            show this help message and exit\n  --pmo PMO             a pmo file to validate\n  --jsonschema_file JSONSCHEMA_FILE\n                        jsonschema to validate against\n\n\nUse this validate a PMO file that follows the standard format, by default will use the schema that is within the pmotools-python directory\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\n\n\npmotools-python validate_pmo --pmo moz2018_PMO.json.gz\n\n\nCan also use specific jsonschema file\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/portable_microhaplotype_object.schema.json\n\n\npmotools-python validate_pmo --pmo moz2018_PMO.json.gz --jsonschema_file portable_microhaplotype_object.schema.json\n\n\nThe python code for validate_pmo script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/pmo_utils/validate_pmo.py\n\n#!/usr/bin/env python3\nimport os\nimport argparse\nimport json\n\n\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.pmo_engine.pmo_checker import PMOChecker\nfrom pmotools.utils.small_utils import Utils\nfrom pmotools import __version__ as __pmotools_version__\n\n\ndef parse_args_validate_pmo():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--pmo\", type=str, required=True, help=\"a pmo file to validate\")\n    parser.add_argument(\n        \"--jsonschema_file\",\n        default=os.path.join(\n            os.path.dirname(\n                os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n            ),\n            \"schemas/\",\n            f\"portable_microhaplotype_object_v{__pmotools_version__}.schema.json\",\n        ),\n        type=str,\n        required=False,\n        help=\"jsonschema to validate against\",\n    )\n\n    return parser.parse_args()\n\n\ndef validate_pmo():\n    args = parse_args_validate_pmo()\n\n    # read in the PMO\n    pmo = PMOReader.read_in_pmo(args.pmo)\n\n    # create checker\n    with Utils.smart_open_read_by_ext(args.jsonschema_file) as f:\n        checker = PMOChecker(json.load(f))\n        # validate\n        checker.validate_pmo_json(pmo)\n\n\nif __name__ == \"__main__\":\n    validate_pmo()"
  },
  {
    "objectID": "pmotools-python-usages/extracting_panel_info_from_pmo.html",
    "href": "pmotools-python-usages/extracting_panel_info_from_pmo.html",
    "title": "Getting panel info out of PMO using pmotools-python",
    "section": "",
    "text": "Most of these basic panel info can be found underneath extract_panel_info_from_pmo\n\nCodepmotools-python\n\n\n\n\npmotools-python v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (PMO) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert Excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to a JSON file\n    terra_amp_output_to_json - Convert Terra output to JSON sequence table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract samples + haplotypes using selected meta\n    extract_pmo_with_select_specimen_names - Extract specific samples from the specimens table\n    extract_pmo_with_select_library_sample_names - Extract experiment sample names from experiment_info table\n    extract_pmo_with_select_targets - Extract specific targets\n    extract_pmo_with_read_filter - Extract with a read filter\n    extract_allele_table - Extract allele tables for tools like dcifer or moire\n    extract_insert_of_panels - Extract inserts of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract ref_seq of panel inserts from a PMO\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple PMOs of the same panel\n\nextract_basic_info_from_pmo\n    list_library_sample_names_per_specimen_name - List experiment_sample_ids per specimen_id\n    list_specimen_meta_fields - List specimen meta fields in the specimen_info section\n    list_bioinformatics_run_names - List all tar_amp_bioinformatics_info_ids in a PMO\n    count_specimen_meta - Count values of selected specimen meta fields\n    count_targets_per_library_sample - Count number of targets per sample\n    count_library_samples_per_target - Count number of samples per target\n\nvalidation\n    validate_pmo - Validate a PMO file against a JSON Schema\n\n\nGetting files for examples\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\nExtract insert locations of panels from PMO\nThis will extract the insert location of targets of the panel infos out of a PMO and write it out as a bed file\n\nCodepmotools-python extract_insert_of_panels -h \n\nusage: pmotools-python extract_insert_of_panels [-h] --file FILE\n                                                [--output OUTPUT]\n                                                [--overwrite] [--add_ref_seqs]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n  --add_ref_seqs   add ref seqs to the output as ref_seq\n\n\nThe python code for extract_insert_of_panels script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/extract_insert_of_panels.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_insert_of_panels():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.add_argument(\n        \"--add_ref_seqs\",\n        action=\"store_true\",\n        help=\"add ref seqs to the output as ref_seq\",\n    )\n\n    return parser.parse_args()\n\n\ndef extract_insert_of_panels():\n    args = parse_args_extract_insert_of_panels()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # get panel insert locations\n    panel_bed_locs = PMOProcessor.extract_panels_insert_bed_loc(pmo)\n\n    # write\n    with Utils.smart_open_write(args.output) as f:\n        f.write(\n            \"\\t\".join(\n                [\n                    \"#chrom\",\n                    \"start\",\n                    \"end\",\n                    \"target_id\",\n                    \"length\",\n                    \"strand\",\n                    \"extra_info\",\n                ]\n            )\n        )\n        if args.add_ref_seqs:\n            f.write(\"\\tref_seq\")\n        f.write(\"\\n\")\n        for loc in panel_bed_locs:\n            f.write(\n                \"\\t\".join(\n                    [\n                        loc.chrom,\n                        str(loc.start),\n                        str(loc.end),\n                        loc.name,\n                        str(loc.score),\n                        loc.strand,\n                        loc.extra_info,\n                    ]\n                )\n            )\n            if args.add_ref_seqs:\n                f.write(\"\\t\" + str(loc.ref_seq))\n            f.write(\"\\n\")\n\n\nif __name__ == \"__main__\":\n    extract_insert_of_panels()\n\n\n\n\nCodecd example \npmotools-python extract_insert_of_panels --file ../../format/moz2018_PMO.json.gz\n\n#chrom  start   end target_id   length  strand  extra_info\nPf3D7_01_v3 145449  145622  t1  173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 179903  180115  t2  212 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 181557  181673  t3  116 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 495971  496143  t4  172 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 512199  512388  t5  189 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 531682  531900  t6  218 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 532690  532844  t7  154 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 534215  534368  t8  153 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_01_v3 534941  535110  t9  169 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_02_v3 109807  109982  t10 175 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_02_v3 278165  278336  t11 171 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_02_v3 470492  470676  t12 184 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_02_v3 805822  805942  t13 120 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 85440   85646   t14 206 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 141963  142181  t15 218 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 221363  221495  t16 132 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 618396  618581  t17 185 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 654002  654175  t18 173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_03_v3 850816  850989  t19 173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 109912  110087  t20 175 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 133491  133701  t21 210 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 141778  141945  t22 167 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 415653  415826  t23 173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 544718  544861  t24 143 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 748230  748436  t25 206 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 748533  748696  t26 163 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 802525  802713  t27 188 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 1037634 1037844 t28 210 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 1100656 1100831 t29 175 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 1102389 1102578 t30 189 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 1113450 1113604 t31 154 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_04_v3 1128489 1128673 t32 184 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_05_v3 329378  329550  t33 172 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_05_v3 958059  958221  t34 162 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_05_v3 958389  958506  t35 117 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_05_v3 1042162 1042281 t36 119 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_05_v3 1309609 1309744 t37 135 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_06_v3 145343  145501  t38 158 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_06_v3 532195  532378  t39 183 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 165235  165422  t40 187 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 166035  166167  t41 132 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 298886  299005  t42 119 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 729975  730088  t43 113 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 1149415 1149585 t44 170 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_07_v3 1358694 1358911 t45 217 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 102326  102500  t46 174 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 336468  336647  t47 179 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 339168  339357  t48 189 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 549993  550218  t49 225 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 933023  933143  t50 120 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 1269320 1269456 t51 136 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 1344686 1344819 t52 133 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_08_v3 1362891 1363087 t53 196 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 516928  517092  t54 164 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 596133  596334  t55 201 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 685601  685792  t56 191 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 1178894 1179078 t57 184 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 1406405 1406541 t58 136 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_09_v3 1437114 1437303 t59 189 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_10_v3 377095  377209  t60 114 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_10_v3 992371  992544  t61 173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_10_v3 1386700 1386869 t62 169 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_10_v3 1399544 1399711 t63 167 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_10_v3 1436479 1436682 t64 203 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 119486  119693  t65 207 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1009856 1010038 t66 182 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1018953 1019085 t67 132 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1376185 1376372 t68 187 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1552430 1552640 t69 210 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1750865 1751055 t70 190 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_11_v3 1816211 1816425 t71 214 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 63166   63280   t72 114 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 659891  660010  t73 119 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 684088  684261  t74 173 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 943258  943428  t75 170 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 1237431 1237603 t76 172 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_12_v3 2050130 2050314 t77 184 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 103659  103879  t78 220 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 156566  156722  t79 156 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 1150303 1150493 t80 190 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 1419543 1419670 t81 127 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 1725365 1725570 t82 205 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 1876352 1876534 t83 182 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 2114975 2115142 t84 167 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 2124634 2124847 t85 213 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 2479086 2479246 t86 160 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 2481106 2481288 t87 182 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_13_v3 2669135 2669307 t88 172 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 39953   40137   t89 184 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 120215  120351  t90 136 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 150105  150294  t91 189 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 279663  279786  t92 123 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 407379  407571  t93 192 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 564208  564377  t94 169 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 1038369 1038486 t95 117 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 1956129 1956286 t96 157 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 1992289 1992426 t97 137 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 2524962 2525089 t98 127 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 3124642 3124842 t99 200 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\nPf3D7_14_v3 3214351 3214478 t100    127 +   [genome_name_version=3D7_2020-09-01;panel=heomev1;reaction=full;]\n\n\n\nCodecd example \npmotools-python extract_insert_of_panels --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_panel_insert_locs.bed --overwrite\n\n\nCan add on the reference sequence if it’s loaded in PMO, if it’s not loaded will be blank column\n\nCodecd example \npmotools-python extract_insert_of_panels --add_ref_seqs --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_panel_insert_locs.bed --overwrite\n\n\nExtract ref sequences of insert locations of panels from PMO\nThis will extract the reference sequence of the insert location of the targets within the panel info out of a PMO and write it out as a table. The reference sequence is an optional field and so if no reference sequence is loaded then just blanks will be extracted\n\nCodepmotools-python extract_refseq_of_inserts_of_panels -h \n\nusage: pmotools-python extract_refseq_of_inserts_of_panels [-h] --file FILE\n                                                           [--output OUTPUT]\n                                                           [--overwrite]\n\nextract ref_seq of inserts of panels, but if no ref_seq is save in the PMO\nwill just be blank\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for extract_refseq_of_inserts_of_panels script is below\n\n\nCode\npmotools-python/src/pmotools/scripts/extract_info_from_pmo/extract_refseq_of_inserts_of_panels.py\n\n#!/usr/bin/env python3\nimport argparse\n\n\nfrom pmotools.pmo_engine.pmo_processor import PMOProcessor\nfrom pmotools.pmo_engine.pmo_reader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_refseq_of_inserts_of_panels():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--file\", type=str, required=True, help=\"PMO file\")\n    parser.add_argument(\n        \"--output\", type=str, default=\"STDOUT\", required=False, help=\"output file\"\n    )\n    parser.add_argument(\n        \"--overwrite\", action=\"store_true\", help=\"If output file exists, overwrite it\"\n    )\n    parser.description = \"extract ref_seq of inserts of panels, but if no ref_seq is save in the PMO will just be blank\"\n    return parser.parse_args()\n\n\ndef extract_refseq_of_inserts_of_panels():\n    args = parse_args_extract_refseq_of_inserts_of_panels()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # get panel insert locations\n    panel_bed_locs = PMOProcessor.extract_panels_insert_bed_loc(pmo)\n\n    # write\n    with Utils.smart_open_write(args.output) as f:\n        f.write(\"\\t\".join([\"target_id\", \"ref_seq\"]) + \"\\n\")\n        for loc in panel_bed_locs:\n            f.write(\"\\t\".join([loc.name, loc.ref_seq]) + \"\\n\")\n\n\nif __name__ == \"__main__\":\n    extract_refseq_of_inserts_of_panels()\n\n\n\n\nCodecd example \npmotools-python extract_refseq_of_inserts_of_panels --file ../../format/moz2018_PMO.json.gz\n\ntarget_id   ref_seq\nt1  AAACTTTTTTTATTTTTTTTGTCAATAGATAAATGATCAATATTTTCTATATTTAATCTATCAAGTATTTTTATATATCTATTATTTCTTTCTTCGATGGATAAATTATAAGAATCAATATCCTTTCTTTCATCAACAAACTTTTTTATTGTTAACTCCATTTTTTTATTTAA\nt2  CTTTCGATACAGGACATATAGATCATAATATAAACGAATATGAAAAACATTTTACAATTTTAAAAGAATCTTTTTTTCATAAGTCATTAAAATTTATGGATTATATATGGATTGTTATAATGAAACGAGAAAATAATACATTTTTAAATAGAATAAGAACTGAACAAGTCAAAAAATCGTTATTAATAACAGGTATTATAAACGAAAATATT\nt3  TTCATTCTTTTTTTAACGAAAACTATTCATCTCAAAAATATAAGATATTTTATATGACGAATGCCATTGTATTTTTTGTTACGTAAAACCTGACTTCTTCAAGGAAAACACATGCG\nt4  TGAAAGTAGCGAATACCCTGTAGAAATTGTTAGTAAACCTCTGGAATGGTTATTGTTTCATGATTTGACTAAGCCTGATGTTACTGCACTACCTGAAGAATTACCATTAACGAGCTATAAAGTAACACCTACTTCTATTAATGTATTGCATAAAGAGGGCCCCACTTTAAAA\nt5  TTAAATAAATTAAGTGAAGATGATTATGAAAAAAATTGTAGACATTTAAATTATTTAATAGATAATATAAGAGAATTATTTTTTAGTTCTAAAAATATTAGAATTCCTGATGTAGCTCGTAAATATTTGTGGGATAATCAAATTGAAGGAAATCTCAAAAAATTAATATCTTCAGAAACAAAATATAAA\nt6  AAAAGAAAGATGTTAAGAAAAAAAAGATCGATATGATAAATATATTACACATTCCTACAAATAATTATAGCATGCCAAATGAAAAAGATATAAACAGTTATGAATTTTTTGGATCTGAACCTATTGAATTATATGATGTAAAATCTAATAAGAATTGTGTTATAACTAGCCAATCTTATATTTGTATTGAAAACCCGCATGCTGCCATAGTATCCGAA\nt7  ACTTTCTTAATTCTATGAATGAAGAATATACGCATATTAATTTAAATAACTTTATACATAATAATAACCATGATAATGACGAAAATTATACATTAGATCAGGTGGAAGGATATCCTATGACTAGTTATCAAAATAATATATACAAGGATTTTTT\nt8  TGATAAAAAAAGAAAATGTAACAATCTACCTTGTGATTGTATCTTATGTAAAAAAAAGCACAATGTTTGTTATTGTAATATGTGTAAAAAGAAAGAAAAAAATATGAGAGAAGATTTATCGGTTGTAAAATATAATGAATATCCGATTAGTGT\nt9  AATACTCCGTCAGATATTCAAAATGAATGTATTTGTTCAAAAATAAATGAAGATAGAAATAATGATATGATAAACATATCTGAAATATATTATCGTTTCATTAAATTTATAACAATGATTGAAATATATTTGTGTGTAATAGAGGAAATTAAAAGGGAAGAATGGGAAA\nt10 AACTTATGTTCATGAGCTAATTTCCCACAAATACTCCATAACGAACTTTTCATTTTATTAAATTTATCTCTCAAAAGAGAATGACTATAATGCCATATTAAATACATATCTTTCCTTTCTAATTTTCCTGGTAATTCTATTATCATTCTTTCTAAATCTTCTTCTGTAACTTTTC\nt11 GGAATTTTCTTTTTTATGACTTTCTTCTCCTTGTTCAGAAGCTTCTTTTTCATCCTTTTTTTCTGCTGCGTCAGATAAATTGGGGGAAGCACTTGAAGATTCATTTCCTCCAGGAGTATTACTAGTACTTACTCCGTCCACATTTGGTTTTTCTTCCCCTAGAATTCTCAT\nt12 ATACACATAAGAAAAAAAAAATTTATTTATTCTTACAAAAAGAATATAAAAACAAAATTTTGGGATTTATAAATTTTTATAAACATATAACACACAAAATAAAAAAGAAACAAGAAAATGTTCATGATAAAATCACTTTTTTAAAATGTCTAAAGGAACTCTTTTTTGTCACACATACAAATAA\nt13 TTAATTATGAAGACAGTCTCACGACTTCATGTTATATTGATGAAAACAAATCCGATTCATCCTATGAAACTGAAGAAAATGTAAACTATAATAATAAAATGGGTAAACGCAAAAATTTAG\nt14 AACTTTTTAACACTATCATTATAATTATGTCTTTTATTTTCATATTTTTCTTTATAATAATTTATATCCTTTAATTTTTCTTTCATCAAATTTAACCATTTATCATTTAAATTCTCTTTTTCCACAGCTCCAGCATTTTTATTTATATCATCTACAACTACATCTTCCTTCACATAATTATTTATATAAAAATTATTATCATCTAA\nt15 AGCATTTATAACAAAATATCAGAAGATGGAAAAACCAAAAATAGCCTACTTAGCGATATATCTAAATTATTTAAAATTGTAAAAGAAAGCAAATTAATATTTGTAACTGGATTTTTATTAACAACCTTGTCAGCAATTGTCGATTCATACATTCCAATTTTTCTATCCAAAACGGTATCTTTTGTAATGGAAAGAAAAAAATTTACATTTCTTAAAAT\nt16 TTGAACTATTTACGACATTAAACACACTGGAACATTTTTCCATTTTACAAATTTTTTTTTCAATATCATTTGCATAATCTAATTCGTCTTTAGGTTTATTAGCAGAGCCAGGCTTTATTCTAACTTGAATAC\nt17 AAAAAGAGATTATAGAAGTGGAAAGAAGACATATATAATACAAGCTCTACAATATGCATTAACATATTATAGCAAACTTTCAAATAGAAAGGAAGCACCTAAAGTAACCATGTTATTTACAGATGGAAATGATTCCTATGAATCAGAAAAGGGATTACAGGATATTGCATTATTATATAGAAAAG\nt18 ATATTTTTATAATTTCCTTTCATCTTATTTTTTTCTTTATATTTTTTTTTTTCATATGTAAGATTTATATAATCACTTTCGCTTTTTCTAACCCTTTTGAACTTTTTAAATGTACTTCGTTCATTATTTCTAATTCTCGTAAACACAAGAATAAATATTTTGATATATCTTAT\nt19 TCATATTCGTTTCAGCGTTTATAGAGCGAATATTATCGATTATGTCTATATTCCCTAAAATATGTACATAATAATCTCCATTTAATAATGTTACTTTCTTAAGAATATTTTTGTATATGACATCAAAGATATTACGAGTTAACAATACATCTACATTTCCGTCTATTATATAT\nt20 AATATTTGTATATATTCTAGTAAACACTTTAGGTACACCTGCAAGTACCTCAACATCTGAATTATATAAATCTTTAGAAAAACAACTAATATCCTTACTCGATATATTTATTTTTATACCAAGAATAACAGCCATATAAACCAAAACTCTCTCAAATACATGTGATACAGGTAAA\nt21 TTAGATTTTTTCCCTCCAGCAGGTGCACTAACTTTAGGTGTTTTAAATCTAGATGTATGTGGAACCCCATCTTTATTTGGTTTACCTCTATTTAATCTTTTACCAGCAGTAGAAACTACATTCTCTCGATTATCATTACCTACTTCAGTCTTTACAATTGTAGGAGGTGTTTTAACATGATTATCCCCTCCATGAGGAGTAACCCTTAAA\nt22 CTTTCAAATTATATAAAGACAGAACTAAGAAATATAAACCTGCAAGAAATAAAAAACAATATAATAAAAATATTTAAAGAATTCAAATCTGCACACAAAGAAATTAAAAAAGAATCAGAACAAATTAATAAAGAATTTACCAAAATGGATGTCGTCATAAATCAATT\nt23 ATGCTAGTTTTGCTGCTCATGAAAATAAAAGCTACTCATATGAAAGTCGTACATATAAAATGTATCCACCTGAATTTAATACATTAATGTTAAAAGCAGATTATTTTATAAGAGATATAAATACACGAGGATTTAGAGAAGTAAATATGGATTCATGTAAATCATATACAAAT\nt24 ATATATTTTACATAATAACAATCCTTCATGTAATGATTATAATTTAAATAATCTTTCATTTAATATAAATAAATATATTAATGAAGAAAAAGGCAAAAATAAAAAAACAAATCAACATATATCAGAACAATTTTTATTTCCTA\nt25 GAAATGTAATTCCCTAGATATGAAATATTTTTGTGCAGTTACAACATATGTGAATGAATCAAAATATGAAAAATTGAAATATAAGAGATGTAAATATTTAAACAAAGAAACTGTGGATAATGTAAATGATATGCCTAATTCTAAAAAATTACAAAATGTTGTAGTTATGGGAAGAACAAGCTGGGAAAGCATTCCAAAAAAATTTA\nt26 AATAGTTTTACTTGGGAAATTAAATTACTATAAATGTTTTATTATAGGAGGTTCCGTTGTTTATCAAGAATTTTTAGAAAAGAAATTAATAAAAAAAATATATTTTACTAGAATAAATAGTACATATGAATGTGATGTATTTTTTCCAGAAATAAATGAAAAT\nt27 TAAATTATTATAGAAAGATAGAAGTTATTTTATATGAATGGTTATATTTTCATTATAATAATGTATATAACACCAAAGTAAAAAAACAAAAATTTATATTTACCCAACAAAAAAAAGACATATCAAAACATAACAAGTTATATCTTCAGTATGATCAAAATAAAAGAAACTCTGAAATAGAACATACA\nt28 ATCTTATAAAGTTAATGAAATAGCTCAACTTAATTTAACCATAGAAAGAGATTTAACAGATGATGCTGTGATTTTTGCACACTCACTTTATTTACCATTTGAAAAAGAAGAAATGTGGTGGATCGTTATCGGAATTAAAAAAATGAACTTACTTTTATCTATCAAAAAATTATCTTTATTGAAAAGTGTCAATAATATAAAAATTAATTT\nt29 AATGTTCTAAGATCTGATGGAAAAATATCTGATCAAGGTTCTCAGAAAAGTCCTCCTAAGGAACTTTCTAATAAACAAATGACTCCTGCTCAACGTAAGAATGTGCCACATTTTGTTGAAAGAAGAGGCTATGGAAATAGTCATGTTAGGGGTAACGCACTTAAAAAAATTAGTA\nt30 GAAGAAATAAATAAAATAATTTATACAAACGAATTTAATAATTATGAAGATAAAATATATGAAGATGTCAAATATATTAAAGAACAGGAAAATGAAATGTACTTGAGAGATGGAATTGAAGAGTTACATATGGATGAACCAAGTGGGGATGTATATTTTGATGATCAAGATGATTATATATTTTTAGAT\nt31 AAATCATCTAAGAATAAACTTTTTTGTTTAAACCATTTATTGAACATTTCACTTAAATGTGATTCAATTTTTTTTTCTGAGCTTTCCATAATTTGATTACAACTATTCAATTTGTTTGTATAAGTTTTAGGTCTTATTATTCTTTTACGTTTTA\nt32 ATTGAAAGAGTTAAAGGGAAAAATACAAAATTATTTAGATAATGATATTCAATTGAAAAATGGAAAACTCCTATATAAGGATACATGGGATAGAATTGTTTTGAAATTTTGTAGAACTGTAGCAATAGAAGAGGCAGAATACACTAGAAAATTTTATAGCTTAATTAATGATAAACATACAATT\nt33 ATTGTGATGTATATAAATTCCCTTCTTCTTTATGTACCACATTATAAGAACCACGAACATATTCTTTTAAAAATGTTAACTTACTTCCAACAAATATATAATCAAAACAAAATTTTTTATTGTCGAAATGTTCTCGTTCAACCCCATTCATATTTCGGATATCATTATTTAA\nt34 ATTTATATCATTTGTATGTGCTGTATTATCAGGAGGAACATTACCTTTTTTTATATCTGTGTTTGGTGTAATATTAAAGAACATGAATTTAGGTGATGATATTAATCCTATAATATTATCATTAGTATCTATAGGTTTAGTACAATTTATATTATCAATGAT\nt35 TACGAAATTTATAACAATTTTTACATATGCCAGTTCCTTTTTAGGTTTATATATTTGGTCATTAATAAAAAATGCACGTTTGACTTTATGTATTACTTGCGTTTTTCCGTTAATTTA\nt36 ATATTATTACGGTACCATTATATGATTCTTTAGGTCCTCAATCAAGTAGATTTATATTAGATCAAACACAGATGGAAACTATTGTATGTGACAAGACATGTGCTCGTAATTTATTTAAG\nt37 TAATGAAGAAAATATGTCTGACAGACCAAACAGTTTATCTCATGATAAGGATCAACACCTCGATGAAACACATAATGAACAATATGGATTATACGTAAAAGAAATGGAATCTAAAGTTGAAAAATTAGCTGAAAA\nt38 AATTTGAATAAAATTTATCATTCACAATATTATATTTTTGTTTCTTCTTTTTTCCCATAATATTATTATTTTGTTCACAATATATGTTCATGTGTCCCCTCTTTTTCTGTAAAATATTAAAATGTTTCTTACTATGCTTCTCTTCATTTTTAATAACA\nt39 AGAACAATTGCTAAACACCAAATTGGGTGAAACAAAAAACCACCTGAACAGAACCCCATTTATACCTGAATCGGTCATACGAGAAAGGAAATTACGCCAAGAAAAAGCTCAATCCACAAACAACATGTTCGATTCAACAAACGCAGATAGTATTACGTCCCCATGTGATCCAACGAATGCCAC\nt40 ATCATTATTATTATTATTATAATTATCATTGTTATTATTATTGTTGTTGTTGTTATTATTATTTCCTTTATTATTTAATATGCATTTTTTAATATCCATTTTATTATTTATCATATCAGTACTTTTATTTTTCTCCTTTTCGTTTATAGCTTTTTCCCTATGCACCCTGAATTTCCCATTTTTTTTT\nt41 CTTTTATTTGAACTTTTTTATTTTCTTCATTATCAATATAAAAACAACAATCTTTAAATTTATGAAATAACACCCAACTTAATGTATAAAATATAATTTCTATAAAATCAAAATTAATGTAATAACCTAATT\nt42 ACATTCAATATGGTTCTGAGCTTAAAGATGTTATCCTTATACATGTTTCTATTCTCATTCGTTATAACATCAATGACATATAAAACATATCGCTCAAATATTTTGTGAACAATATTATA\nt43 TTTTATGTGAAATTTTAAATAAAGAGAAATTGTTTGTGCACACATCTATTTTGGGATATATATCTAATCGTTTATGTTACGATATAAAAAAATATAGATGTTCATTATTGAAG\nt44 TAATATTTAATATTTTTGTTTAGGAAGTTTTCAAAATTGATGACATTGATAACCGTTTTTATTAAATCGCTTGGGTTGTTTGTGTGTTCCATTGTAGAAGACATAATTTTAAGAATGTGTTTTTGTGTTATTAAACAAAACTTTGTTACTATATGGAATCGTATGTTATA\nt45 AAGAATCTCAACTTTTGCTTAAAAAAAATGATAACAAATATAATTCTAAATTTTGTAATGATTTGAAGAATAGTTTTTTAGATTATGGACATCTTGCTATGGGAAATGATATGGATTTTGGAGGTTATTCAACTAAGGCAGAAAACAAAATTCAAGAAGTTTTTAAAGGGGCTCATGGGGAAATAAGTGAACATAAAATTAAAAATTTTAGAAAAAA\nt46 TTAATTTTCTCAAGTAACATATTTTTGTCTTGACTACTTTCATCTGTAAATGGAACGACTACTCTTTGCTTACCTGCAAAAAGGACAACTGACATATGAGCCTTATCCTTACTTACATTCGAATTAAAGACCATAGATTCTAAAAATGGTATAGTTCCTTTTAACCAATAATCC\nt47 TAAATTTACAGAAAAATTTAGATTTAATCATATGGCTAAAAAAGAATATAAAAGAAGGAGAAGCTTTAATTTCTGATATACCCACATCAAGTTTTTTAAGGTGTACTACAAATTATAAATTTGTATTGCATCCACAATATGAAGATAGTAACTTGAGAAAGAGGGTTCAAGATTATTAT\nt48 ATCATTACTATTCTTTATCCATATATATGTTGTTATATCAGTTGCACCTGAGGGTGGATTCAAACCTCTTGCTTGTATAATATATGCACGTACTACTAAATTACGTGTTAATCTATATTCTCTTACTAAATCATCACATTTCTTTATCATTTCTTTTTTTAAATACATTGTCTTTTCATCATACACATT\nt49 AACTAACAAATTATGATAATCTAGTTTATGATATAAAAAATTATTTAGAACAAAGATTAAATTTTCTTGTATTAAATGGAATACCTCGTTATAGGATACTATTTGATATTGGATTAGGATTTGCGAAGAAACATGATCAATCTATTAAACTCTTACAAAATATACATGTATATGATGAGTATCCACTTTTTATTGGATATTCAAGAAAAAGATTTATTGCCCATT\nt50 TTGGTTTTAATGAGGATGATTTAGATAAAGAGTTTTTTTTTGATTTGCCGTCGATTAGTGGTTTTTCAAGTAATGGTATGAAAAAATGTAATTTAAGAAATTTATTAAAAAGATTAGAAG\nt51 GCCTTAGCATTAATAACACTTATAGGAGGTATTTATATGACTAAAGGAAGAAAAAGTTCCATATGGCATAATTCAGAAATAAATGATACACTTTATGATGTTGTTCTTGAAACAGTGAATCAAGGAAATACAGATG\nt52 AAATATATCTTTTACTTTATCTGTAAGTTTCATGGAATCTATTATTTCATGTGCATATTTTATTTTTGCCTCGTTTATATATTTACCTGCTTTTAATTTACATAAACATTTTTCTATTAAGTTTTGATCATTT\nt53 CGTAAAAAAAAAGGGTTTTCCTAAAAAACCATCGGTTCATGGTTTTACACAGATGGTGTTTTTGCAGCTTACTAATATAGTCATGTATGCCCTTTGTTTTATGAGCCTTTCACAAATATATGCTTATTTCGAAAACGTGAATTTTTATATTATAAGCAATTTTCGTTTCCTTGAGAGATATTTTAATATATTCAAT\nt54 ATGTTTGTGTAATAAAGGATATTTCTATAATGTCAAGAAACAACAATGTGAAGAATGTCCCATAGGTTTTTATTGTCCAAAAATAAGCTCAAAAAATAATATAAAAAAACCTATCAAATGTCCTAAAAATTCCTCAAGTATAAAAAAAGGTATGTATATATCAA\nt55 ATTATTTTCGTTTTTTTTTATATTATCATTATAATTATATGTATTTACAAAGAATTTATTATTATTTGTTTCTTTATAATTATATTCATTTTCTTTATTACTTAAGGAATTTATATTTGATAAAACTTGTTGTCCTCTTTCTTCTTTGTTGATGTGAATATTTGAGAAAATAATAATAAATGTAATGACTAGGGCTATGTT\nt56 ACAAAGGAACAAGATAATTTTTTCCATTTTTATAAAAGTAATATATATGATATGGAAAATAGAACCTGTAATAATAATATATTACAATATTGTGTTATGAATAATAAATCATATTTATTTCATAATATATCATCCAAAAAAAATATATATATAAAAAAAAAGAATCATCAGTTTTCTTTATTCATATATTC\nt57 ACAAATTATCCTTAGCCCCAGATATGGTAAAGACATATCACTGTTATAAATTAGGAAAGCAAGCAGCTGAATTATTAGAATCTATCATTTTAAAGAAAAAGTTCGTAAGATTTAGAGTTACTGATGCTATTGATGTATATGATTTCTTTTATATAAAGAAAGTTTTATCCAGTCGTATTAAGAA\nt58 TAATTAATTTTAATGATGATGTTACTTTAGAAACACAATCCATGATAGCACACGGAGGGTCTTTGTCAGAAATAGAAGAAACTGGAGATTTATCTTCAGATGTTGATAGATTACATTCATCAATCGAAACTACTCC\nt59 CTAAAACCTGACAGCTTTGTACAGTTATATTTACCCAATTAGAATGTTCAAACATATTTAAGTGTTGCCATTCTTCAAATAATTTTTTTTCATATTCAGTTTTTGGTTGGTTTTTAAATTCTTTTGATACTGTACCTTCTGCGGATGGTATAGGGAAGTTAAAAATTTTATTACGTACTTTGTTTGATT\nt60 AACCAAAAAATGATACCTGTACGTTTTTCTCCAGGAGAAACAAAAAAATTAGAAAGGATTCTCAAAAAAGTAGACGACTTTTTCTGTGCCAATATTAAAGCTCAATATACTTGC\nt61 TTTTTAAAAAAAAAAATTATGATATAAAATCTTCAATTAATAAAAGATCTATCCAGTTCTTTAAAGACACTAATATAGATCATTATATAGCATATGAATATTATAAGGAGGACCGTACGGAATTTATATTAACTATTATGAATGAAAAAAATATTACTCATCAAGAAACTCAA\nt62 AGGGAACAGGTTAAATATATTGAAGACGTGGTTTGATAATCAGGTATTTCTTTAATTAAATATTCATGATATTGTTCGTTAGATACATAAATTAATTCGTCCTCCACATTTTGCTGTTCTGTTATAATTTGTGAAGAAGCTTGGTTTGTCTTATTTGGTAATTGCTCTT\nt63 AACATCAGAACATAGTAAAGATTTAAATAATAATGATTCAAAAAATGAATCTAGTGATATTATTTCAGTAAATAATAAATCAAATAAAGTACAAAATCATTTTGAATCATTATCAGATTTAGAATTACTTGAAAATTCCTCACAAGATAATTTAGACAAAGATACAA\nt64 CGAGAAGAAACACGTTTTATCTCATAATTCATATGAGAAAACTAAAAATAATGAAAATAATAAATTTTTCGATAAGGATAAAGAGTTAACGATGTCTAATGTAAAAAATGTGTCACAAACAAATTTCAAAAGTCTTTTAAGAAATCTTGGTGTTTCAGAGAATATATTCCTTAAAGAAAATAAATTAAATAAGGAAGGGAAAT\nt65 TTTCATCCAAGAGTAATTATGTTTTTCTTGTTGATATTTTGCTTTATACAAACGAGCAAGATACTTTTTATACGATTCATGCTCTTTAATTTTCTTTTCAAAAGTTTTGGTTATAATGTGTTCAAGTGATTGTAAAGTATTTTTCTTTAATTTTCTCCATATTAATCTACATGCGATTATAAGAATTCTATATTCTTTGATATTCCC\nt66 GAATTCTATCTATTTGTTTAATTGGTGTCCATGAATTTTTAGAGAAACACCACATATCAGCTAATAAGGAATTATTAACATCTAATCCTCCATGAATATATAAAAAATCATTAAAACTGAAAGAAGCATGCTTATATCTTGCACGTGGACAAATTTTATTTCCAATAAGTTCCCATTTCTTT\nt67 CTAGTGACTGTACATTTTTCATCTAATGTTCTATAGGATAAAGAATCTGAAGGACAATGCATATCATTACAAAAATAGCATGCACCTTTAAAATATAAATAAGAATGTCTTAACACAACAAAGGAATCAAAA\nt68 TTCTCATTCCTTTGAAAATATGAACTATTCAACTCATCAAGTTTTTCATATGTTATTTCATAACTGCCATCATCTGAATCCTCTTCATCACTACTACTTAAAGAATGCTCTTCTACAGTTATATCTTCATAATGATTATTTTTAGGAAAATATTCTTCAGATCTTTCTATAAATTCTGTTCCACTAC\nt69 AATATCGACAATTATAAAGAAAAAATAGAAAATTTTAATGAAAGATATTATGAAGATGATTTAAGTTTCTTAAACTTTCCAGGAACCATAACAAGTTATGATAAAAACCATCAAAGAGATAAAAGAAAAAACTGTTTTGAAGAATATCTAGACAATAATAATTATTTTATTGATAGTAATCTAAAGGAAGTTATAGAAAATAATATATAT\nt70 TTATTAAAAACAACAAATAAATTACCAAGGTCATGGAAAAAACTCTTGTTAAATCTATCCATTAGATTTCAAACAATACCTATAGGTGGTTCTATCGAAATCATATCAAAGGATGAGAAAAATATTTCTATGACACGATCCAGTGAATATAATGCAACAACATATGAGCATTACACATTTCCCAAATGGT\nt71 ATTGACTTCTCCGGGTTGGTTACATTATCATTACAACCAATATTATTAAGGTTAATACTATTTTTATCATTATTATTGTTGTTTTCATTTGTGTGGTTATATAATAACAATGATGTGTCGTCTATTGGATCATTTTGCACAAGGTCAATATCATTAGAATTATGTTTCATATTATTTGTATACATTTTTTTGTAATTATCATTTTTTCTTACTT\nt72 TATAATTTCACCTTTTGAATTACATATGTCTGTATTCAAAAATTTTATATCTCTACTCCATATATTTATCTTTACACCCAAAAACAAAGCAATGAAAAAAACAACCCTTTCATA\nt73 GGGTCGACTTTTGGTGGTTTAACATTTTCAGCTACGAGATTTTCGAATGATGGCAATCCTACTTTGATTAATTCCTTTAACATAGATTTTGCGTGTTTTTTTACTTCTGATTTGATATC\nt74 AATATCAAGATGGTAGTATTGTTTTAGATGTTAGTAGTACGAGAGATAAACTTTATGGAGAAGTTGAGTGGGAAGGATATAAATTTGAACTTGTGGATACAGGAGGTTTAGTTTTTGAACAAGAAAAGTTTTCAAAAGAAATAAAGGATCAAATTCTTATGGCTCTAAAAGAA\nt75 AATCAACTATAATTAAAAATAGTGGAATTATTGAAAACTTTGGAGATATTGATTATATCTTTACGGATAAAACAGGAACACTAACAGAAAATGTCATGGTGCTTAAAGTTATACATATAGGTTTTGATGTTATACATGCAGAAAATGAAAAAAATTCCATACAAGGTAAT\nt76 AGTATGAACACAAAACCGAAAGAGAGTTTAAAAAAAGATTCGATTTTAATGAAGGAAGAAATAACATAATAAATGTGTCAAATGTAAAGAAAACATGTAATATAGTTAAAAATGATTTAAAGGAATCTAACGAGATAAAAACTAATATAAACACAAGTTCTTATAATTTATA\nt77 TTTTAAACTTTGAATCTGTTCAATTAATAACACTTCATCATTGTCTTCGCCTTTTATAATATCTCCATGATTATGTGCTCCTCTAATTAAGGTATCACTAACCTGTTGTTCATCTGTCGCATGAGAACTAGTAGATATATCTGGTTTATTTTTTTTCTTTCTTTTTGTTATTTCTAATTTTTTT\nt78 AACTGATGTTAATGAAGGCCAAAATGGAAAACGTTTAACACAAGAAAAAACCCTAAAACAAATTCCTTCGACATCACCAAATAATTTAGAACAAAAATTACAACAAACACATATTTCTTCTTCCCAACAAAAACATTTAATAAAAACTACTCCTACTTCAGATTCAACTACAACTTCATCAAGCTCTTCTGTTCCTCTTACAAAACAATCCCCTCATTCT\nt79 TATAGAGTTATTATGTTCGAATTAATGACCAGATTATTTCGATTTTATACAAAACCAATAGACCTTATTATTACTATGAATACACACAGATATGACACACCTATATTGTTAAAACATTCAAACAGCTTACAACTTATCTTATCAAATCAACAAAAT\nt80 CTAAAAAAAGCAAACAAAAAGAAAAGAGAATGGAAGATTTAAGTATTGAGGAAAATTTGAAAGAGAAATTAATAAACCTAAATATTCAGAAACAGTATAGTGGTTTCCATATGAAAGAAATGGAGGAACAAAATATTCCTGAATTAAATATTCCACAACTTTCAGCTATTCATAATAGAGAAGATATGAA\nt81 CTGGTTTTTGTACTTCTTGTCCTTGTGTTGATATCTCTTGTTCATTTTTAGATTGAGTATCTGTTTCACTTTGTGCCTTTACCTTTGATAATACGTTTTTACCGAATAATCCTAAATTTTGGAATAA\nt82 CCCAATACAATAAATTCTACCATTTGACGTAACACCACAATTATTTCTTCTAGGTATATTTAAATTACTTGAAACATACCATACATCTCTTAAACGATCATACACCTCAGTTTCAAATAAAGCCTTATAATCATAGTTATTACCACCAAAAACGTATAAGAAATTATTCAATACAGCACTTCCAAAATAAGCTTTTTTGGTAGAC\nt83 TTATATTTTGGTTCAGACAAATGTACGTTACATGAAATATGTGCACTATCATCAACTAAAGAAATATCTAAACTATCTGTAAAAGTATGTTTAGAACTAACATTTGAAGAGAAGTTACATCCGTGTATGACTTTTTTTTCATATTTTGGTTTTAAAACTATTTTATAATTATTATTTTTAAA\nt84 ATCATTAAGTAAAAAATTTACGGTATCGACATTAACAGTGTAATAATTTCTTCCTAAATTTAAATGTTCTATATAATTCAAATTTAATACGGTATTTAACCTTTCTTCAAGTATTATCATTGCATTAATTTGAAACATAAGTAAAAAATTATTAGCACTTCTAAAAT\nt85 TAACATTTTTTTAACATCTTTACCTTTTTGACTTGGTTCTTTATCATAATTCTGTTGTTCTGCAGAATCAGCATTTACTTCAGTTTCTTCTTTATTTTGAAAAGTGTTTGATTCTACATGAGAATTGGAAGATGAACGTCTATGTTTTACTTCTGTATAACTAGTACGTTCTCCAGTATGATGAGCCTTATGGTTTACATCTTCAGTTTCTTC\nt86 TCTATGCTTTATCAAAACAAAGTAATCAAAATGTAATACATTATTCTTGTCGATCTATATGTGCTTTTACAAAAAACCCTAAGGGTTTAGAAGCGGTAAAGGATATCAAGGACTTTGCGAATATTATAAGTAAATCTGTTGGTGATTTGAGTAAAGAGAA\nt87 GCAACTTACTTTAGAAGCCATGAATTCGGCCGATGATCCATTGGAAGCATTTAAAAATACTTTATTAATATTTGATTTTAATTTATCTGAATTTGATAAGGATCCATATATAAATGGTGTGCATGATTTAGCATCTAATATAAAGGATTGTTTAAGAAAAGGAGGTCACAGTAAAATATATT\nt88 AAAAAAAATACATTTAAATCTATAATATTTGTAATAAATGATAAGAATATTAGTATTAATAGGGTACTACTATTTGTAAATACTTTTCTACATAATTTATCAATAGTAGGAAATATGATATTCTTTTTGTTTGGCTTTATTTTATCTGGGATTTTCCAATCATAAAGTTCGA\nt89 ACATAGAAATATGTGCGAAAATTGGGAAAAAAATAAATAACAGGAATTGTTATATAAATTGAATCAAGAATGGCACAAAGAAAATAATACTGGTGACTTTCACACTAGTGATATCACACACAATAGTGGTATTACATACAGTAGTGGTAACATACCTAGTGAAAGTAATAGTAGTTATATCCAA\nt90 CTTACAATGTTCTTCGCATTCGAAATTTTTTTCAGGATTACTTGAAAAGCCTTCTGGACAATTACAATATTCATATCCATGAGTATTCTTACAAACACCTTTTCCACAATTTAAAAAACATTTTTCTTCATTTAAA\nt91 ATAATAATAGTAATATAAAGAATTATTCAGCTGTAGATATATTCTCACCCAAAAAAACTGGAAAGGAATGTATTAAATGTCTCCCAGATAATTTTTGTGAATGCGAATGTAGTTGTAAAAATAAAACAGGTTTTTCAATGAAATATAGACATGCCAGTAAGGGATCTAAAGGATATAGTAAAAAAATGA\nt92 GAGTAATAGTGATTCATATAAGGTAAATTGTATTAATTTCTCTGAAGGATTTTGTTGCTGTCATCCAATAAATAATTTAGCACTATTATATGGAGAGTATCAACAAAATCAAGAATCAAAAAT\nt93 TCTCCTTCCTTTTCATTCTTTACTTTATTTCTATTAATACACAACTCTCCTTGAGTTAAGAGATTTACGATATTATCAATATTGTTTTCTTTCATATACTTCAACTTTTTACTATTCATTTTTAAAAGATAATTAACCAAGTTACTCATGTTTGTATTAGATGGTATGTTCCCAATTTTTTCGTCTTTTCTT\nt94 TTATTAAAACTTTTTTTTCTTTCTGTAAAGTTTGTACATTATGTTTTGATGAGTTTTGATTATCTTCATAAAACTTTATATATTTATAAAAATTATTTTGTATAAAATCATTTAATAAAGGTAACATAATCTTTTTAGCTTGATTCAATTCACTACATGAATGTATATT\nt95 CATACAATTAATAAAGCTCTACGATAAATTTCTTTTTTATTTGATTTAGAAAAAGGAGAAAACCATTGAAACTTTTTGGCTAGATATTTATGGTCTTTATCAAAAATATATTCTGAA\nt96 ATATATATAAAGTTAAACCTATAAATAATACACTACCTAATAAACTATTCTTATATTTAAAAATAAATATAATACATGTTATTAATCCTTCTATTGTTGCCGGAATAATATACATTAAAACAGAACTCATCAAATTATTAGCACTCTCGGTACCTCT\nt97 ATAAACACCAGTACCATTTTTTTCTGATAAATTAATATTTTTTTGTATAACATCATATTTATCCCTTTTCGTGGTAAGTGCAGTATCCTGTTTTATTATTATATTATCGAATTCATCATGGTGTATATTTCTTTCAT\nt98 AAATGAGGTATAATCATCCATTTCGTTGGGTCGATTTGATCTATTTTTAAGGTCCATATATTGAGATGAATCATTATGCATTTTATAATCATGAGGGATATTAGGTGCATGGTATTTAGGGTCTTTA\nt99 TATGGAAAAATGGAATATGAAGTATTAAGTGATGATAACATAGTGTATGAAAATATACAACATGATTTATTAAAAACAATAGAAGATGATGAAGAAATGTTAAAAGGAACTGAAAGGAAGGATAATATAGATATACTGAGGACTCCTGGAAGGGGAGAATATAATATGTGGTCTACTTCTGGACTAGGGTTCTATGAATT\nt100    ATCGTTTTGAATTGTTAGAATTTAAAATGACGGAGGATTGTTATACAAAAATGTGGTTTGATTTTATGAGTGATTTTGGAATAGCTACAATGAATGAAACCGAACATACTAGATCTTTTTATGGATT\n\n\n\nCodecd example \npmotools-python extract_refseq_of_inserts_of_panels --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_panel_ref_seqs.tsv --overwrite"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html",
    "href": "pmotools-python-usages-notebooks/build_pmo.html",
    "title": "Creating a PMO File",
    "section": "",
    "text": "In this tutorial we will go through the steps to build a PMO, utilising the functions within the pmo-tools package.\nFor more information on any of the fields mentioned please see the documentation."
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html#setup",
    "href": "pmotools-python-usages-notebooks/build_pmo.html#setup",
    "title": "Creating a PMO File",
    "section": "Setup",
    "text": "Setup\nFirst we will import the functions that we will need to run this notebook.\n\n\nCode\nfrom pmotools.json_convertors.microhaplotype_table_to_pmo_dict import microhaplotype_table_to_pmo_dict\nfrom pmotools.json_convertors.metatable_to_json_meta import experiment_info_table_to_json, specimen_info_table_to_json\nfrom pmotools.json_convertors.panel_information_to_pmo_dict import panel_info_table_to_pmo_dict\nfrom pmotools.json_convertors.demultiplexed_targets_to_pmo_dict import demultiplexed_targets_to_pmo_dict\n\n\n\n\nCode\nimport pandas as pd\nimport json \n\n\nHere we define a function that will be used to print a few lines from the data we will be creating.\n\n\nCode\ndef print_json_head(dict, n=10):\n    json_object = json.dumps(dict, indent=4)\n    for i, l in enumerate(json_object.split('\\n')):\n        if i &gt;= n:\n            break\n        print(l)"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html#creating-pmo",
    "href": "pmotools-python-usages-notebooks/build_pmo.html#creating-pmo",
    "title": "Creating a PMO File",
    "section": "Creating PMO",
    "text": "Creating PMO\nTo create the full PMO we will need a few sets of information. These include:\n\nPanel Information : A table including data on the targets that make up the panel.\nAllele table : A table containing the alleles called for each of the samples for each of the targets and the reads associated.\nDemultiplexed reads : A table containing the raw reads for each sample, for each target after demultiplexing, before any filtering.\nExperimental metadata : Information on the sequencing run, for example where each sample was located on the plate.\nSpecimen Information : metadata on the biological samples\n\nWe will specify the paths to the example data we will use below, but if you would like to try and use your own data then replace the following paths:\n\n\nCode\npanel_information_path = 'example_data/mad4hatter_panel_info_example.tsv'\nallele_table_path = 'example_data/mad4hatter_allele_data_example.txt'\ndemultiplexed_reads_path = 'example_data/mad4hatter_amplicon_coverage.txt'\n\n\n\nPanel Information\nFirst we will work on putting the panel information into PMO format. Although labs may store this information in a variety of ways and this process may seem cumbersome, you will only have to do this once for each panel that you work with.\nThe panel information consists of 2 parts; The panel_targets (information on the targets) and the target_genome (information on the reference genome being targeted).\nTo include details of the reference genome we need the following information.\n\nname : name of the genome\nversion : the genome version\ntaxon_id : the NCBI taxonomy number\nurl : a link to the where this genome file could be downloaded\n\nOptionally, you can also include a link to genomes annotation file, as we have below. Below is an example of compiling this information into the json format manually:\n\n\nCode\ntarget_genome_info = {\n            \"gff_url\" : \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n            \"name\" : \"3D7\",\n            \"taxon_id\" : 5833,\n            \"url\" : \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n            \"version\" : \"2020-09-01\"\n        }\n\n\nFields that are required to define the target information are …\n\ntarget_id : a unique identifier for each of the targets\nforward primer seq : The sequence for the forward primer associated with this target\nreverse primer sequence : The sequence for the reverse primer associated with this target\n\nNote: in the case that you have multiple primers to target the same region, please include these on separate lines in the table with the same target_id.\nOptionally you can also include location information for the primers. To include this information you will need to include in the table:\n\nchrom : the chromosome name\nstart : the start of the location, 0-based positioning\nend : the end of the location, 0-based positioning\n\nFor more information on optional fields that can be included, check the documentation.\nHere we show how to take panel information that is used to run the MAD4HatTeR pipeline and convert it to PMO.\n\n\nCode\nmadhatter_panel_info = pd.read_csv(panel_information_path, sep='\\t')\nmadhatter_panel_info.head()\n\n\n\n\n\n\n\n\n\namplicon\namplicon_start\namplicon_end\nampInsert_start\nampInsert_end\nrev_primer\namplicon_length\nampInsert_length\nfwd_primer\ntarget_type\nstrand\ngene_id\n\n\n\n\n0\nPf3D7_01_v3-145388-145662-1A\n145388\n145662\n145421\n145630\nAAAATGTCCAATATGTCAAGGTATATTAAAGT\n274\n209\nCCTGAGTTTTAAGTGAATGAATATATTTTTGTT\ndiversity\n+\nPF3D7_0103300\n\n\n1\nPf3D7_01_v3-162867-163115-1A\n162867\n163115\n162889\n163092\nTGTGTGCTTTGTCGTTGATTCAT\n248\n203\nTACTACCGATCATCAAGCCGAA\ndiversity\n+\nPF3D7_0103600\n\n\n2\nPf3D7_01_v3-181512-181761-1A\n181512\n181761\n181545\n181729\nTAGTTTAAATCTATACTTGTCTCACCTGAACA\n249\n184\nCTTTTCATATTTGTCTATTAGCTTTTTCAAACC\ndiversity\n+\nPF3D7_0104100\n\n\n3\nPf3D7_01_v3-455794-456054-1A\n455794\n456054\n455827\n456021\nGTGTTTCATTATTTTAGACACATTCAGGAATTT\n260\n194\nACAATGTAGAACAATATATAAAACTGGAAAAGA\ndiversity\n+\nNaN\n\n\n4\nPf3D7_01_v3-528859-529104-1A\n528859\n529104\n528890\n529073\nAATCATTTTATCCCACTTATTTATCTCGTCT\n245\n183\nCTTAGTTTAGATTTGCCTACAATATTTGCAC\ndiversity\n+\nPF3D7_0113800\n\n\n\n\n\n\n\nWe can use the panel_info_table_to_pmo_dict function to convert this into the correct format for PMO.\n\n\nCode\nprint(panel_info_table_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe containing panel information into dictionary of targets and reference information\n\n\n    :param target_table: The dataframe containing the target information\n    :param panel_id: the panel ID assigned to the panel\n    :param genome_info: A dictionary containing the genome information\n    :param target_id_col: the name of the column containing the target IDs\n    :param forward_primers_seq_col: the name of the column containing the sequence of the forward primer\n    :param reverse_primers_seq_col: the name of the column containing the sequence of the reverse primer\n    :param forward_primers_start_col (Optional): the name of the column containing the 0-based start coordinate of the forward primer\n    :param forward_primers_end_col (Optional): the name of the column containing the 0-based end coordinate of the forward primer\n    :param reverse_primers_start_col (Optional): the name of the column containing the 0-based start coordinate of the reverse primer\n    :param reverse_primers_end_col (Optional): the name of the column containing the 0-based end coordinate of the reverse primer\n    :param insert_start_col (Optional): the name of the column containing the 0-based start coordinate of the insert\n    :param insert_end_col (Optional): the name of the column containing the 0-based end coordinate of the insert\n    :param chrom_col (Optional): the name of the column containing the chromosome for the target\n    :param gene_id_col (Optional): the name of the column containing the gene id\n    :param strand_col (Optional): the name of the column containing the strand for the target\n    :param target_type_col (Optional): A classification type for the target\n    :param additional_target_info_cols (Optional): dictionary of optional additional columns to add to the target information dictionary. Keys are column names and values are the type.\n    :return: a dict of the panel information\n    \n\n\nWe will use this first just to include the most basic required information.\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info,\n    \"mad4hatter_poolsD1R1R2\",\n    target_genome_info,\n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n)\n\n\nLet’s take a look at the first 30 rows of the information we put together…\n\n\nCode\nprint_json_head(panel_information_pmo,30)\n\n\n{\n    \"panel_info\": {\n        \"mad4hatter_poolsD1R1R2\": {\n            \"panel_id\": \"mad4hatter_poolsD1R1R2\",\n            \"target_genome\": {\n                \"gff_url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n                \"name\": \"3D7\",\n                \"taxon_id\": 5833,\n                \"url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n                \"version\": \"2020-09-01\"\n            },\n            \"targets\": {\n                \"Pf3D7_01_v3-145388-145662-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"CCTGAGTTTTAAGTGAATGAATATATTTTTGTT\"\n                        }\n                    ],\n                    \"reverse_primers\": [\n                        {\n                            \"seq\": \"AAAATGTCCAATATGTCAAGGTATATTAAAGT\"\n                        }\n                    ]\n                },\n                \"Pf3D7_01_v3-162867-163115-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-162867-163115-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"TACTACCGATCATCAAGCCGAA\"\n\n\nOptionally we can include some more information. You can see that some of the fields in the table above don’t directly match the optional fields. Therefore, we must first wrangle the data slightly to fit the requirements.\nNote: You may not have to apply all of the following steps to your panel information, this is just an example and is specific to the MAD4HatTeR panel information.\nThe chromosome for each target is stored within the locus name, so we extract that and put it in it’s own column below.\n\n\nCode\nmadhatter_panel_info['chrom'] = [chr[0] for chr in madhatter_panel_info.amplicon.str.split('-')]\n\n\nNext we need to generate 0-based coordinates of the location the primers are targetting. The panel information we have only includes the full target start and end (including the primer) and is 1-based, so we do the conversion as follows.\n\n\nCode\n# Create 0-based coordinate for start of forward primer\nmadhatter_panel_info['fwd_primer_start_0_based'] = madhatter_panel_info.amplicon_start-1\n# Calculate the length of the forward primer, add this to the primer start coordinate to get the end coordinate \nmadhatter_panel_info['fwd_primer_len'] = [len(p) for p in madhatter_panel_info.fwd_primer]\nmadhatter_panel_info['fwd_primer_end_0_based'] = madhatter_panel_info.fwd_primer_start_0_based+madhatter_panel_info.fwd_primer_len\n\n# Calculate the length of the reverse primer. Subtract this from the end coordinate of the target to get the start coordinate of the reverse primer\nmadhatter_panel_info['rev_primer_len'] = [len(p) for p in madhatter_panel_info.rev_primer]\nmadhatter_panel_info['rev_primer_start_0_based'] = madhatter_panel_info.amplicon_end-madhatter_panel_info.rev_primer_len\n# The 0-based reverse primer end would be the same as the amplicon end \nmadhatter_panel_info['rev_primer_end_0_based'] = madhatter_panel_info.amplicon_end\n\n\nIn the MAD4HatTeR pipeline, we trim one base from each end of the amplicon insert because the base following a primer is often erroneous. We can create insert coordinates with this adjustment, as shown below. If you choose not to apply this trimming step, you can instead use the coordinate at the end of the forward primer and the beginning of the reverse primer to define the start and end of the insert.\n\n\nCode\nmadhatter_panel_info['insert_start_0_based'] = madhatter_panel_info.fwd_primer_end_0_based+1\nmadhatter_panel_info['insert_end_0_based'] = madhatter_panel_info.rev_primer_start_0_based-1\n\n\nNow we can create panel information to go into PMO with all of the optional fields we just created.\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info, \n    \"mad4hatter_poolsD1R1R2\", \n    target_genome_info, \n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n    forward_primers_start_col=\"fwd_primer_start_0_based\",\n    forward_primers_end_col=\"fwd_primer_end_0_based\",\n    reverse_primers_start_col=\"rev_primer_start_0_based\",\n    reverse_primers_end_col=\"rev_primer_end_0_based\",\n    insert_start_col=\"insert_start_0_based\",\n    insert_end_col=\"insert_end_0_based\",\n    chrom_col=\"chrom\",\n    strand_col=\"strand\",\n    gene_id_col=\"gene_id\",\n    target_type_col=\"target_type\",\n)\n\n\nYou can also add on your own custom fields using the additional_target_info_cols parameter. Below we add on the amplicon insert length information. If there is a field that you want to add and think others would find useful please contact us and we can add it in. This way we can make sure to keep ontologies consistent!\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info,\n    \"mad4hatter_poolsD1R1R2\",\n    target_genome_info,\n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n    forward_primers_start_col=\"fwd_primer_start_0_based\",\n    forward_primers_end_col=\"fwd_primer_end_0_based\",\n    reverse_primers_start_col=\"rev_primer_start_0_based\",\n    reverse_primers_end_col=\"rev_primer_end_0_based\",\n    insert_start_col=\"insert_start_0_based\",\n    insert_end_col=\"insert_end_0_based\",\n    chrom_col=\"chrom\",\n    strand_col=\"strand\",\n    gene_id_col=\"gene_id\",\n    target_type_col=\"target_type\",\n    additional_target_info_cols=[\"ampInsert_length\"]\n)\n\n\nLet’s have a look at this now with the extra information added to the panel information\n\n\nCode\nprint_json_head(panel_information_pmo,46)\n\n\n{\n    \"panel_info\": {\n        \"mad4hatter_poolsD1R1R2\": {\n            \"panel_id\": \"mad4hatter_poolsD1R1R2\",\n            \"target_genome\": {\n                \"gff_url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n                \"name\": \"3D7\",\n                \"taxon_id\": 5833,\n                \"url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n                \"version\": \"2020-09-01\"\n            },\n            \"targets\": {\n                \"Pf3D7_01_v3-145388-145662-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"CCTGAGTTTTAAGTGAATGAATATATTTTTGTT\",\n                            \"location\": {\n                                \"chrom\": \"Pf3D7_01_v3\",\n                                \"end\": 145420,\n                                \"start\": 145387,\n                                \"strand\": \"+\"\n                            }\n                        }\n                    ],\n                    \"reverse_primers\": [\n                        {\n                            \"seq\": \"AAAATGTCCAATATGTCAAGGTATATTAAAGT\",\n                            \"location\": {\n                                \"chrom\": \"Pf3D7_01_v3\",\n                                \"end\": 145662,\n                                \"start\": 145630,\n                                \"strand\": \"+\"\n                            }\n                        }\n                    ],\n                    \"gene_id\": \"PF3D7_0103300\",\n                    \"target_type\": \"diversity\",\n                    \"ampInsert_length\": 209,\n                    \"insert_location\": {\n                        \"chrom\": \"Pf3D7_01_v3\",\n                        \"start\": 145421,\n                        \"end\": 145629,\n                        \"strand\": \"+\"\n                    }\n                },\n\n\n\n\nMetadata\nThis section will compile metadata on two levels:\n\nSpecimen Level: Information about specimen that was collected.\nExperiment Level: Information about the sequencing or amplification runs performed on a specimen.\n\nIt’s important to note that a single specimen may be linked to multiple experiments.\nIn our example this is stored in one table, but may be stored in multiple places for you.\n\n\nCode\nmetadata = pd.read_excel('example_data/mad4hatter_metadata_example.xlsx')\nmetadata.head()\n\n\n\n\n\n\n\n\n\nspecimen_id\ncollection_date\ncollection_country\nsamp_collect_device\nlat_lon\ncollector\ngeo_admin3\nhost_taxon_id\nproject_name\nsamp_store_loc\nsamp_taxon_id\nexperiment_sample_id\npanel_id\nplate_name\nplate_row\nplate_col\nsequencing_info_id\n\n\n\n\n0\nSAMN38241219\n2019-01\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819135\nMad4hatter\nplate1\nA\n1\nrun1\n\n\n1\nSAMN38241215\n2017-02\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819139\nMad4hatter\nplate1\nA\n2\nrun1\n\n\n2\nSAMN38241214\n2016-05\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819141\nMad4hatter\nplate1\nA\n3\nrun1\n\n\n3\nSAMN38241052\n2015-05\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819151\nMad4hatter\nplate1\nA\n4\nrun1\n\n\n4\nSAMN38241112\n2019-06\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819200\nMad4hatter\nplate1\nA\n5\nrun1\n\n\n\n\n\n\n\n\nSpecimen Level Metadata\nNow we put together the specimen level metadata. This is the metadata associated with the sample collected from the host. For more information on this section see the documentation.\n\n\nCode\nprint(specimen_info_table_to_json.__doc__)\n\n\n\n    Converts a DataFrame containing specimen information into JSON.\n\n    :param contents (pd.DataFrame): The input DataFrame containing experiment data.\n    :param specimen_id_col (str): The column name for specimen sample IDs. Default: specimen_id\n    :param samp_taxon_id (int): NCBI taxonomy number of the organism. Default: samp_taxon_id\n    :param collection_date (string): Date of the sample collection. Default: collection_date\n    :param collection_country (string): Name of country collected in (admin level 0). Default : collection_country\n    :param collector (string): Name of the primary person managing the specimen. Default: collector\n    :param samp_store_loc (string): Sample storage site. Default: samp_store_loc\n    :param samp_collect_device (string): The way the sample was collected. Default : samp_collect_device\n    :param project_name (string): Name of the project. Default : project_name\n    :param alternate_identifiers (Optional[str]): List of optional alternative names for the samples\n    :param geo_admin1 (Optional[str]): Geographical admin level 1\n    :param geo_admin2 (Optional[str]): Geographical admin level 2\n    :param geo_admin3 (Optional[str]): Geographical admin level 3\n    :param host_taxon_id (Optional[int]): NCBI taxonomy number of the host\n    :param individual_id (Optional[str]): ID for the individual a specimen was collected from\n    :param lat_lon (Optional[str]): Latitude and longitude of the collection site\n    :param parasite_density (Optional[float]): The parasite density\n    :param plate_col (Optional[int]): Column the specimen was in in the plate\n    :param plate_name (Optional[str]): Name of plate the specimen was in\n    :param plate_row (Optional[str]): Row the specimen was in in the plate\n    :param sample_comments (Optional[str]): Additional comments about the sample\n    :param additional_specimen_cols (Optional[List[str], None]]): Additional column names to include\n\n    :return: JSON format where keys are `specimen_id` and values are corresponding row data.\n    \n\n\n\n\nCode\nspecimen_info_json = specimen_info_table_to_json(metadata, geo_admin3='geo_admin3',host_taxon_id='host_taxon_id', lat_lon='lat_lon')\nprint_json_head(specimen_info_json, 20)\n\n\n{\n    \"SAMN38241219\": {\n        \"specimen_id\": \"SAMN38241219\",\n        \"samp_taxon_id\": 5833,\n        \"collection_date\": \"2019-01\",\n        \"collection_country\": \"Mozambique\",\n        \"collector\": \"Brokhattingen, Nanna\",\n        \"samp_store_loc\": \"UCSF Greenhouse Lab\",\n        \"samp_collect_device\": \"dried blood spot\",\n        \"project_name\": \"PRJNA1040019\",\n        \"geo_admin3\": \"Maputo\",\n        \"host_taxon_id\": 1758,\n        \"lat_lon\": \"25.58,32.35\"\n    },\n    \"SAMN38241215\": {\n        \"specimen_id\": \"SAMN38241215\",\n        \"samp_taxon_id\": 5833,\n        \"collection_date\": \"2017-02\",\n        \"collection_country\": \"Mozambique\",\n        \"collector\": \"Brokhattingen, Nanna\",\n\n\n\n\nExperiment Level Metadata\nThis section shows how to put together the experiment level metadata. More information on this table can be found [here](pd.read_excel(‘example_data/mad4hatter_experiment_info_table_example.xlsx’).\n\n\nCode\nprint(experiment_info_table_to_json.__doc__)\n\n\n\n    Converts a DataFrame containing experiment information into JSON.\n\n    :param contents (pd.DataFrame): Input DataFrame containing experiment data.\n    :param experiment_sample_id_col (str): Column name for experiment sample IDs. Default: experiment_sample_id\n    :param sequencing_info_id (str): Column name for sequencing information IDs. Default: sequencing_info_id\n    :param specimen_id (str): Column name for specimen IDs. Default: specimen_id\n    :param panel_id (str): Column name for panel IDs. Default: panel_id\n    :param accession (Optional[str]): Column name for accession information.\n    :param plate_col (Optional[int]): Column index for plate information.\n    :param plate_name (Optional[str]): Column name for plate names.\n    :param plate_row (Optional[str]): Column name for plate rows.\n    :param additional_experiment_cols (Optional[List[str], None]]): Additional column names to include.\n\n    :return: JSON format where keys are `experiment_sample_id` and values are corresponding row data.\n    \n\n\n\n\nCode\nexperiment_info_json = experiment_info_table_to_json(metadata, plate_name='plate_name', plate_col='plate_col',plate_row='plate_row', additional_experiment_cols=['collection_date','collection_country'])\nprint_json_head(experiment_info_json, 20)\n\n\n{\n    \"SRR26819135\": {\n        \"experiment_sample_id\": \"SRR26819135\",\n        \"sequencing_info_id\": \"run1\",\n        \"specimen_id\": \"SAMN38241219\",\n        \"panel_id\": \"Mad4hatter\",\n        \"plate_col\": 1,\n        \"plate_name\": \"plate1\",\n        \"plate_row\": \"A\",\n        \"collection_date\": \"2019-01\",\n        \"collection_country\": \"Mozambique\"\n    },\n    \"SRR26819139\": {\n        \"experiment_sample_id\": \"SRR26819139\",\n        \"sequencing_info_id\": \"run1\",\n        \"specimen_id\": \"SAMN38241215\",\n        \"panel_id\": \"Mad4hatter\",\n        \"plate_col\": 2,\n        \"plate_name\": \"plate1\",\n        \"plate_row\": \"A\",\n\n\n\n\n\nMicrohaplotype Information\nNext, we’ll organize the microhaplotype information into the required format.\nThis involves two components that we will generate from one table(click on the links to find out more information about each part):\n\nThe representative microhaplotype details: A summary of all of unique microhaplotypes called within the population you have included in your PMO for each target. Each unique microhaplotype will be assigned a short ID within PMO to improve the scalability of the format.\nThe detected microhaplotypes: Microhaplotypes called for each sample for each target and the associated reads. This will be linked to the above table using the generated microhaplotype ID instead of the full microhaplotype sequence.\n\nFirst we will load an example allele table that may be similar to something you have from your own microhaplotype pipeline. This table includes a sampleID, the target, and the ASV and number of reads detected for each of these.\n\n\nCode\nexample_allele_table = pd.read_csv(allele_table_path, sep='\\t')\nexample_allele_table.head()\n\n\n\n\n\n\n\n\n\nSampleID\nLocus\nASV\nReads\nAllele\nPseudoCIGAR\n\n\n\n\n0\nSRR26819553\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n13\nPf3D7_01_v3-145388-145662-1A.1\n25+25N169+8N188+9N\n\n\n1\nSRR26819207\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n4\nPf3D7_01_v3-145388-145662-1A.2\n25+25N94A139T169+8N188+9N\n\n\n2\nSRR26819545\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n22\nPf3D7_01_v3-145388-145662-1A.1\n25+25N169+8N188+9N\n\n\n3\nSRR26819527\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n1\nPf3D7_01_v3-145388-145662-1A.2\n25+25N94A139T169+8N188+9N\n\n\n4\nSRR26819214\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n14\nPf3D7_01_v3-145388-145662-1A.3\n25+25N139T169+8N188+9N\n\n\n\n\n\n\n\nLet’s have a look at the function we will use to create this part of PMO microhaplotype_table_to_pmo_dict\n\n\nCode\nprint(microhaplotype_table_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe of a microhaplotype calls into a dictionary containing a dictionary for the haplotypes_detected and a dictionary for the representative_haplotype_sequences.\n\n    :param contents: The dataframe containing microhaplotype calls\n    :param bioinfo_id: the bioinformatics ID of the microhaplotype table\n    :param sampleID_col: the name of the column containing the sample IDs\n    :param locus_col: the name of the column containing the locus IDs\n    :param mhap_col: the name of the column containing the microhaplotype sequence\n    :param reads_col: the name of the column containing the reads counts\n    :param additional_hap_detected_cols: optional additional columns to add to the microhaplotype detected dictionary, the key is the pandas column and the value is what to name it in the output\n    :return: a dict of both the haplotypes_detected and representative_haplotype_sequences\n    \n\n\nWe can see that we need a dataframe with columns for sample IDs, locus names, microhaplotype sequences, and their corresponding read counts. We also need to supply a unique bioinformatics ID. Including this ID allows us to store results from multiple bioinformatics pipelines run on the same sequencing data in a unified format if necessary.\nHere we set a bioinformatics ID, so we can use the same one when generating other tables later on.\n\n\nCode\nbioinfo_id = \"Mozambique2018-MAD4HatTeR\"\n\n\nThe function has default column names that align with the standard output from DADA2. However, since we’re using MAD4HatTeR data, which has slightly different column headers, we’ll need to specify these column names explicitly in the function.\n\n\nCode\nmicrohaplotype_info = microhaplotype_table_to_pmo_dict(\n    example_allele_table,\n    sampleID_col=\"SampleID\",\n    locus_col=\"Locus\",\n    mhap_col=\"ASV\",\n    reads_col=\"Reads\",\n    bioinfo_id=bioinfo_id,\n)\n\n\n\n\nDemultiplexed Experiment Samples\nWe also include information on the demultiplexed reads for each Sample for each target using a function called demultiplexed_targets_to_pmo_dict.\n\n\nCode\nprint(demultiplexed_targets_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe of microhaplotype calls into a dictionary for detected haplotypes \n    and representative haplotype sequences.\n\n    :param contents: DataFrame containing demultiplexed sample information\n    :param bioinfo_id: Bioinformatics ID of the demultiplexed targets\n    :param sampleID_col: Name of the column containing sample IDs\n    :param target_id_col: Name of the column containing locus IDs\n    :param read_count_col: Name of the column containing read counts\n    :param additional_hap_detected_cols: Optional columns to include in the output,\n                                         with keys as column names and values as their output names\n    :return: JSON string containing the processed data\n    \n\n\n\n\nCode\namplicon_coverage = pd.read_csv(demultiplexed_reads_path, sep='\\t')\namplicon_coverage.head()\n\n\n\n\n\n\n\n\n\nSampleID\nLocus\nReads\nOutputDada2\nOutputPostprocessing\n\n\n\n\n0\nSRR26819135\nPf3D7_01_v3-145388-145662-1A\n54\n54\n54\n\n\n1\nSRR26819135\nPf3D7_01_v3-162867-163115-1A\n400\n398\n398\n\n\n2\nSRR26819135\nPf3D7_01_v3-181512-181761-1A\n266\n266\n266\n\n\n3\nSRR26819135\nPf3D7_01_v3-455794-456054-1A\n81\n80\n80\n\n\n4\nSRR26819135\nPf3D7_01_v3-528859-529104-1A\n485\n485\n485\n\n\n\n\n\n\n\nNote that we use the same bioinfo_id that we set above.\n\n\nCode\ndemultiplexed_targets_pmo = demultiplexed_targets_to_pmo_dict(amplicon_coverage, bioinfo_id,  sampleID_col = 'SampleID', target_id_col='Locus',read_count_col ='Reads')\n\n\n\n\nCode\nprint_json_head(demultiplexed_targets_pmo, 15)\n\n\n{\n    \"target_demultiplexed_experiment_samples\": {\n        \"Mozambique2018-MAD4HatTeR\": {\n            \"demultiplexed_experiment_samples\": {\n                \"SRR26819135\": {\n                    \"demultiplexed_targets\": {\n                        \"experiment_sample_id\": \"SRR26819135\",\n                        \"Pf3D7_01_v3-145388-145662-1A\": {\n                            \"raw_read_count\": 54,\n                            \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\"\n                        },\n                        \"Pf3D7_01_v3-162867-163115-1A\": {\n                            \"raw_read_count\": 400,\n                            \"target_id\": \"Pf3D7_01_v3-162867-163115-1A\"\n                        },\n\n\n\n\nSequencing info\nPMO includes details of the sequencing run. Below is an example and more information on the required fields can be found here\n\n\nCode\nsequencing_infos ={\n        \"Mozambique2018\" : \n        {\n            \"lib_kit\" : \"TruSeq i5/i7 barcode primers\",\n            \"lib_layout\" : \"paired-end\",\n            \"lib_screen\" : \"40 µL reaction containing 10 µL of bead purified digested product, 18μL of nuclease-free water, 8μL of 5X secondary PCR master mix, and 5 µL of 10 µM TruSeq i5/i7 barcode primers\",\n            \"nucl_acid_amp\" : \"https://www.paragongenomics.com/targeted-sequencing/amplicon-sequencing/cleanplex-ngs-amplicon-sequencing/\",\n            \"nucl_acid_date\" : \"2019-07-15\",\n            \"nucl_acid_ext\" : \"https://www.paragongenomics.com/targeted-sequencing/amplicon-sequencing/cleanplex-ngs-amplicon-sequencing/\",\n            \"pcr_cond\" : \"10 min at 95°C, 13 cycles for high density samples (or 15 cycles for low density samples) of 15 sec at 98°C and 75 sec at 60°C\",\n            \"seq_center\" : \"UCSF\",\n            \"seq_date\" : \"2019-07-15\",\n            \"seq_instrument\" : \"NextSeq 550 instrument\",\n            \"sequencing_info_id\" : \"run1\"\n        }\n    }\n\n\n\n\nBioinformatics Info\nNow we manually enter some information on the bioinformatics run. More information on the fields can be found here. Below is an example from the MAD4HatTeR pipeline.\n\n\nCode\ntaramp_bioinformatics_infos = {\n    bioinfo_id : \n    {\n        \"demultiplexing_method\" : \n        {\n            \"program\" : \"Cutadapt extractorPairedEnd\",\n            \"purpose\" : \"Takes raw paired-end reads and demultiplexes on primers and does QC filtering\",\n            \"version\" : \"v4.4\"\n        },\n        \"denoising_method\" : \n        {\n            \"program\" : \"DADA2\",\n            \"purpose\" : \"Takes sequences per sample per target and clusters them\",\n            \"version\" : \"v3.16\"\n        },\n        \"tar_amp_bioinformatics_info_id\" : bioinfo_id\n    }\n}"
  }
]