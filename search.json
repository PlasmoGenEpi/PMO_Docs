[
  {
    "objectID": "References.html",
    "href": "References.html",
    "title": "References",
    "section": "",
    "text": "Crystal-Ornelas, Robert, Charuleka Varadharajan, Dylan O’Ryan, Kathleen Beilsmith, Benjamin Bond-Lamberty, Kristin Boye, Madison Burrus, et al. 2022. “Enabling FAIR Data in Earth and Environmental Science with Community-Centric (Meta)data Reporting Formats.” Sci Data 9 (1): 700.\n\n\nOldoni, Fabio, Kenneth K Kidd, and Daniele Podini. 2019. “Microhaplotypes in Forensic Genetics.” Forensic Sci. Int. Genet. 38 (January): 54–69.\n\n\n“SRA Metadata and Submission Overview.” n.d. https://www.ncbi.nlm.nih.gov/sra/docs/submitmeta/.\n\n\nTessema, Sofonias K, Nicholas J Hathaway, Noam B Teyssier, Maxwell Murphy, Anna Chen, Ozkan Aydemir, Elias M Duarte, et al. 2022. “Sensitive, Highly Multiplexed Sequencing of Microhaplotypes from the Plasmodium Falciparum Heterozygome.” J. Infect. Dis. 225 (April): 1227–37.\n\n\nVangay Pajau, Burgin Josephine, Johnston Anjanette, Beck Kristen L., Berrios Daniel C., Blumberg Kai, Canon Shane, et al. 2021. “Microbiome Metadata Standards: Report of the National Microbiome Data Collaborative’s Workshop and Follow-On Activities.” mSystems 6 (1): e01194–20.\n\n\nWeisenhorn, Pamela, and Kathleen Beilsmith. 2022. “ESS-DIVE Reporting Format for Amplicon Abundance Table.” Environmental System Science Data Infrastructure for a Virtual Ecosystem; Environmental Systems Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE).\n\n\nYilmaz, Pelin, Renzo Kottmann, Dawn Field, Rob Knight, James R Cole, Linda Amaral-Zettler, Jack A Gilbert, et al. 2011. “Minimum Information about a Marker Gene Sequence (MIMARKS) and Minimum Information about Any (x) Sequence (MIxS) Specifications.” Nat. Biotechnol. 29 (5): 415–20."
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html",
    "title": "Getting basic info out of a PMO",
    "section": "",
    "text": "Code\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\npmo = PMOReader.read_in_pmo(\"../format/moz2018_PMO.json.gz\")"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-sample-counts-per-target",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-sample-counts-per-target",
    "title": "Getting basic info out of a PMO",
    "section": "Getting sample counts per target",
    "text": "Getting sample counts per target\n\n\nCode\n# get counts of the samples per target\ncounts_df = PMOExtractor.count_samples_per_target(pmo)\n\nprint(counts_df)\n\n\n   tar_amp_bioinformatics_info_id target_id sample_number\n0         Mozambique2018-SeekDeep        t1           119\n0         Mozambique2018-SeekDeep       t10           117\n0         Mozambique2018-SeekDeep      t100           124\n0         Mozambique2018-SeekDeep       t11           120\n0         Mozambique2018-SeekDeep       t12           119\n..                            ...       ...           ...\n0         Mozambique2018-SeekDeep       t96           119\n0         Mozambique2018-SeekDeep       t97           122\n0         Mozambique2018-SeekDeep       t98           122\n0         Mozambique2018-SeekDeep       t99           120\n0         Mozambique2018-SeekDeep       t76            32\n\n[100 rows x 3 columns]"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-target-counts-per-sample",
    "href": "pmotools-python-usages-notebooks/getting_basic_info_on_pmo_file.html#getting-target-counts-per-sample",
    "title": "Getting basic info out of a PMO",
    "section": "Getting target counts per sample",
    "text": "Getting target counts per sample\n\n\nCode\n# get counts of the samples per target\ntarget_counts_df = PMOExtractor.count_targets_per_sample(pmo)\nprint(target_counts_df)\n\n\n   tar_amp_bioinformatics_info_id experiment_sample_id target_number\n0         Mozambique2018-SeekDeep           8025874217            99\n0         Mozambique2018-SeekDeep           8025874231            99\n0         Mozambique2018-SeekDeep           8025874234            97\n0         Mozambique2018-SeekDeep           8025874237            99\n0         Mozambique2018-SeekDeep           8025874250            98\n..                            ...                  ...           ...\n0         Mozambique2018-SeekDeep           SS1-10K-C1            98\n0         Mozambique2018-SeekDeep           SS2-10K-C1            98\n0         Mozambique2018-SeekDeep           SS3-10K-C1            98\n0         Mozambique2018-SeekDeep           SS4-10K-C1            99\n0         Mozambique2018-SeekDeep           SS5-10K-C1            97\n\n[124 rows x 3 columns]"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "To get simple counts of number of targets with sample counts, samples with target counts, the counts of meta fields\nMost of these basic info extractor can be found underneath extract_basic_info_from_pmo\n\nCodepmotools-runner.py\n\n\n\n\npmotools v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (pmo) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to JSON Meta\n    terra_amp_output_to_json - Convert terra output table to JSON seq table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract from PMO samples and associated haplotypes with selected meta\n    extract_pmo_with_select_specimen_ids - Extract from PMO specific samples from the specimens table\n    extract_pmo_with_select_experiment_sample_ids - Extract from PMO specific experiment sample ids from the experiment_info table\n    extract_pmo_with_select_targets - Extract from PMO specific targets\n    extract_pmo_with_read_filter - Extract from PMO with a read filter\n    extract_allele_table - Extract allele tables which can be as used as input to such tools as dcifer or moire\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple pmos of the same panel into a single pmo\n\nextract_basic_info_from_pmo\n    list_experiment_sample_ids_per_specimen_id - Each specimen_id can have multiple experiment_sample_ids, list out all in a PMO\n    list_specimen_meta_fields - List out the specimen meta fields in the specimen_info section\n    list_tar_amp_bioinformatics_info_ids - List out all the tar_amp_bioinformatics_info_ids in a PMO file\n    count_specimen_meta - Count the values of specific specimen meta fields in the specimen_info section\n    count_targets_per_sample - Count the number of targets per sample\n    count_samples_per_target - Count the number of samples per target\n\nextract_panel_info_from_pmo\n    extract_insert_of_panels - Extract the insert of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract the ref_seq of panels from a PMO\n\n\nGetting files for examples\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nThis will list all the meta fields within the specimen_infos section of a PMO file. Since not all meta fields are always present in all specimens, this will list the count of samples each field appears in and the number of total specimens\n\nCodepmotools-runner.py list_specimen_meta_fields -h \n\nusage: pmotools-runner.py list_specimen_meta_fields [-h] --file FILE\n                                                    [--output OUTPUT]\n                                                    [--delim DELIM]\n                                                    [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_specimen_meta_fields script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/list_specimen_meta_fields.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_specimen_meta_fields():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n\n    return parser.parse_args()\n\ndef list_specimen_meta_fields():\n    args = parse_args_list_specimen_meta_fields()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    counts_df = PMOExtractor.count_specimen_meta_fields(pmo)\n\n    # output\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\nif __name__ == \"__main__\":\n    list_specimen_meta_fields()\n\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz\n\nfield   presentInSpecimensCount totalSpecimenCount\ncollection_country  124 124\ncollection_date 124 124\ncollector   124 124\ngeo_admin3  124 124\nhost_taxon_id   124 124\nlat_lon 124 124\nparasite_density    124 124\nplate_col   81  124\nplate_name  81  124\nplate_row   81  124\nproject_name    124 124\nsamp_collect_device 124 124\nsamp_store_loc  124 124\nsamp_taxon_id   124 124\nspecimen_id 124 124\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz --output spec_fields_moz2018_PMO.tsv --overwrite\n\n\n\nThis will list all the meta values (and the combinations) for the meta fields within the specimen_infos section of a PMO file.\n\nCodepmotools-runner.py count_specimen_meta -h \n\nusage: pmotools-runner.py count_specimen_meta [-h] --file FILE\n                                              [--output OUTPUT]\n                                              [--delim DELIM] [--overwrite]\n                                              --meta_fields META_FIELDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --meta_fields META_FIELDS\n                        the fields to count the subfields of, can supply\n                        multiple separated by commas, e.g. --meta_fields\n                        collection_country,collection_date\n\n\nThe python code for count_specimen_meta script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_specimen_meta.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_specimen_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--meta_fields', type=str, required=True, help='the fields to count the subfields of, can supply multiple separated by commas, e.g. --meta_fields collection_country,collection_date')\n\n    return parser.parse_args()\n\n\ndef count_specimen_meta():\n    args = parse_args_count_specimen_meta()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # process the meta_fields argument\n    meta_fields_toks = args.meta_fields.split(',')\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count sub-fields\n    counts_df = PMOExtractor.count_specimen_meta_subfields(pmo, meta_fields_toks)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_specimen_meta()\n\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country\n\ncollection_country  specimensCount  specimensFreq   totalSpecimenCount\nMozambique  81  0.6532258064516129  124\nNA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country --overwrite --output collection_country_count_moz2018_PMO.tsv.gz \n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country,geo_admin3\n\ncollection_country  geo_admin3  specimensCount  specimensFreq   totalSpecimenCount\nMozambique  Inhassoro   27  0.21774193548387097 124\nMozambique  Mandlakazi  28  0.22580645161290322 124\nMozambique  Namaacha    26  0.20967741935483872 124\nNA  NA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz --meta_fields collection_country,collection_date | head\n\ncollection_country  collection_date specimensCount  specimensFreq   totalSpecimenCount\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    51  0.002624401790768281    19433\nBangladesh  2015    508 0.026141100190397778    19433\nBangladesh  2016    816 0.041990428652292494    19433\nBangladesh  2017    12  0.0006175063037101837   19433\nBenin   2014    41  0.002109813204343128    19433\nBenin   2016    117 0.006020686461174291    19433\nBrazil  1980    1   5.145885864251531e-05   19433\n\n\n\nThis will simply list out all the analyses (all the tar_amp_bioinformatics_info_ids) stored within a PMO\n\nCodepmotools-runner.py list_tar_amp_bioinformatics_info_ids -h \n\nusage: pmotools-runner.py list_tar_amp_bioinformatics_info_ids\n       [-h] --file FILE [--output OUTPUT] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_tar_amp_bioinformatics_info_ids script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/list_tar_amp_bioinformatics_info_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_tar_amp_bioinformatics_info_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n\n    return parser.parse_args()\n\ndef list_tar_amp_bioinformatics_info_ids():\n    args = parse_args_list_tar_amp_bioinformatics_info_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract all taramp_bioinformatics_ids\n    bioids = pmo[\"taramp_bioinformatics_infos\"].keys()\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\n\".join(bioids) + \"\\n\")\n\n\n\n\nif __name__ == \"__main__\":\n    list_tar_amp_bioinformatics_info_ids()\n\n\n\n\nCodecd example \npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file ../../format/moz2018_PMO.json.gz  \n\nMozambique2018-SeekDeep\n\n\n\nCodecd example \npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file ../../format/PathWeaverHeome1_PMO.json.gz \n\nPathWeaverHeome1\n\n\nThis can be helpful after combining PMOs\n\nCodecd example \n\npmotools-runner.py combine_pmos --pmo_files ../../format/moz2018_PMO.json.gz,../../format/PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file combined_Heome1_PMO.json.gz \n\n\n\n\nMozambique2018-SeekDeep\nPathWeaverHeome1\n\n\n\nCount up the number targets each experimental_sample_id has. A read filter can be applied to see how targets would be kept if such a filter was applied\n\nCodepmotools-runner.py count_targets_per_sample -h \n\nusage: pmotools-runner.py count_targets_per_sample [-h] --file FILE\n                                                   [--output OUTPUT]\n                                                   [--delim DELIM]\n                                                   [--overwrite]\n                                                   [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_targets_per_sample script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_targets_per_sample.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_targets_per_sample():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=False, help='the minimum read count (inclusive) to be counted as covered by sample')\n\n    return parser.parse_args()\n\n\ndef count_targets_per_sample():\n    args = parse_args_count_targets_per_sample()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOExtractor.count_targets_per_sample(pmo, args.read_count_minimum)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_targets_per_sample()\n\n\n\n\nCodecd example \n\npmotools-runner.py count_targets_per_sample --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  experiment_sample_id    target_number\nMozambique2018-SeekDeep 8025874217  99\nMozambique2018-SeekDeep 8025874231  99\nMozambique2018-SeekDeep 8025874234  97\nMozambique2018-SeekDeep 8025874237  99\nMozambique2018-SeekDeep 8025874250  98\nMozambique2018-SeekDeep 8025874253  99\nMozambique2018-SeekDeep 8025874261  99\nMozambique2018-SeekDeep 8025874266  85\nMozambique2018-SeekDeep 8025874271  99\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-runner.py count_targets_per_sample --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  experiment_sample_id    target_number\nMozambique2018-SeekDeep 8025874217  99\nMozambique2018-SeekDeep 8025874231  73\nMozambique2018-SeekDeep 8025874234  93\nMozambique2018-SeekDeep 8025874237  98\nMozambique2018-SeekDeep 8025874250  68\nMozambique2018-SeekDeep 8025874253  99\nMozambique2018-SeekDeep 8025874261  98\nMozambique2018-SeekDeep 8025874266  37\nMozambique2018-SeekDeep 8025874271  98\n\n\n\nCount up the number of experimental_sample_ids each target has. A read filter can be applied to see how many samples a taget would have if a filter was applied\n\nCodepmotools-runner.py count_samples_per_target -h \n\nusage: pmotools-runner.py count_samples_per_target [-h] --file FILE\n                                                   [--output OUTPUT]\n                                                   [--delim DELIM]\n                                                   [--overwrite]\n                                                   [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_samples_per_target script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_samples_per_target.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_samples_per_target():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=False, help='the minimum read count (inclusive) to be counted as covered by sample')\n\n    return parser.parse_args()\n\n\ndef count_samples_per_target():\n    args = parse_args_count_samples_per_target()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOExtractor.count_samples_per_target(pmo, args.read_count_minimum)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_samples_per_target()\n\n\n\n\nCodecd example \n\npmotools-runner.py count_samples_per_target --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  target_id   sample_number\nMozambique2018-SeekDeep t1  119\nMozambique2018-SeekDeep t10 117\nMozambique2018-SeekDeep t100    124\nMozambique2018-SeekDeep t11 120\nMozambique2018-SeekDeep t12 119\nMozambique2018-SeekDeep t13 124\nMozambique2018-SeekDeep t14 118\nMozambique2018-SeekDeep t15 119\nMozambique2018-SeekDeep t16 121\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-runner.py count_samples_per_target --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  target_id   sample_number\nMozambique2018-SeekDeep t1  108\nMozambique2018-SeekDeep t10 107\nMozambique2018-SeekDeep t100    107\nMozambique2018-SeekDeep t11 111\nMozambique2018-SeekDeep t12 104\nMozambique2018-SeekDeep t13 105\nMozambique2018-SeekDeep t14 110\nMozambique2018-SeekDeep t15 110\nMozambique2018-SeekDeep t16 106"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_specimen_meta_fields",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_specimen_meta_fields",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will list all the meta fields within the specimen_infos section of a PMO file. Since not all meta fields are always present in all specimens, this will list the count of samples each field appears in and the number of total specimens\n\nCodepmotools-runner.py list_specimen_meta_fields -h \n\nusage: pmotools-runner.py list_specimen_meta_fields [-h] --file FILE\n                                                    [--output OUTPUT]\n                                                    [--delim DELIM]\n                                                    [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --delim DELIM    the delimiter of the output text file, examples input\n                   tab,comma but can also be the actual delimiter\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_specimen_meta_fields script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/list_specimen_meta_fields.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_specimen_meta_fields():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n\n    return parser.parse_args()\n\ndef list_specimen_meta_fields():\n    args = parse_args_list_specimen_meta_fields()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count fields\n    counts_df = PMOExtractor.count_specimen_meta_fields(pmo)\n\n    # output\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\nif __name__ == \"__main__\":\n    list_specimen_meta_fields()\n\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz\n\nfield   presentInSpecimensCount totalSpecimenCount\ncollection_country  124 124\ncollection_date 124 124\ncollector   124 124\ngeo_admin3  124 124\nhost_taxon_id   124 124\nlat_lon 124 124\nparasite_density    124 124\nplate_col   81  124\nplate_name  81  124\nplate_row   81  124\nproject_name    124 124\nsamp_collect_device 124 124\nsamp_store_loc  124 124\nsamp_taxon_id   124 124\nspecimen_id 124 124\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/moz2018_PMO.json.gz --output spec_fields_moz2018_PMO.tsv --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_specimen_meta",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_specimen_meta",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will list all the meta values (and the combinations) for the meta fields within the specimen_infos section of a PMO file.\n\nCodepmotools-runner.py count_specimen_meta -h \n\nusage: pmotools-runner.py count_specimen_meta [-h] --file FILE\n                                              [--output OUTPUT]\n                                              [--delim DELIM] [--overwrite]\n                                              --meta_fields META_FIELDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --meta_fields META_FIELDS\n                        the fields to count the subfields of, can supply\n                        multiple separated by commas, e.g. --meta_fields\n                        collection_country,collection_date\n\n\nThe python code for count_specimen_meta script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_specimen_meta.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_specimen_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--meta_fields', type=str, required=True, help='the fields to count the subfields of, can supply multiple separated by commas, e.g. --meta_fields collection_country,collection_date')\n\n    return parser.parse_args()\n\n\ndef count_specimen_meta():\n    args = parse_args_count_specimen_meta()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # process the meta_fields argument\n    meta_fields_toks = args.meta_fields.split(',')\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count sub-fields\n    counts_df = PMOExtractor.count_specimen_meta_subfields(pmo, meta_fields_toks)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_specimen_meta()\n\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country\n\ncollection_country  specimensCount  specimensFreq   totalSpecimenCount\nMozambique  81  0.6532258064516129  124\nNA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country --overwrite --output collection_country_count_moz2018_PMO.tsv.gz \n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/moz2018_PMO.json.gz --meta_fields collection_country,geo_admin3\n\ncollection_country  geo_admin3  specimensCount  specimensFreq   totalSpecimenCount\nMozambique  Inhassoro   27  0.21774193548387097 124\nMozambique  Mandlakazi  28  0.22580645161290322 124\nMozambique  Namaacha    26  0.20967741935483872 124\nNA  NA  43  0.3467741935483871  124\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz --meta_fields collection_country,collection_date | head\n\ncollection_country  collection_date specimensCount  specimensFreq   totalSpecimenCount\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    51  0.002624401790768281    19433\nBangladesh  2015    508 0.026141100190397778    19433\nBangladesh  2016    816 0.041990428652292494    19433\nBangladesh  2017    12  0.0006175063037101837   19433\nBenin   2014    41  0.002109813204343128    19433\nBenin   2016    117 0.006020686461174291    19433\nBrazil  1980    1   5.145885864251531e-05   19433"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_tar_amp_bioinformatics_info_ids",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#list_tar_amp_bioinformatics_info_ids",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "This will simply list out all the analyses (all the tar_amp_bioinformatics_info_ids) stored within a PMO\n\nCodepmotools-runner.py list_tar_amp_bioinformatics_info_ids -h \n\nusage: pmotools-runner.py list_tar_amp_bioinformatics_info_ids\n       [-h] --file FILE [--output OUTPUT] [--overwrite]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for list_tar_amp_bioinformatics_info_ids script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/list_tar_amp_bioinformatics_info_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_list_tar_amp_bioinformatics_info_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n\n    return parser.parse_args()\n\ndef list_tar_amp_bioinformatics_info_ids():\n    args = parse_args_list_tar_amp_bioinformatics_info_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract all taramp_bioinformatics_ids\n    bioids = pmo[\"taramp_bioinformatics_infos\"].keys()\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\n\".join(bioids) + \"\\n\")\n\n\n\n\nif __name__ == \"__main__\":\n    list_tar_amp_bioinformatics_info_ids()\n\n\n\n\nCodecd example \npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file ../../format/moz2018_PMO.json.gz  \n\nMozambique2018-SeekDeep\n\n\n\nCodecd example \npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file ../../format/PathWeaverHeome1_PMO.json.gz \n\nPathWeaverHeome1\n\n\nThis can be helpful after combining PMOs\n\nCodecd example \n\npmotools-runner.py combine_pmos --pmo_files ../../format/moz2018_PMO.json.gz,../../format/PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\npmotools-runner.py list_tar_amp_bioinformatics_info_ids --file combined_Heome1_PMO.json.gz \n\n\n\n\nMozambique2018-SeekDeep\nPathWeaverHeome1"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_targets_per_sample",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_targets_per_sample",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "Count up the number targets each experimental_sample_id has. A read filter can be applied to see how targets would be kept if such a filter was applied\n\nCodepmotools-runner.py count_targets_per_sample -h \n\nusage: pmotools-runner.py count_targets_per_sample [-h] --file FILE\n                                                   [--output OUTPUT]\n                                                   [--delim DELIM]\n                                                   [--overwrite]\n                                                   [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_targets_per_sample script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_targets_per_sample.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_targets_per_sample():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=False, help='the minimum read count (inclusive) to be counted as covered by sample')\n\n    return parser.parse_args()\n\n\ndef count_targets_per_sample():\n    args = parse_args_count_targets_per_sample()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOExtractor.count_targets_per_sample(pmo, args.read_count_minimum)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_targets_per_sample()\n\n\n\n\nCodecd example \n\npmotools-runner.py count_targets_per_sample --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  experiment_sample_id    target_number\nMozambique2018-SeekDeep 8025874217  99\nMozambique2018-SeekDeep 8025874231  99\nMozambique2018-SeekDeep 8025874234  97\nMozambique2018-SeekDeep 8025874237  99\nMozambique2018-SeekDeep 8025874250  98\nMozambique2018-SeekDeep 8025874253  99\nMozambique2018-SeekDeep 8025874261  99\nMozambique2018-SeekDeep 8025874266  85\nMozambique2018-SeekDeep 8025874271  99\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-runner.py count_targets_per_sample --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  experiment_sample_id    target_number\nMozambique2018-SeekDeep 8025874217  99\nMozambique2018-SeekDeep 8025874231  73\nMozambique2018-SeekDeep 8025874234  93\nMozambique2018-SeekDeep 8025874237  98\nMozambique2018-SeekDeep 8025874250  68\nMozambique2018-SeekDeep 8025874253  99\nMozambique2018-SeekDeep 8025874261  98\nMozambique2018-SeekDeep 8025874266  37\nMozambique2018-SeekDeep 8025874271  98"
  },
  {
    "objectID": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_samples_per_target",
    "href": "pmotools-python-usages/getting_basic_info_from_pmo.html#count_samples_per_target",
    "title": "Getting basic info out of PMO using pmotools-python",
    "section": "",
    "text": "Count up the number of experimental_sample_ids each target has. A read filter can be applied to see how many samples a taget would have if a filter was applied\n\nCodepmotools-runner.py count_samples_per_target -h \n\nusage: pmotools-runner.py count_samples_per_target [-h] --file FILE\n                                                   [--output OUTPUT]\n                                                   [--delim DELIM]\n                                                   [--overwrite]\n                                                   [--read_count_minimum READ_COUNT_MINIMUM]\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       output file\n  --delim DELIM         the delimiter of the output text file, examples input\n                        tab,comma but can also be the actual delimiter\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) to be counted as\n                        covered by sample\n\n\nThe python code for count_samples_per_target script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/count_samples_per_target.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_count_samples_per_target():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the output text file, examples input tab,comma but can also be the actual delimiter')\n    parser.add_argument('--overwrite', action='store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=False, help='the minimum read count (inclusive) to be counted as covered by sample')\n\n    return parser.parse_args()\n\n\ndef count_samples_per_target():\n    args = parse_args_count_samples_per_target()\n\n    # check files\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith(\".gz\"))\n    args.output = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # count\n    counts_df = PMOExtractor.count_samples_per_target(pmo, args.read_count_minimum)\n\n    #write out\n    counts_df.to_csv(sys.stdout if \"STDOUT\" == args.output else args.output, sep = output_delim, index=False)\n\n\nif __name__ == \"__main__\":\n    count_samples_per_target()\n\n\n\n\nCodecd example \n\npmotools-runner.py count_samples_per_target --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  target_id   sample_number\nMozambique2018-SeekDeep t1  119\nMozambique2018-SeekDeep t10 117\nMozambique2018-SeekDeep t100    124\nMozambique2018-SeekDeep t11 120\nMozambique2018-SeekDeep t12 119\nMozambique2018-SeekDeep t13 124\nMozambique2018-SeekDeep t14 118\nMozambique2018-SeekDeep t15 119\nMozambique2018-SeekDeep t16 121\n\n\nApply a read count minimum filter (this a total read count summed for a target and not on a haplotype level)\n\nCodecd example \n\npmotools-runner.py count_samples_per_target --read_count_minimum 3000 --file ../../format/moz2018_PMO.json.gz  | head\n\ntar_amp_bioinformatics_info_id  target_id   sample_number\nMozambique2018-SeekDeep t1  108\nMozambique2018-SeekDeep t10 107\nMozambique2018-SeekDeep t100    107\nMozambique2018-SeekDeep t11 111\nMozambique2018-SeekDeep t12 104\nMozambique2018-SeekDeep t13 105\nMozambique2018-SeekDeep t14 110\nMozambique2018-SeekDeep t15 110\nMozambique2018-SeekDeep t16 106"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html",
    "href": "pmotools-python-usages/subsetting_from_PMO.html",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "There may be some instances were you want to subset a much larger PMO file into a smaller PMO file to focus only one a set of samples and/or targets. There are several ways of doing this.\n\nCan subset to only specific targets by using pmotools-runner.py extract_pmo_with_select_targets\n\nCodepmotools-runner.py extract_pmo_with_select_targets -h\n\nusage: pmotools-runner.py extract_pmo_with_select_targets [-h] --file FILE\n                                                          --output OUTPUT\n                                                          [--overwrite]\n                                                          [--verbose]\n                                                          --targets TARGETS\n\noptions:\n  -h, --help         show this help message and exit\n  --file FILE        PMO file\n  --output OUTPUT    Output json file path\n  --overwrite        If output file exists, overwrite it\n  --verbose          write out various messages about extraction\n  --targets TARGETS  Can either comma separated target_ids, or a plain text\n                     file where each line is a target_ids\n\n\nThe python code for extract_pmo_with_select_targets script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_targets.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_targets():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--targets', type=str, required=True, help='Can either comma separated target_ids, or a plain text file where each line is a target_ids')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_targets():\n    args = parse_args_extract_pmo_with_select_targets()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse target ids\n    all_target_ids = Utils.parse_delimited_input_or_file(args.targets)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_targets(pmo, all_target_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_targets()\n\n\n\nYou can extract by supplies the desired targets with comma separated values on the command line\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets t1,t20,t31  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\nYou can also provide a single column file where each line is a desired target\n\nCodecd example \n\necho -e \"t1\\nt20\\nt31\" &gt; select_targets.txt \npmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets select_targets.txt  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\necho -e \"t1\\nt20\\nt31\" | pmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets STDIN --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\n\nYou can subset to just to just select specimen_id, each specimen can have several experiments associated with it, by supplying the specimen_id all associated experiments will also be pulled\nSimilar to above you can supply the specimen_ids either as comma separated values or in a plain text file where each line is a specimen_id\n\nCodepmotools-runner.py extract_pmo_with_select_specimen_ids -h\n\nusage: pmotools-runner.py extract_pmo_with_select_specimen_ids\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --specimen_ids SPECIMEN_IDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --specimen_ids SPECIMEN_IDS\n                        Can either comma separated specimen_ids, or a plain\n                        text file where each line is a specimen_id\n\n\nThe python code for extract_pmo_with_select_specimen_ids script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_specimen_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_specimen_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--specimen_ids', type=str, required=True, help='Can either comma separated specimen_ids, or a plain text file where each line is a specimen_id')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_specimen_ids():\n    args = parse_args_extract_pmo_with_select_specimen_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen ids\n    all_specimen_ids = Utils.parse_delimited_input_or_file(args.specimen_ids)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_specimen_ids(pmo, all_specimen_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_specimen_ids()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids 8025874217,8025875146,8034209589 --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" &gt; select_specimen_ids.txt \n\npmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids select_specimen_ids.txt --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" | pmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids STDIN --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\n\n\nIf you want just specific experiment_sample_id you can supply those instead too\nSimilar to above you can supply the experiment_sample_ids either as comma separated values or in a plain text file where each line is a experiment_sample_id or from standard in (STDIN)\n\nCodepmotools-runner.py extract_pmo_with_select_experiment_sample_ids -h\n\nusage: pmotools-runner.py extract_pmo_with_select_experiment_sample_ids\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --experiment_sample_ids EXPERIMENT_SAMPLE_IDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --experiment_sample_ids EXPERIMENT_SAMPLE_IDS\n                        Can either comma separated experiment_sample_ids, or a\n                        plain text file where each line is a\n                        experiment_sample_id\n\n\nThe python code for extract_pmo_with_select_experiment_sample_ids script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_experiment_sample_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_experiment_sample_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--experiment_sample_ids', type=str, required=True, help='Can either comma separated experiment_sample_ids, or a plain text file where each line is a experiment_sample_id')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_experiment_sample_ids():\n    args = parse_args_extract_pmo_with_select_experiment_sample_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen ids\n    all_experiment_sample_ids = Utils.parse_delimited_input_or_file(args.experiment_sample_ids)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_experiment_sample_ids(pmo, all_experiment_sample_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_experiment_sample_ids()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids 8025875029,8034209834,8034209115 --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025875029\\n8034209834\\n8034209115\" &gt; select_experiment_sample_ids.txt \n  \npmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids select_experiment_sample_ids.txt --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\n\nIf you want to get specific samples that match certain meta fields like specific collection_country or collection_date you can use ``\n\nCodepmotools-runner.py extract_pmo_with_selected_meta -h \n\nusage: pmotools-runner.py extract_pmo_with_selected_meta [-h] --file FILE\n                                                         --output OUTPUT\n                                                         [--overwrite]\n                                                         [--verbose]\n                                                         --metaFieldsValues\n                                                         METAFIELDSVALUES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --metaFieldsValues METAFIELDSVALUES\n                        Meta Fields to include, should either be a table with\n                        columns field, values (and optionally group) or\n                        supplied command line as\n                        field1=value1,value2,value3:field2=value1,value2\n\n\nThe python code for extract_pmo_with_selected_meta script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_selected_meta.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_selected_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--metaFieldsValues', type=str, required=True, help='Meta Fields to include, should either be a table with columns field, values (and optionally group) or supplied command line as field1=value1,value2,value3:field2=value1,value2')\n    return parser.parse_args()\n\ndef extract_pmo_with_selected_meta():\n    args = parse_args_extract_pmo_with_selected_meta()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract out of PMO\n    pmo_out, group_counts = PMOExtractor.extract_from_pmo_samples_with_meta_groupings(pmo, args.metaFieldsValues)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n    if args.verbose:\n        sys.stdout.write(\"Extracted the following number of specimens per group:\" + \"\\n\")\n        group_counts.to_csv(sys.stdout, sep = \"\\t\", index = True)\n\nif __name__ == \"__main__\":\n    extract_pmo_with_selected_meta()\n\n\n\npmotools-runner.py extract_pmo_with_selected_meta is written to allow the extraction on multiple intersecting meta field requirments that can be either supplied in a file or with delimited on the command line\nYou may also want to know what current meta fields are present and how many samples in each. This can be done with pmotools-runner.py list_specimen_meta_fields and pmotools-runner.py count_specimen_meta\n\nCodecd example \nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/PathWeaverHeome1_PMO.json.gz\n\nfield   presentInSpecimensCount totalSpecimenCount\ncollection_country  19433   19433\ncollection_date 19433   19433\ncollector   19433   19433\ngeo_admin3  19433   19433\ngeo_continent   19433   19433\ngeo_region  19433   19433\ngeo_subRegion   19433   19433\nhost_taxon_id   19433   19433\nproject_name    19433   19433\nsamp_collect_device 19433   19433\nsamp_store_loc  19433   19433\nsamp_taxon_id   19433   19433\nspecimen_id 19433   19433\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz  --meta_fields collection_country,collection_date | head -20\n\ncollection_country  collection_date specimensCount  specimensFreq   totalSpecimenCount\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    51  0.002624401790768281    19433\nBangladesh  2015    508 0.026141100190397778    19433\nBangladesh  2016    816 0.041990428652292494    19433\nBangladesh  2017    12  0.0006175063037101837   19433\nBenin   2014    41  0.002109813204343128    19433\nBenin   2016    117 0.006020686461174291    19433\nBrazil  1980    1   5.145885864251531e-05   19433\nBrazil  2016    13  0.000668965162352699    19433\nBrazil  2017    5   0.00025729429321257654  19433\nBrazil  NA  1   5.145885864251531e-05   19433\nBurkina Faso    2008    58  0.002984613801265888    19433\nCambodia    1993    6   0.00030875315185509186  19433\nCambodia    2007    26  0.001337930324705398    19433\nCambodia    2008    50  0.0025729429321257654   19433\nCambodia    2009    66  0.0033962846704060105   19433\nCambodia    2010    182 0.009365512272937786    19433\nCambodia    2011    441 0.02269335666134925 19433\n\n\nExtracting on matching 1 meta field, below will extract just the samples that have collection_country=Bangladesh\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite\n\n\nIf you want to see how many samples were extracted can use --verbose\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite --verbose\n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh  1418\n\n\nCollecting more than 1 matching field separate by comma, for example to extract both Bangladesh,Benin\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin\" --output Bangladesh_Benin_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh,Benin    1576\n\n\nCan add more extraction criteria meta, for example to extract samples with collection_country of Bangladesh or Benin and with collection_date of 2016\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin:collection_date=2016\" --output Bangladesh_Benin_2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh,Benin    2016    933\n\n\nTo get more specific you can group meta field extraction criteria , for example if you wanted samples from Bangladesh from year 2015 but wanted Benin from year 2016 you can separate by a ;\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh:collection_date=2015;collection_country=Benin:collection_date=2016\" --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh  2015    508\n1   Benin   2016    117\n\n\nRather than supplying with the command line a file can be created\n\nCodecd example \n\necho -e \"group\\tfield\\tvalues\" &gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_country\\tBangladesh\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_date\\t2015\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_country\\tBenin\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_date\\t2016\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \n\n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues Bangladesh2015_Benin2016_extractionCriteria.tsv --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\nBangladesh2015  Bangladesh  2015    508\nBenin2016   Benin   2016    117\n\n\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/moz2018_PMO.json.gz --metaFieldsValues \"collection_country=Mozambique:geo_admin3=Inhassoro;collection_country=Mozambique:geo_admin3=Mandlakazi,Namaacha\" --output Mozambique_moz2018_PMO.json.gz  --verbose  --overwrite\n\nExtracted the following number of specimens per group:\ngroup   collection_country  geo_admin3  count\n0   Mozambique  Inhassoro   27\n1   Mozambique  Mandlakazi,Namaacha 54\n\n\n\n\nCodepmotools-runner.py extract_pmo_with_read_filter -h\n\nusage: pmotools-runner.py extract_pmo_with_read_filter [-h] --file FILE\n                                                       --output OUTPUT\n                                                       [--overwrite]\n                                                       --read_count_minimum\n                                                       READ_COUNT_MINIMUM\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) for detected\n                        haplotypes to be kept\n\n\nThe python code for extract_pmo_with_read_filter script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_read_filter.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_read_filter():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=True, help='the minimum read count (inclusive) for detected haplotypes to be kept')\n    return parser.parse_args()\n\ndef extract_pmo_with_read_filter():\n    args = parse_args_extract_pmo_with_read_filter()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_with_read_filter(pmo, args.read_count_minimum)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\nif __name__ == \"__main__\":\n    extract_pmo_with_read_filter()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_minReadCount1000.json.gz --overwrite\n\n\n\nThe extraction methods also allow for STDOUT and STDIN piping for example\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\nCan also pipe into other pmotools-runner.py functions like extracting allele tables\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output alleles_data_t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.tsv.gz --overwrite\n\n\nCan pipe final output to STDOUT as well for further processing\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output STDOUT  --specimen_info_meta_fields specimen_id,collection_country\n\nsampleID    locus   allele  specimen_id collection_country\n8025875029  t1  t1.0    8025875029  Mozambique\n8025875029  t1  t1.1    8025875029  Mozambique\n8025875029  t20 t20.3   8025875029  Mozambique\n8025875029  t20 t20.5   8025875029  Mozambique\n8025875029  t20 t20.4   8025875029  Mozambique\n8025875029  t31 t31.1   8025875029  Mozambique\n8025875029  t31 t31.3   8025875029  Mozambique\n8034209115  t1  t1.2    8034209115  Mozambique\n8034209115  t20 t20.4   8034209115  Mozambique\n8034209115  t20 t20.1   8034209115  Mozambique\n8034209115  t31 t31.1   8034209115  Mozambique\n8034209115  t31 t31.3   8034209115  Mozambique\n8034209834  t1  t1.0    8034209834  Mozambique\n8034209834  t20 t20.1   8034209834  Mozambique\n8034209834  t20 t20.0   8034209834  Mozambique\n8034209834  t31 t31.2   8034209834  Mozambique\n8034209834  t31 t31.0   8034209834  Mozambique\n\n\nfilter to a read amount and then write allele table\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output moz2018_PMO_minReadCount1000_allele_table.tsv.gz  --microhap_fields read_count --representative_haps_fields seq --default_base_col_names specimen_id,target_id,allele --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-targets",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-targets",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "Can subset to only specific targets by using pmotools-runner.py extract_pmo_with_select_targets\n\nCodepmotools-runner.py extract_pmo_with_select_targets -h\n\nusage: pmotools-runner.py extract_pmo_with_select_targets [-h] --file FILE\n                                                          --output OUTPUT\n                                                          [--overwrite]\n                                                          [--verbose]\n                                                          --targets TARGETS\n\noptions:\n  -h, --help         show this help message and exit\n  --file FILE        PMO file\n  --output OUTPUT    Output json file path\n  --overwrite        If output file exists, overwrite it\n  --verbose          write out various messages about extraction\n  --targets TARGETS  Can either comma separated target_ids, or a plain text\n                     file where each line is a target_ids\n\n\nThe python code for extract_pmo_with_select_targets script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_targets.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_targets():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--targets', type=str, required=True, help='Can either comma separated target_ids, or a plain text file where each line is a target_ids')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_targets():\n    args = parse_args_extract_pmo_with_select_targets()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse target ids\n    all_target_ids = Utils.parse_delimited_input_or_file(args.targets)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_targets(pmo, all_target_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_targets()\n\n\n\nYou can extract by supplies the desired targets with comma separated values on the command line\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets t1,t20,t31  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\n\nYou can also provide a single column file where each line is a desired target\n\nCodecd example \n\necho -e \"t1\\nt20\\nt31\" &gt; select_targets.txt \npmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets select_targets.txt  --output t1_t20_t31_moz2018_PMO.json.gz --overwrite\n\necho -e \"t1\\nt20\\nt31\" | pmotools-runner.py extract_pmo_with_select_targets --file ../../format/moz2018_PMO.json.gz --targets STDIN --output t1_t20_t31_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-specimen_ids",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-specimen_ids",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "You can subset to just to just select specimen_id, each specimen can have several experiments associated with it, by supplying the specimen_id all associated experiments will also be pulled\nSimilar to above you can supply the specimen_ids either as comma separated values or in a plain text file where each line is a specimen_id\n\nCodepmotools-runner.py extract_pmo_with_select_specimen_ids -h\n\nusage: pmotools-runner.py extract_pmo_with_select_specimen_ids\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --specimen_ids SPECIMEN_IDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --specimen_ids SPECIMEN_IDS\n                        Can either comma separated specimen_ids, or a plain\n                        text file where each line is a specimen_id\n\n\nThe python code for extract_pmo_with_select_specimen_ids script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_specimen_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_specimen_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--specimen_ids', type=str, required=True, help='Can either comma separated specimen_ids, or a plain text file where each line is a specimen_id')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_specimen_ids():\n    args = parse_args_extract_pmo_with_select_specimen_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen ids\n    all_specimen_ids = Utils.parse_delimited_input_or_file(args.specimen_ids)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_specimen_ids(pmo, all_specimen_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_specimen_ids()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids 8025874217,8025875146,8034209589 --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" &gt; select_specimen_ids.txt \n\npmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids select_specimen_ids.txt --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025874217\\n8025875146\\n8034209589\" | pmotools-runner.py extract_pmo_with_select_specimen_ids --specimen_ids STDIN --file ../../format/moz2018_PMO.json.gz --output 8025874217_8025875146_8034209589_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-experiment_sample_ids",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-specific-experiment_sample_ids",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "If you want just specific experiment_sample_id you can supply those instead too\nSimilar to above you can supply the experiment_sample_ids either as comma separated values or in a plain text file where each line is a experiment_sample_id or from standard in (STDIN)\n\nCodepmotools-runner.py extract_pmo_with_select_experiment_sample_ids -h\n\nusage: pmotools-runner.py extract_pmo_with_select_experiment_sample_ids\n       [-h] --file FILE --output OUTPUT [--overwrite] [--verbose]\n       --experiment_sample_ids EXPERIMENT_SAMPLE_IDS\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --experiment_sample_ids EXPERIMENT_SAMPLE_IDS\n                        Can either comma separated experiment_sample_ids, or a\n                        plain text file where each line is a\n                        experiment_sample_id\n\n\nThe python code for extract_pmo_with_select_experiment_sample_ids script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_select_experiment_sample_ids.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_select_experiment_sample_ids():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--experiment_sample_ids', type=str, required=True, help='Can either comma separated experiment_sample_ids, or a plain text file where each line is a experiment_sample_id')\n    return parser.parse_args()\n\ndef extract_pmo_with_select_experiment_sample_ids():\n    args = parse_args_extract_pmo_with_select_experiment_sample_ids()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # parse specimen ids\n    all_experiment_sample_ids = Utils.parse_delimited_input_or_file(args.experiment_sample_ids)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_select_experiment_sample_ids(pmo, all_experiment_sample_ids)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\n\nif __name__ == \"__main__\":\n    extract_pmo_with_select_experiment_sample_ids()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids 8025875029,8034209834,8034209115 --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\necho -e \"8025875029\\n8034209834\\n8034209115\" &gt; select_experiment_sample_ids.txt \n  \npmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids select_experiment_sample_ids.txt --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output 8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-samples-within-specific-metafields",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-samples-within-specific-metafields",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "If you want to get specific samples that match certain meta fields like specific collection_country or collection_date you can use ``\n\nCodepmotools-runner.py extract_pmo_with_selected_meta -h \n\nusage: pmotools-runner.py extract_pmo_with_selected_meta [-h] --file FILE\n                                                         --output OUTPUT\n                                                         [--overwrite]\n                                                         [--verbose]\n                                                         --metaFieldsValues\n                                                         METAFIELDSVALUES\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --verbose             write out various messages about extraction\n  --metaFieldsValues METAFIELDSVALUES\n                        Meta Fields to include, should either be a table with\n                        columns field, values (and optionally group) or\n                        supplied command line as\n                        field1=value1,value2,value3:field2=value1,value2\n\n\nThe python code for extract_pmo_with_selected_meta script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_selected_meta.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_selected_meta():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--verbose', action = 'store_true', help='write out various messages about extraction')\n    parser.add_argument('--metaFieldsValues', type=str, required=True, help='Meta Fields to include, should either be a table with columns field, values (and optionally group) or supplied command line as field1=value1,value2,value3:field2=value1,value2')\n    return parser.parse_args()\n\ndef extract_pmo_with_selected_meta():\n    args = parse_args_extract_pmo_with_selected_meta()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract out of PMO\n    pmo_out, group_counts = PMOExtractor.extract_from_pmo_samples_with_meta_groupings(pmo, args.metaFieldsValues)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n    if args.verbose:\n        sys.stdout.write(\"Extracted the following number of specimens per group:\" + \"\\n\")\n        group_counts.to_csv(sys.stdout, sep = \"\\t\", index = True)\n\nif __name__ == \"__main__\":\n    extract_pmo_with_selected_meta()\n\n\n\npmotools-runner.py extract_pmo_with_selected_meta is written to allow the extraction on multiple intersecting meta field requirments that can be either supplied in a file or with delimited on the command line\nYou may also want to know what current meta fields are present and how many samples in each. This can be done with pmotools-runner.py list_specimen_meta_fields and pmotools-runner.py count_specimen_meta\n\nCodecd example \nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodecd example \npmotools-runner.py list_specimen_meta_fields --file ../../format/PathWeaverHeome1_PMO.json.gz\n\nfield   presentInSpecimensCount totalSpecimenCount\ncollection_country  19433   19433\ncollection_date 19433   19433\ncollector   19433   19433\ngeo_admin3  19433   19433\ngeo_continent   19433   19433\ngeo_region  19433   19433\ngeo_subRegion   19433   19433\nhost_taxon_id   19433   19433\nproject_name    19433   19433\nsamp_collect_device 19433   19433\nsamp_store_loc  19433   19433\nsamp_taxon_id   19433   19433\nspecimen_id 19433   19433\n\n\n\nCodecd example \npmotools-runner.py count_specimen_meta --file ../../format/PathWeaverHeome1_PMO.json.gz  --meta_fields collection_country,collection_date | head -20\n\ncollection_country  collection_date specimensCount  specimensFreq   totalSpecimenCount\nBangladesh  2008    15  0.0007718828796377296   19433\nBangladesh  2009    16  0.000823341738280245    19433\nBangladesh  2012    51  0.002624401790768281    19433\nBangladesh  2015    508 0.026141100190397778    19433\nBangladesh  2016    816 0.041990428652292494    19433\nBangladesh  2017    12  0.0006175063037101837   19433\nBenin   2014    41  0.002109813204343128    19433\nBenin   2016    117 0.006020686461174291    19433\nBrazil  1980    1   5.145885864251531e-05   19433\nBrazil  2016    13  0.000668965162352699    19433\nBrazil  2017    5   0.00025729429321257654  19433\nBrazil  NA  1   5.145885864251531e-05   19433\nBurkina Faso    2008    58  0.002984613801265888    19433\nCambodia    1993    6   0.00030875315185509186  19433\nCambodia    2007    26  0.001337930324705398    19433\nCambodia    2008    50  0.0025729429321257654   19433\nCambodia    2009    66  0.0033962846704060105   19433\nCambodia    2010    182 0.009365512272937786    19433\nCambodia    2011    441 0.02269335666134925 19433\n\n\nExtracting on matching 1 meta field, below will extract just the samples that have collection_country=Bangladesh\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite\n\n\nIf you want to see how many samples were extracted can use --verbose\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh\" --output Bangladesh_moz2018_PMO.json.gz   --overwrite --verbose\n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh  1418\n\n\nCollecting more than 1 matching field separate by comma, for example to extract both Bangladesh,Benin\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin\" --output Bangladesh_Benin_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  count\n0   Bangladesh,Benin    1576\n\n\nCan add more extraction criteria meta, for example to extract samples with collection_country of Bangladesh or Benin and with collection_date of 2016\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh,Benin:collection_date=2016\" --output Bangladesh_Benin_2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh,Benin    2016    933\n\n\nTo get more specific you can group meta field extraction criteria , for example if you wanted samples from Bangladesh from year 2015 but wanted Benin from year 2016 you can separate by a ;\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues \"collection_country=Bangladesh:collection_date=2015;collection_country=Benin:collection_date=2016\" --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\n0   Bangladesh  2015    508\n1   Benin   2016    117\n\n\nRather than supplying with the command line a file can be created\n\nCodecd example \n\necho -e \"group\\tfield\\tvalues\" &gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_country\\tBangladesh\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Bangladesh2015\\tcollection_date\\t2015\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_country\\tBenin\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \necho -e \"Benin2016\\tcollection_date\\t2016\" &gt;&gt; Bangladesh2015_Benin2016_extractionCriteria.tsv \n\n\npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/PathWeaverHeome1_PMO.json.gz --metaFieldsValues Bangladesh2015_Benin2016_extractionCriteria.tsv --output Bangladesh2015_Benin2016_moz2018_PMO.json.gz   --overwrite --verbose \n\nExtracted the following number of specimens per group:\ngroup   collection_country  collection_date count\nBangladesh2015  Bangladesh  2015    508\nBenin2016   Benin   2016    117\n\n\n\nCodecd example \npmotools-runner.py extract_pmo_with_selected_meta  --file ../../format/moz2018_PMO.json.gz --metaFieldsValues \"collection_country=Mozambique:geo_admin3=Inhassoro;collection_country=Mozambique:geo_admin3=Mandlakazi,Namaacha\" --output Mozambique_moz2018_PMO.json.gz  --verbose  --overwrite\n\nExtracted the following number of specimens per group:\ngroup   collection_country  geo_admin3  count\n0   Mozambique  Inhassoro   27\n1   Mozambique  Mandlakazi,Namaacha 54"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-a-read-filter-for-detected-microhaplotypes",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#subsetting-by-a-read-filter-for-detected-microhaplotypes",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "Codepmotools-runner.py extract_pmo_with_read_filter -h\n\nusage: pmotools-runner.py extract_pmo_with_read_filter [-h] --file FILE\n                                                       --output OUTPUT\n                                                       [--overwrite]\n                                                       --read_count_minimum\n                                                       READ_COUNT_MINIMUM\n\noptions:\n  -h, --help            show this help message and exit\n  --file FILE           PMO file\n  --output OUTPUT       Output json file path\n  --overwrite           If output file exists, overwrite it\n  --read_count_minimum READ_COUNT_MINIMUM\n                        the minimum read count (inclusive) for detected\n                        haplotypes to be kept\n\n\nThe python code for extract_pmo_with_read_filter script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_pmo_with_read_filter.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_pmo_with_read_filter():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, required=True, help='Output json file path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--read_count_minimum', default=0.0, type=float, required=True, help='the minimum read count (inclusive) for detected haplotypes to be kept')\n    return parser.parse_args()\n\ndef extract_pmo_with_read_filter():\n    args = parse_args_extract_pmo_with_read_filter()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in pmo\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # extract\n    pmo_out = PMOExtractor.extract_from_pmo_with_read_filter(pmo, args.read_count_minimum)\n\n    # write out the extracted\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.file.endswith('.gz') or args.output.endswith(\".gz\"))\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\nif __name__ == \"__main__\":\n    extract_pmo_with_read_filter()\n\n\n\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_minReadCount1000.json.gz --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/subsetting_from_PMO.html#piping-together-extraction",
    "href": "pmotools-python-usages/subsetting_from_PMO.html#piping-together-extraction",
    "title": "Subsetting from a PMO using pmotools-python",
    "section": "",
    "text": "The extraction methods also allow for STDOUT and STDIN piping for example\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.json.gz --overwrite\n\n\nCan also pipe into other pmotools-runner.py functions like extracting allele tables\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output alleles_data_t1_t20_t31_8025875029_8034209834_8034209115_moz2018_PMO.tsv.gz --overwrite\n\n\nCan pipe final output to STDOUT as well for further processing\n\nCodecd example \n\necho -e \"8025875029\\n8034209834\\n8034209115\" | pmotools-runner.py extract_pmo_with_select_experiment_sample_ids --experiment_sample_ids STDIN --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_pmo_with_select_targets --file STDIN --targets t1,t20,t31  --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output STDOUT  --specimen_info_meta_fields specimen_id,collection_country\n\nsampleID    locus   allele  specimen_id collection_country\n8025875029  t1  t1.0    8025875029  Mozambique\n8025875029  t1  t1.1    8025875029  Mozambique\n8025875029  t20 t20.3   8025875029  Mozambique\n8025875029  t20 t20.5   8025875029  Mozambique\n8025875029  t20 t20.4   8025875029  Mozambique\n8025875029  t31 t31.1   8025875029  Mozambique\n8025875029  t31 t31.3   8025875029  Mozambique\n8034209115  t1  t1.2    8034209115  Mozambique\n8034209115  t20 t20.4   8034209115  Mozambique\n8034209115  t20 t20.1   8034209115  Mozambique\n8034209115  t31 t31.1   8034209115  Mozambique\n8034209115  t31 t31.3   8034209115  Mozambique\n8034209834  t1  t1.0    8034209834  Mozambique\n8034209834  t20 t20.1   8034209834  Mozambique\n8034209834  t20 t20.0   8034209834  Mozambique\n8034209834  t31 t31.2   8034209834  Mozambique\n8034209834  t31 t31.0   8034209834  Mozambique\n\n\nfilter to a read amount and then write allele table\n\nCodecd example \n\npmotools-runner.py extract_pmo_with_read_filter --read_count_minimum 1000 --file ../../format/moz2018_PMO.json.gz --output STDOUT | pmotools-runner.py extract_allele_table --file STDIN --bioid Mozambique2018-SeekDeep --output moz2018_PMO_minReadCount1000_allele_table.tsv.gz  --microhap_fields read_count --representative_haps_fields seq --default_base_col_names specimen_id,target_id,allele --overwrite"
  },
  {
    "objectID": "pmotools-python-usages/pmotools-runner.html",
    "href": "pmotools-python-usages/pmotools-runner.html",
    "title": "Command line interface to pmotools-python with pmotools-runner.py",
    "section": "",
    "text": "See installation instruction page for how to install pmotools-python which comes with a command line interact called pmotools-runner.py\n\nCodepmotools-runner.py\n\n\n\n\npmotools v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (pmo) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to JSON Meta\n    terra_amp_output_to_json - Convert terra output table to JSON seq table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract from PMO samples and associated haplotypes with selected meta\n    extract_pmo_with_select_specimen_ids - Extract from PMO specific samples from the specimens table\n    extract_pmo_with_select_experiment_sample_ids - Extract from PMO specific experiment sample ids from the experiment_info table\n    extract_pmo_with_select_targets - Extract from PMO specific targets\n    extract_pmo_with_read_filter - Extract from PMO with a read filter\n    extract_allele_table - Extract allele tables which can be as used as input to such tools as dcifer or moire\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple pmos of the same panel into a single pmo\n\nextract_basic_info_from_pmo\n    list_experiment_sample_ids_per_specimen_id - Each specimen_id can have multiple experiment_sample_ids, list out all in a PMO\n    list_specimen_meta_fields - List out the specimen meta fields in the specimen_info section\n    list_tar_amp_bioinformatics_info_ids - List out all the tar_amp_bioinformatics_info_ids in a PMO file\n    count_specimen_meta - Count the values of specific specimen meta fields in the specimen_info section\n    count_targets_per_sample - Count the number of targets per sample\n    count_samples_per_target - Count the number of samples per target\n\nextract_panel_info_from_pmo\n    extract_insert_of_panels - Extract the insert of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract the ref_seq of panels from a PMO"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html",
    "href": "format/DevelopmentOfFormat.html",
    "title": "Development of Format",
    "section": "",
    "text": "The meta fields for the sample and sequencing are based on NCBI naming schemes especially from SRA submission portal for human-associated pathogen. Depending on which reporting standard is selected at the time of submission, these are derived and vlided via the the MiXS standards set by the Genomics Standards Consortium (GSC)\n\nWhen submitting sample meta data to SRA, you have to choose a reporting standard to validate your meta data against\n\nThere are 4 reporting standards that one might pick for targeted amplicon sequencing of a pathogen\n\n\nMIGS.eu.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMIMARKS.specimen.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMicrobe.1.0 (non-MiXS derived, SRA discourages usage)\n\nPathogen.cl.1.0 (non-MiXS derived, SRA discourages usage)\n\nMIGS.eu.human-associated.6.0 and MIMARKS.specimen.human-associated.6.0 have the same required fields and only differ with a handful of different fields\nDetermining difference between MIGS.eu.human-associated and MIMARKS.specimen.human-associated\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\nMIMARKS_specimen_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip= 12)\n\ncolname_compared = set_decompose(colnames(MIGS_eu_human_associated), colnames(MIMARKS_specimen_human_associated))\n\nlist(\"Only in MIGS_eu_human_associated\" = colname_compared$only_in_vectorA, \n     \"Only in MIMARKS_specimen_human_associated\" = colname_compared$only_in_vectorB)\n\n$`Only in MIGS_eu_human_associated`\n[1] \"estimated_size\"  \"host_taxid\"      \"num_replicons\"   \"pathogenicity\"   \"ploidy\"          \"propagation\"     \"ref_biomaterial\"\n\n$`Only in MIMARKS_specimen_human_associated`\n[1] \"rel_to_oxygen\"\n\n\nSite describing all BioSample Attributes at the SRA https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?package-0=MIGS.eu.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIGS.eu.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=MIMARKS.specimen&package-1=MIMARKS.specimen.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIMARKS.specimen.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Microbe.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMicrobe.1.0.xlsx\n\n\nCodeMicrobe = readxl::read_excel(\"sra_standards/Microbe.1.0.xlsx\", skip = 12)\ncreate_dt(Microbe)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nsample_type (non MixS standard) - Sample type, such as cell culture, mixed culture, tissue sample, whole organism, single cell, metagenomic assembly\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nOne of the following\n\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Pathogen&package-1=Pathogen.cl.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nPathogen.cl.1.0.xlsx\n\n\nCodePathogen = readxl::read_excel(\"sra_standards/Pathogen.cl.1.0.xlsx\", skip = 12)\ncreate_dt(Pathogen)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\ncollected_by - Name of persons or institute who collected the sample\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\nhost_disease (non-MixS field) - Name of relevant disease, e.g. Salmonella gastroenteritis. Controlled vocabulary, http://bioportal.bioontology.org/ontologies/1009 or http://www.ncbi.nlm.nih.gov/mesh\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nAdditonal fields not in GSC or SRA submission but are often found in downloads from SRAs. This is because the geo_loc_name can be country followed by several more details, these columns allow for listing only the country and continent\n\ngeo_loc_name_country\ngeo_loc_name_country_continent\n\nInfo about the sequencing of the samples above, details can be found below link:\nSRA sequencing meta: https://www.ncbi.nlm.nih.gov/sra/docs/submitportal/#6-sra-metadata\nExample file for SRA submission\n\nSRA_metadata.xlsx\n\n\nCodeSRA_sequencing_metadata = readxl::read_excel(\"sra_standards/SRA_metadata.xlsx\", sheet = 2)\ncreate_dt(SRA_sequencing_metadata)\n\n\n\n\n\n\nDetails about the requirments\n\nIf you created samples previously, provide accessions in the form of SAMN# in the column sample_accession. Otherwise provide the sample name used in the BioSample attributes spreadsheet.\nEach row in the template represents a sequencing library with a unique combination of sample + library + sequencing strategy + layout + instrument model. Each row should have a unique library_id that is short and meaningful (like an ID you might use in lab).\nWhen libraries are indeed identical (same combination of sample + library + strategy + layout + instrument model), all files should be placed in the same row To do this simply enter the file names consecutively in the same row by adding more columns with headers filename2, filename3, etc…. PAIRED files must always be listed in the same row.\nsample_name - must match exactly the sample_name in the tables above\nlibrary_id - each must be unique, should be short like what is in a samplesheet\ntitle - Short description that will identify the dataset on public pages. A clear and concise formula for the title would be like: {methodology} of {organism}: {sample info} _e.g. RNA-Seq of mus musculus:adult female spleen\nlibrary_strategy - what the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\nlibrary_source - Source of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\nlibrary_selection - how amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\nlibrary_layout (MixS equivalent lib_layout) - Specify whether to expect single, paired, or other configuration of reads\nplatform (MixS equivalent is part of seq_meth) - Machine used to sequence data, should be one from https://ontobee.org/ontology/OBI?iri=http://purl.obolibrary.org/obo/OBI_0400103\ninstrument_model (MixS equivalent is part of seq_meth) - The specific model of the machine above\ndesign_description - A short description of how sequencing was done, paragraph style\nfiletype and filenames - the type of file and the names of the files associated with the sequencing\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002/\n\nCodeMigsEu_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MigsEu_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MigsEu_v6.2.0_fields)\n\n\n\n\nCodeMigsEu_v6.2.0_fields  = MigsEu_v6.2.0_fields%&gt;% \n  mutate(in_MigsEu_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0016003/\n\nCodeHumanAssociated_v6.2.0_fields = readr::read_tsv(\"mixs_standards/HumanAssociated_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(HumanAssociated_v6.2.0_fields)\n\n\n\n\nCodeHumanAssociated_v6.2.0_fields  = HumanAssociated_v6.2.0_fields%&gt;% \n  mutate(in_HumanAssociated_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009/\n\nCodeMimarksC_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MimarksC_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MimarksC_v6.2.0_fields)\n\n\n\n\nCodeMimarksC_v6.2.0_fields  = MimarksC_v6.2.0_fields%&gt;% \n  mutate(in_MimarksC_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\n\n\nCodeall_mixs_fields = MigsEu_v6.2.0_fields %&gt;% \n  full_join(MimarksC_v6.2.0_fields) %&gt;% \n  full_join(HumanAssociated_v6.2.0_fields) %&gt;% \n  arrange(fields) %&gt;% \n  mutate(in_both_MigsEu_MimarksC = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0)%&gt;% \n  mutate(in_all_three = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0 & in_HumanAssociated_v6.2.0)\ncreate_dt(all_mixs_fields)\n\n\n\n\n\n\nThe fields choices for PMO took into consideration the Mixs standards, SRA standards, and from other similar amplicon standards (which are also based on Mixs standards), Environmental System Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE) and National Microbiome Data Collaborative (NMDC)\nThe SRA takes two tables, one defining bio samples and one defining sequencing experiments done on those bio samples of which there could be multiple sequencing experiments. Therefore the decison was made to also create two seperate data sections for defining a biosample (specimen_info) and one defining experiments on those specimens (experiment_info), this allows the mirroring of SRA as well as allowing for storing replicates of a single specimen. A 3rd section was created to store redundant sequencing info (sequencing_info).\n\nComparing the specimen_info fields to the MIXS standard and SRA. Please see specimen_info in FormatOverview for short description of each pmo field and above for the SRA fields\n\nCodecreate_dt(readr::read_tsv(\"specimen_info_field_comparison.tsv\"))\n\n\n\n\n\n\nComparing the sequencing_info and experiment_info fields to the Mixs standards and the data required for SRA submission above\n\nCodecreate_dt(readr::read_tsv(\"experiment_and_sequencing_field_comparison.tsv\"))"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#sra-sample-fields",
    "href": "format/DevelopmentOfFormat.html#sra-sample-fields",
    "title": "Development of Format",
    "section": "",
    "text": "When submitting sample meta data to SRA, you have to choose a reporting standard to validate your meta data against\n\nThere are 4 reporting standards that one might pick for targeted amplicon sequencing of a pathogen\n\n\nMIGS.eu.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMIMARKS.specimen.human-associated.6.0 (MiXS dervived/standard compliant, SRA encourages usage)\n\nMicrobe.1.0 (non-MiXS derived, SRA discourages usage)\n\nPathogen.cl.1.0 (non-MiXS derived, SRA discourages usage)\n\nMIGS.eu.human-associated.6.0 and MIMARKS.specimen.human-associated.6.0 have the same required fields and only differ with a handful of different fields\nDetermining difference between MIGS.eu.human-associated and MIMARKS.specimen.human-associated\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\nMIMARKS_specimen_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip= 12)\n\ncolname_compared = set_decompose(colnames(MIGS_eu_human_associated), colnames(MIMARKS_specimen_human_associated))\n\nlist(\"Only in MIGS_eu_human_associated\" = colname_compared$only_in_vectorA, \n     \"Only in MIMARKS_specimen_human_associated\" = colname_compared$only_in_vectorB)\n\n$`Only in MIGS_eu_human_associated`\n[1] \"estimated_size\"  \"host_taxid\"      \"num_replicons\"   \"pathogenicity\"   \"ploidy\"          \"propagation\"     \"ref_biomaterial\"\n\n$`Only in MIMARKS_specimen_human_associated`\n[1] \"rel_to_oxygen\"\n\n\nSite describing all BioSample Attributes at the SRA https://www.ncbi.nlm.nih.gov/biosample/docs/attributes/\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?package-0=MIGS.eu.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIGS.eu.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIGS.eu.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=MIMARKS.specimen&package-1=MIMARKS.specimen.human-associated.6.0&action=definition\nGSC website defining the fields: https://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMIMARKS.specimen.human-associated.6.0.xlsx\n\n\nCodeMIGS_eu_human_associated = readxl::read_excel(\"sra_standards/MIMARKS.specimen.human-associated.6.0.xlsx\", skip = 12)\ncreate_dt(MIGS_eu_human_associated)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\nhost (non-MixS standard, equivalent is specific_host)\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\n\nenv_broad_scale - Add terms that identify the major environment type(s) where your sample was collected. Recommend subclasses of biome [ENVO:00000428]. Multiple terms can be separated by one or more pipes e.g.: mangrove biome [ENVO:01000181]|estuarine biome [ENVO:01000020]\n\n\nenv_local_scale - Add terms that identify environmental entities having causal influences upon the entity at time of sampling, multiple terms can be separated by pipes, e.g.: shoreline [ENVO:00000486]|intertidal zone [ENVO:00000316]\n\n\nenv_medium - Add terms that identify the material displaced by the entity at time of sampling. Recommend subclasses of environmental material [ENVO:00010483]. Multiple terms can be separated by pipes e.g.: estuarine water [ENVO:01000301]|estuarine mud [ENVO:00002160]\n\n\nisol_growth_condt - PMID or url for isolation and growth condition specifications\n\nOne of the following fields, (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\n\ncultivar - cultivar name - cultivated variety of plant\n\n\necotype - a population within a given species displaying genetically based, phenotypic traits that reflect adaptation to a local habitat, e.g., Columbia\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Microbe.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nMicrobe.1.0.xlsx\n\n\nCodeMicrobe = readxl::read_excel(\"sra_standards/Microbe.1.0.xlsx\", skip = 12)\ncreate_dt(Microbe)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\nsample_type (non MixS standard) - Sample type, such as cell culture, mixed culture, tissue sample, whole organism, single cell, metagenomic assembly\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nOne of the following\n\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nSRA website defining the fields: https://submit.ncbi.nlm.nih.gov/biosample/template/?organism-organism_name=&organism-taxonomy_id=&package-0=Pathogen&package-1=Pathogen.cl.1.0&action=definition\nExample file for SRA submission, these are all posible fields with required fields marked with a star(*)\n\nPathogen.cl.1.0.xlsx\n\n\nCodePathogen = readxl::read_excel(\"sra_standards/Pathogen.cl.1.0.xlsx\", skip = 12)\ncreate_dt(Pathogen)\n\n\n\n\n\n\nThough all of these fields are required, they can also have the values of not applicable\n\n\nsample_name - Sample Name is a name that you choose for the sample. It can have any format, but we suggest that you make it concise, unique and consistent within your lab, and as informative as possible. Every Sample Name from a single Submitter must be unique\n\n\norganism - The most descriptive organism name for this sample (to the species, if possible). It is OK to submit an organism name that is not in our database. In the case of a new species, provide the desired organism name, and our taxonomists may assign a provisional taxID\n\n\ncollection_date - the date on which the sample was collected; date/time ranges are supported by providing two dates from among the supported value formats, delimited by a forward-slash character; collection times are supported by adding “T”, then the hour and minute after the date, and must be in Coordinated Universal Time (UTC), otherwise known as “Zulu Time” (Z); supported formats include “DD-Mmm-YYYY”, “Mmm-YYYY”, “YYYY” or ISO 8601 standard “YYYY-mm-dd”, “YYYY-mm”, “YYYY-mm-ddThh:mm:ss”; e.g., 30-Oct-1990, Oct-1990, 1990, 1990-10-30, 1990-10, 21-Oct-1952/15-Feb-1953, 2015-10-11T17:53:03Z; valid non-ISO dates will be automatically transformed to ISO format\n\n\ngeo_loc_name - Geographical origin of the sample; use the appropriate name from this list https://www.insdc.org/submitting-standards/geo_loc_name-qualifier-vocabulary/. Use a colon to separate the country or ocean from more detailed information about the location, eg “Canada: Vancouver” or “Germany: halfway down Zugspitze, Alps”\n\n\ncollected_by - Name of persons or institute who collected the sample\n\nhost (non-MixS standard, equivalent is specific_host) - The natural (as opposed to laboratory) host to the organism from which the sample was obtained. Use the full taxonomic name, eg, “Homo sapiens”.\n\nhost_disease (non-MixS field) - Name of relevant disease, e.g. Salmonella gastroenteritis. Controlled vocabulary, http://bioportal.bioontology.org/ontologies/1009 or http://www.ncbi.nlm.nih.gov/mesh\n\nisolation_source (non MixS standard) - Describes the physical, environmental and/or local geographical source of the biological sample from which the sample was derived\n\nlat_lon - The geographical coordinates of the location where the sample was collected. Specify as degrees latitude and longitude in format “d[d.dddd] N|S d[dd.dddd] W|E”, eg, 38.98 N 77.11 W\n\nOne of the following (none of these are technically a MixS standard but a MixS stand field called subspecf_gen_lin allows for the definiton of any of these)\n\n\nstrain - microbial or eukaryotic strain name\n\n\nisolate - identification or description of the specific individual from which this sample was obtained\n\nAdditonal fields not in GSC or SRA submission but are often found in downloads from SRAs. This is because the geo_loc_name can be country followed by several more details, these columns allow for listing only the country and continent\n\ngeo_loc_name_country\ngeo_loc_name_country_continent"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#sra-sequencing-fields",
    "href": "format/DevelopmentOfFormat.html#sra-sequencing-fields",
    "title": "Development of Format",
    "section": "",
    "text": "Info about the sequencing of the samples above, details can be found below link:\nSRA sequencing meta: https://www.ncbi.nlm.nih.gov/sra/docs/submitportal/#6-sra-metadata\nExample file for SRA submission\n\nSRA_metadata.xlsx\n\n\nCodeSRA_sequencing_metadata = readxl::read_excel(\"sra_standards/SRA_metadata.xlsx\", sheet = 2)\ncreate_dt(SRA_sequencing_metadata)\n\n\n\n\n\n\nDetails about the requirments\n\nIf you created samples previously, provide accessions in the form of SAMN# in the column sample_accession. Otherwise provide the sample name used in the BioSample attributes spreadsheet.\nEach row in the template represents a sequencing library with a unique combination of sample + library + sequencing strategy + layout + instrument model. Each row should have a unique library_id that is short and meaningful (like an ID you might use in lab).\nWhen libraries are indeed identical (same combination of sample + library + strategy + layout + instrument model), all files should be placed in the same row To do this simply enter the file names consecutively in the same row by adding more columns with headers filename2, filename3, etc…. PAIRED files must always be listed in the same row.\nsample_name - must match exactly the sample_name in the tables above\nlibrary_id - each must be unique, should be short like what is in a samplesheet\ntitle - Short description that will identify the dataset on public pages. A clear and concise formula for the title would be like: {methodology} of {organism}: {sample info} _e.g. RNA-Seq of mus musculus:adult female spleen\nlibrary_strategy - what the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\nlibrary_source - Source of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\nlibrary_selection - how amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\nlibrary_layout (MixS equivalent lib_layout) - Specify whether to expect single, paired, or other configuration of reads\nplatform (MixS equivalent is part of seq_meth) - Machine used to sequence data, should be one from https://ontobee.org/ontology/OBI?iri=http://purl.obolibrary.org/obo/OBI_0400103\ninstrument_model (MixS equivalent is part of seq_meth) - The specific model of the machine above\ndesign_description - A short description of how sequencing was done, paragraph style\nfiletype and filenames - the type of file and the names of the files associated with the sequencing"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#gsc-mixs-standards",
    "href": "format/DevelopmentOfFormat.html#gsc-mixs-standards",
    "title": "Development of Format",
    "section": "",
    "text": "https://genomicsstandardsconsortium.github.io/mixs/0010002/\n\nCodeMigsEu_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MigsEu_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MigsEu_v6.2.0_fields)\n\n\n\n\nCodeMigsEu_v6.2.0_fields  = MigsEu_v6.2.0_fields%&gt;% \n  mutate(in_MigsEu_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0016003/\n\nCodeHumanAssociated_v6.2.0_fields = readr::read_tsv(\"mixs_standards/HumanAssociated_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(HumanAssociated_v6.2.0_fields)\n\n\n\n\nCodeHumanAssociated_v6.2.0_fields  = HumanAssociated_v6.2.0_fields%&gt;% \n  mutate(in_HumanAssociated_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010002_0016003/\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009/\n\nCodeMimarksC_v6.2.0_fields = readr::read_tsv(\"mixs_standards/MimarksC_v6.2.0_fields.txt\") %&gt;% \n  arrange(fields)\ncreate_dt(MimarksC_v6.2.0_fields)\n\n\n\n\nCodeMimarksC_v6.2.0_fields  = MimarksC_v6.2.0_fields%&gt;% \n  mutate(in_MimarksC_v6.2.0 = T)\n\n\n\nhttps://genomicsstandardsconsortium.github.io/mixs/0010009_0016003/\n\n\nCodeall_mixs_fields = MigsEu_v6.2.0_fields %&gt;% \n  full_join(MimarksC_v6.2.0_fields) %&gt;% \n  full_join(HumanAssociated_v6.2.0_fields) %&gt;% \n  arrange(fields) %&gt;% \n  mutate(in_both_MigsEu_MimarksC = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0)%&gt;% \n  mutate(in_all_three = in_MigsEu_v6.2.0  & in_MimarksC_v6.2.0 & in_HumanAssociated_v6.2.0)\ncreate_dt(all_mixs_fields)"
  },
  {
    "objectID": "format/DevelopmentOfFormat.html#pmo-sample-and-sequencing-fields",
    "href": "format/DevelopmentOfFormat.html#pmo-sample-and-sequencing-fields",
    "title": "Development of Format",
    "section": "",
    "text": "The fields choices for PMO took into consideration the Mixs standards, SRA standards, and from other similar amplicon standards (which are also based on Mixs standards), Environmental System Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE) and National Microbiome Data Collaborative (NMDC)\nThe SRA takes two tables, one defining bio samples and one defining sequencing experiments done on those bio samples of which there could be multiple sequencing experiments. Therefore the decison was made to also create two seperate data sections for defining a biosample (specimen_info) and one defining experiments on those specimens (experiment_info), this allows the mirroring of SRA as well as allowing for storing replicates of a single specimen. A 3rd section was created to store redundant sequencing info (sequencing_info).\n\nComparing the specimen_info fields to the MIXS standard and SRA. Please see specimen_info in FormatOverview for short description of each pmo field and above for the SRA fields\n\nCodecreate_dt(readr::read_tsv(\"specimen_info_field_comparison.tsv\"))\n\n\n\n\n\n\nComparing the sequencing_info and experiment_info fields to the Mixs standards and the data required for SRA submission above\n\nCodecreate_dt(readr::read_tsv(\"experiment_and_sequencing_field_comparison.tsv\"))"
  },
  {
    "objectID": "format/FormatExample.html#from-pf7-data-for-the-same-panel-above",
    "href": "format/FormatExample.html#from-pf7-data-for-the-same-panel-above",
    "title": "PMO Examples",
    "section": "From Pf7+ data for the same panel above",
    "text": "From Pf7+ data for the same panel above\nGlobal data microhaplotypes were constructed by PathWeaver for the same targeted amplicon panel above. This includes approximately 1900 samples.\n\nPathWeaverHeome1_PMO.json.gz"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "",
    "text": "Website describing Portable Microhaplotype Object development"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Introduction",
    "text": "Introduction\nAmplicon can be defined as a piece of DNA/RNA that has been amplified. When referring to amplicon data though we are referring to targeted amplicon data which is when a specific target of interest has been amplified by a set of primers and sequenced from a set of samples. Data from an amplicon can be referred to a microhaplotype (as opposed to a full haplotype which would be a full chromosome, a microhaplotype typical covers more than 1 variant and is approximately &lt;=300bp, which is it’s first definition(Oldoni, Kidd, and Podini 2019) but doesn’t have to meet those criteria precisely)"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Goals",
    "text": "Goals\nTargeted amplicon sequencing has been a data analysis technique that has been well established and made most popular by microbiome analysis where a piece of 16S rRNA is amplified to help classify a microbiome mixture by defining taxon data and abundance.\nThe goal of a developing a amplicon file format, especially with Plasmodium in mind, is easing the comparison between experimental runs within and across labs."
  },
  {
    "objectID": "index.html#sources-of-data",
    "href": "index.html#sources-of-data",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Sources of data",
    "text": "Sources of data\nData can be generated by targeted amplicon sequencing experiments or by doing local assembly on WGS data."
  },
  {
    "objectID": "index.html#goals-of-file-format",
    "href": "index.html#goals-of-file-format",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "Goals of file format",
    "text": "Goals of file format\n\nHelp individual researchers / groups organize their data\nFormat for sharing and reporting data to aid in standardization, transparency, and reproducibility\nAlign downstream analysis tools so no need to reshape data differently for each application\nMake data publicly available for analysis\nFacilitate cross-study analysis and tools e.g. “next-malaria”"
  },
  {
    "objectID": "index.html#the-genomic-standards-consortium",
    "href": "index.html#the-genomic-standards-consortium",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "The Genomic Standards Consortium",
    "text": "The Genomic Standards Consortium\nThe Genomic Standards Consortium\n\nThe Genomic Standards Consortium (GSC) is an open-membership working body formed in September 2005. The aim of the GSC is making genomic data discoverable. The GSC enables genomic data integration, discovery and comparison through international community-driven standards.\n\nThey are listed under the findability, accessibility, interoperability, and reusability (FAIR) sharinghttps://fairsharing.org/GSC"
  },
  {
    "objectID": "index.html#mixs",
    "href": "index.html#mixs",
    "title": "Portable Microhaplotype Object (PMO)",
    "section": "MIxS",
    "text": "MIxS\nGSC have developed several standards in order to try to standardized the way we describe genomics/sequencing data and have developed what is called “Minimum Information about any (X) Sequence” (MIxS) specification\nhttps://github.com/GenomicsStandardsConsortium/mixs/\n\nWithout specific guidelines, most genomic, metagenomic and marker gene sequences in databases are sparsely annotated with the information required to guide data integration, comparative studies and knowledge generation. Even with complex keyword searches, it is currently impossible to reliably retrieve sequences that have originated from certain environments or particular locations on Earth—for example, all sequences from ‘soil’ or ‘freshwater lakes’ in a certain region of the world. Because public databases of the International Nucleotide Sequence Database Collaboration (INSDC; comprising DNA Data Bank of Japan (DDBJ), the European Nucleotide Archive (EBI-ENA) and GenBank depend on author-submitted information to enrich the value of sequence data sets, we argue that the only way to change the current practice is to establish a standard of reporting that requires contextual data to be deposited at the time of sequence submission. The adoption of such a standard would elevate the quality, accessibility and utility of information that can be collected from INSDC or any other data repository.\n\nMicrobial specific\nMicrobiome world has long had to deal with targeted amplicon analysis primarily on 16s RNA sub-unit and more recently on Multilocus sequence typing (MLST)\nESS-DIVE amplicon file formating\nAs such they have already developed some standards on creating a generalized targeted amplicon file, standards set by Environmental System Science Data Infrastructure for a Virtual Ecosystem (ESS-DIVE), https://github.com/ess-dive-community, https://ess-dive.lbl.gov/\nTheir standards try to follow closely with Minimum Information about any Sequence (MIxS) standards\nbiom amplicon file formatting\nOther considerations are also the biom format which is written in HDF5 to help handle storing data in binary format, this is used by QIME along with several other common bacterial genomics tools"
  },
  {
    "objectID": "format/FormatOverview.html",
    "href": "format/FormatOverview.html",
    "title": "PMO fields overview",
    "section": "",
    "text": "Creating fields with efforts to be consistent with MIxS standards. These are the standards that the short read archive (SRA) use to validate metadata upon submission. This also helps to keep data standards to adhere to FAIR (Findable, Accessible, Interoperable, and Reusable).\nFormat was developed in order to achieve an efficient/low-weight format that contains the minimum amount of information about a targeted amplicon analysis without losing any important data. Tools are generated around this table to generate certain fields that are important but not necessary to keep constantly stored in this base class (e.g. SNP/INDEL calls). To increase portability and to keep data internally consistent, format was desinged to be contained within a singular file in JSON format which removes the limitation of storing data only in a tabular format. Output generated from this file can be a table for downstream usage but storing in the flexible JSON format allows storage in non-redundnat organiation (e.g. storing an ID only once while storing other data in lists).\nFormat is defined by utilizing LinkML to generate a general data scheme which creates various validation outputs like JSON Schema for validation tools. LinkML generates a website for viewing all fields defined in the format, https://github.com/PlasmoGenEpi/portable-microhaplotype-object.\nOther notable users of LinkML/MIxS National Microbiome Data Collaborative Schema"
  },
  {
    "objectID": "format/FormatOverview.html#portablemicrohaplotypeobject",
    "href": "format/FormatOverview.html#portablemicrohaplotypeobject",
    "title": "PMO fields overview",
    "section": "PortableMicrohaplotypeObject",
    "text": "PortableMicrohaplotypeObject\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PortableMicrohaplotypeObject/\nRequired\n\nexperiment_info (type=list of ExperimentInfo)\n\na list of experiments of all the seq/amp of the specimens within this project\n\n\n\nspecimen_info (type=list of SpecimenInfo)\n\na list of all the specimens within this project\n\n\n\nsequencing_info (type=list of SequencingInfo)\n\na list of sequencing info for this project\n\n\n\npanel_info (type=list of PanelInfo)\n\na list of info on the panels\n\n\n\ntarget_info (type=list of TargetInfo)\n\na list of info on the targets\n\n\n\ntargeted_genomes (type=list of GenomeInfo)\n\na list of genomes that the targets in TargetInfo refer to\n\n\n\nmicrohaplotypes_info (type=RepresentativeMicrohaplotypes)\n\na list of the information on the representative microhaplotypes\n\n\n\nbioinformatics_methods_info (type=list of BioinformaticsMethodInfo)\n\nthe bioinformatics pipeline/methods used to generated the amplicon analysis for this project\n\n\n\nbioinformatics_run_info (type=list of BioinformaticsRunInfo)\n\nthe runtime info for the bioinformatics pipeline used to generated the amplicon analysis for this project\n\n\n\nmicrohaplotypes_detected (type=list of MicrohaplotypesDetected)\n\nthe microhaplotypes detected in this projects\n\n\n\nproject_info (type=list of ProjectInfo)\n\nthe information about the projects stored in this PMO\n\n\n\npmo_header (type=PmoHeader)\n\nthe PMO information for this file including version etc\n\n\nOptional\n\nread_counts_by_stage (type=list of ReadCountsByStage)\n\nthe read counts for different stages of the pipeline\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#biomethod",
    "href": "format/FormatOverview.html#biomethod",
    "title": "PMO fields overview",
    "section": "BioMethod",
    "text": "BioMethod\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioMethod/ Show BioMethod fields  \n\n\nRequired\n\nprogram_version (type=string)\n\nthe version of generation method, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\n\nprogram (type=string)\n\nname of the program used for this portion of the pipeline\n\n\nOptional\n\nadditional_argument (type=list of string)\n\nany additional arguments that differ from the default\n\n\n\nprogram_description (type=string)\n\na short description of what this method does\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#bioinformaticsmethodinfo",
    "href": "format/FormatOverview.html#bioinformaticsmethodinfo",
    "title": "PMO fields overview",
    "section": "BioinformaticsMethodInfo",
    "text": "BioinformaticsMethodInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioinformaticsMethodInfo/ Show BioinformaticsMethodInfo fields  \n\n\nRequired\n\ndemultiplexing_method (type=BioMethod)\n\nthe demultiplexing method used to separate raw reads from barcodes and primer targets\n\n\n\ndenoising_method (type=BioMethod)\n\nthe method used to de-noise and/or cluster the raw reads\n\n\nOptional\n\nadditional_methods (type=list of BioMethod)\n\nany additional methods used to analyze the data\n\n\n\nbioinformatics_method_name (type=string)\n\nname of the collection of methods is called, e.g. pipeline\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#bioinformaticsruninfo",
    "href": "format/FormatOverview.html#bioinformaticsruninfo",
    "title": "PMO fields overview",
    "section": "BioinformaticsRunInfo",
    "text": "BioinformaticsRunInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/BioinformaticsRunInfo/ Show BioinformaticsRunInfo fields  \n\n\nRequired\n\nbioinformatics_methods_id (type=integer)\n\nthe index into the bioinformatics_methods_info list\n\n\n\nrun_date (type=string)\n\nthe date when the run was done, should be YYYY-MM-DD\n\n\nOptional\n\nbioinformatics_run_name (type=string)\n\na name to for this run\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#experimentinfo",
    "href": "format/FormatOverview.html#experimentinfo",
    "title": "PMO fields overview",
    "section": "ExperimentInfo",
    "text": "ExperimentInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ExperimentInfo/ Show ExperimentInfo fields  \n\n\nRequired\n\nsequencing_info_id (type=integer)\n\nthe index into the sequencing_info list\n\n\n\nspecimen_id (type=integer)\n\nthe index into the specimen_info list\n\n\n\npanel_id (type=integer)\n\nthe index into the panel_info list\n\n\n\nexperiment_sample_name (type=string)\n\na unique identifier for this sequence/amplification run on a specimen_name\n\n\nOptional\n\naccession (type=string)\n\nERA/SRA accession number for the sample if it was submitted\n\n\n\nlibrary_prep_plate_info (type=PlateInfo)\n\nplate location of where experiment was prepared for sequencing\n\n\n\nqpcr_parasite_density_info (type=list of ParasiteDensity)\n\nqpcr parasite density measurement\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#genomeinfo",
    "href": "format/FormatOverview.html#genomeinfo",
    "title": "PMO fields overview",
    "section": "GenomeInfo",
    "text": "GenomeInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/GenomeInfo/ Show GenomeInfo fields  \n\n\nRequired\n\nname (type=string)\n\nname of the genome\n\n\n\ngenome_version (type=string)\n\nthe genome version\n\n\n\ntaxon_id (type=integer)\n\nthe NCBI taxonomy number\n\n\n\nurl (type=string)\n\na link to the where this genome file could be downloaded\n\n\nOptional\n\nchromosomes (type=list of string)\n\na list of chromosomes found within this genome\n\n\n\ngff_url (type=string)\n\na link to the where this genome’s annotation file could be downloaded\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#genomiclocation",
    "href": "format/FormatOverview.html#genomiclocation",
    "title": "PMO fields overview",
    "section": "GenomicLocation",
    "text": "GenomicLocation\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/GenomicLocation/ Show GenomicLocation fields  \n\n\nRequired\n\ngenome_id (type=integer)\n\nthe index to the genome in the targeted_genomes list that this location refers to\n\n\n\nchrom (type=string)\n\nthe chromosome name\n\n\n\nstart (type=integer)\n\nthe start of the location, 0-based positioning\n\n\n\nend (type=integer)\n\nthe end of the location, 0-based positioning\n\n\nOptional\n\nref_seq (type=string)\n\nthe reference sequence of this genomic location\n\n\n\nstrand (type=string)\n\nwhich strand the location is, either + for plus strand or - for negative strand\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#markerofinterest",
    "href": "format/FormatOverview.html#markerofinterest",
    "title": "PMO fields overview",
    "section": "MarkerOfInterest",
    "text": "MarkerOfInterest\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MarkerOfInterest/ Show MarkerOfInterest fields  \n\n\nRequired\n\nmarker_location (type=GenomicLocation)\n\nthe genomic location\n\n\nOptional\n\nassociations (type=list of string)\n\na list of associations with this marker, e.g. SP resistance, etc\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#maskinginfo",
    "href": "format/FormatOverview.html#maskinginfo",
    "title": "PMO fields overview",
    "section": "MaskingInfo",
    "text": "MaskingInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MaskingInfo/ Show MaskingInfo fields  \n\n\nRequired\n\nseq_start (type=integer)\n\nthe start of the masking\n\n\n\nseq_segment_size (type=integer)\n\nthe size of the masking\n\n\n\nreplacement_size (type=integer)\n\nthe size of replacement mask\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#microhaplotypefortarget",
    "href": "format/FormatOverview.html#microhaplotypefortarget",
    "title": "PMO fields overview",
    "section": "MicrohaplotypeForTarget",
    "text": "MicrohaplotypeForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MicrohaplotypeForTarget/ Show MicrohaplotypeForTarget fields  \n\n\nRequired\n\nmhap_id (type=integer)\n\nthe index for a microhaplotype for a target in the microhaplotypes_info list, e.g. microhaplotypes_info[mhaps_target_id][mhap_id]\n\n\n\nreads (type=integer)\n\nthe read count associated with this microhaplotype\n\n\nOptional\n\numis (type=integer)\n\nthe unique molecular identifier (umi) count associated with this microhaplotype\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#microhaplotypesdetected",
    "href": "format/FormatOverview.html#microhaplotypesdetected",
    "title": "PMO fields overview",
    "section": "MicrohaplotypesDetected",
    "text": "MicrohaplotypesDetected\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MicrohaplotypesDetected/ Show MicrohaplotypesDetected fields  \n\n\nRequired\n\nbioinformatics_run_id (type=integer)\n\nthe index into bioinformatics_run_info list\n\n\n\nexperiment_samples (type=list of MicrohaplotypesForSample)\n\na list of the microhaplotypes detected for a sample by targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#microhaplotypesforsample",
    "href": "format/FormatOverview.html#microhaplotypesforsample",
    "title": "PMO fields overview",
    "section": "MicrohaplotypesForSample",
    "text": "MicrohaplotypesForSample\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MicrohaplotypesForSample/ Show MicrohaplotypesForSample fields  \n\n\nRequired\n\nexperiment_sample_id (type=integer)\n\nthe index into the experiment_info list\n\n\n\ntarget_results (type=list of MicrohaplotypesForTarget)\n\na list of the microhaplotypes detected for a list of targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#microhaplotypesfortarget",
    "href": "format/FormatOverview.html#microhaplotypesfortarget",
    "title": "PMO fields overview",
    "section": "MicrohaplotypesForTarget",
    "text": "MicrohaplotypesForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/MicrohaplotypesForTarget/ Show MicrohaplotypesForTarget fields  \n\n\nRequired\n\nmhaps_target_id (type=integer)\n\nthe index for a target in the microhaplotypes_info list\n\n\n\nhaps (type=list of MicrohaplotypeForTarget)\n\na list of the microhaplotypes detected for this target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#panelinfo",
    "href": "format/FormatOverview.html#panelinfo",
    "title": "PMO fields overview",
    "section": "PanelInfo",
    "text": "PanelInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PanelInfo/ Show PanelInfo fields  \n\n\nRequired\n\nreactions (type=list of ReactionInfo)\n\na list of 1 or more reactions that this panel contains, each reactions list the targets that were amplified in that reaction, e.g. pool1, pool2\n\n\n\npanel_name (type=string)\n\na name for the panel\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#parasitedensity",
    "href": "format/FormatOverview.html#parasitedensity",
    "title": "PMO fields overview",
    "section": "ParasiteDensity",
    "text": "ParasiteDensity\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ParasiteDensity/ Show ParasiteDensity fields  \n\n\nRequired\n\ndensity_method (type=string)\n\nthe method of how this density was obtained\n\n\n\nparasite_density (type=number)\n\nthe density in microliters\n\n\nOptional\n\ndate_measured (type=string)\n\nthe date the qpcr was performed, can be YYYY, YYYY-MM, or YYYY-MM-DD\n\n\n\ndensity_method_comments (type=string)\n\nadditional comments about how the density was performed\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#plateinfo",
    "href": "format/FormatOverview.html#plateinfo",
    "title": "PMO fields overview",
    "section": "PlateInfo",
    "text": "PlateInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PlateInfo/ Show PlateInfo fields  \n\n\nRequired\nOptional\n\nplate_col (type=integer)\n\nthe column the specimen was in\n\n\n\nplate_name (type=string)\n\na name of plate the specimen was in\n\n\n\nplate_row (type=string)\n\nthe row the specimen was in\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#pmogenerationmethod",
    "href": "format/FormatOverview.html#pmogenerationmethod",
    "title": "PMO fields overview",
    "section": "PmoGenerationMethod",
    "text": "PmoGenerationMethod\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PmoGenerationMethod/ Show PmoGenerationMethod fields  \n\n\nRequired\n\nprogram_version (type=string)\n\nthe version of generation method, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\n\nprogram_name (type=string)\n\nthe name of the program\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#pmoheader",
    "href": "format/FormatOverview.html#pmoheader",
    "title": "PMO fields overview",
    "section": "PmoHeader",
    "text": "PmoHeader\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PmoHeader/ Show PmoHeader fields  \n\n\nRequired\n\npmo_version (type=string)\n\nthe version of the PMO file, should be in the format of v[MAJOR].[MINOR].[PATCH]\n\n\nOptional\n\ncreation_date (type=string)\n\nthe date of when the PMO file was created or modified, should be YYYY-MM-DD\n\n\n\ngeneration_method (type=PmoGenerationMethod)\n\nthe generation method to create this PMO\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#primerinfo",
    "href": "format/FormatOverview.html#primerinfo",
    "title": "PMO fields overview",
    "section": "PrimerInfo",
    "text": "PrimerInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/PrimerInfo/ Show PrimerInfo fields  \n\n\nRequired\n\nseq (type=string)\n\nthe DNA sequence\n\n\nOptional\n\nlocation (type=GenomicLocation)\n\nwhat the intended genomic location of the primer is\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#projectinfo",
    "href": "format/FormatOverview.html#projectinfo",
    "title": "PMO fields overview",
    "section": "ProjectInfo",
    "text": "ProjectInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ProjectInfo/ Show ProjectInfo fields  \n\n\nRequired\n\nproject_name (type=string)\n\na name for the project, should be unique if multiple projects listed\n\n\n\nproject_description (type=string)\n\na short description of the project\n\n\nOptional\n\nBioProject_accession (type=string)\n\nan SRA bioproject accession e.g. PRJNA33823\n\n\n\nproject_collector_chief_scientist (type=string)\n\ncan be collection of names separated by a semicolon if multiple people involved or can just be the name of the primary person managing the specimen\n\n\n\nproject_contributors (type=list of string)\n\na list of collaborators who contributed to this project\n\n\n\nproject_type (type=string)\n\nthe type of project conducted, e.g. TES vs surveillance vs transmission\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#reactioninfo",
    "href": "format/FormatOverview.html#reactioninfo",
    "title": "PMO fields overview",
    "section": "ReactionInfo",
    "text": "ReactionInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReactionInfo/ Show ReactionInfo fields  \n\n\nRequired\n\npanel_targets (type= list of integer)\n\na list of the target indexes in the target_info list\n\n\n\nreaction_name (type=string)\n\na name for this reaction\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#readcountsbystage",
    "href": "format/FormatOverview.html#readcountsbystage",
    "title": "PMO fields overview",
    "section": "ReadCountsByStage",
    "text": "ReadCountsByStage\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStage/ Show ReadCountsByStage fields  \n\n\nRequired\n\nbioinformatics_run_id (type=integer)\n\nthe index into bioinformatics_run_info list\n\n\n\nread_counts_by_experimental_sample_by_stage (type=list of ReadCountsByStageForExperimentalSample)\n\na list by experiment_sample for the counts at each stage\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#readcountsbystageforexperimentalsample",
    "href": "format/FormatOverview.html#readcountsbystageforexperimentalsample",
    "title": "PMO fields overview",
    "section": "ReadCountsByStageForExperimentalSample",
    "text": "ReadCountsByStageForExperimentalSample\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStageForExperimentalSample/ Show ReadCountsByStageForExperimentalSample fields  \n\n\nRequired\n\nexperiment_sample_id (type=integer)\n\nthe index into the experiment_info list\n\n\n\ntotal_raw_count (type=integer)\n\nthe raw counts off the sequencing machine that a sample began with\n\n\nOptional\n\nread_counts_for_targets (type=list of ReadCountsByStageForTarget)\n\na list of counts by stage for a target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#readcountsbystagefortarget",
    "href": "format/FormatOverview.html#readcountsbystagefortarget",
    "title": "PMO fields overview",
    "section": "ReadCountsByStageForTarget",
    "text": "ReadCountsByStageForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/ReadCountsByStageForTarget/ Show ReadCountsByStageForTarget fields  \n\n\nRequired\n\ntarget_id (type=integer)\n\nthe index into the target_info list\n\n\n\nstages (type=list of StageReadCounts)\n\nthe read counts by each stage\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#representativemicrohaplotype",
    "href": "format/FormatOverview.html#representativemicrohaplotype",
    "title": "PMO fields overview",
    "section": "RepresentativeMicrohaplotype",
    "text": "RepresentativeMicrohaplotype\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotype/ Show RepresentativeMicrohaplotype fields  \n\n\nRequired\n\nseq (type=string)\n\nthe DNA sequence\n\n\nOptional\n\nalt_annotations (type=list of string)\n\na list of additional annotations associated with this microhaplotype, e.g. wildtype, amino acid changes etc\n\n\n\nmasking (type=list of MaskingInfo)\n\nmasking info for the sequence\n\n\n\nmicrohaplotype_name (type=string)\n\nan optional name for this microhaplotype\n\n\n\npseudocigar (type=string)\n\nthe pseudocigar of the haplotype\n\n\n\nquality (type=string)\n\nthe ansi fastq per base quality score for this sequence, this is optional\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#representativemicrohaplotypes",
    "href": "format/FormatOverview.html#representativemicrohaplotypes",
    "title": "PMO fields overview",
    "section": "RepresentativeMicrohaplotypes",
    "text": "RepresentativeMicrohaplotypes\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotypes/ Show RepresentativeMicrohaplotypes fields  \n\n\nRequired\n\ntargets (type=list of RepresentativeMicrohaplotypesForTarget)\n\na list of the microhaplotype for each targets\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#representativemicrohaplotypesfortarget",
    "href": "format/FormatOverview.html#representativemicrohaplotypesfortarget",
    "title": "PMO fields overview",
    "section": "RepresentativeMicrohaplotypesForTarget",
    "text": "RepresentativeMicrohaplotypesForTarget\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/RepresentativeMicrohaplotypesForTarget/ Show RepresentativeMicrohaplotypesForTarget fields  \n\n\nRequired\n\ntarget_id (type=integer)\n\nthe index into the target_info list\n\n\n\nmicrohaplotypes (type=list of RepresentativeMicrohaplotype)\n\na list of the microhaplotypes detected for a target\n\n\nOptional\n\nmhap_location (type=GenomicLocation)\n\na genomic location that was analyzed for this target info, this allows listing location that may be different from the full target location (e.g 1 base in from the full)\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#sequencinginfo",
    "href": "format/FormatOverview.html#sequencinginfo",
    "title": "PMO fields overview",
    "section": "SequencingInfo",
    "text": "SequencingInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/SequencingInfo/ Show SequencingInfo fields  \n\n\nRequired\n\nsequencing_info_name (type=string)\n\na name of for the sequencing done, e.g. batch1\n\n\n\nseq_platform (type=string)\n\nthe sequencing technology used to sequence the run, e.g. ILLUMINA, NANOPORE, PACBIO\n\n\n\nseq_instrument_model (type=string)\n\nthe sequencing instrument model used to sequence the run, e.g. NextSeq 2000, MinION, Revio\n\n\n\nseq_date (type=string)\n\nthe date of sequencing, should be YYYY-MM or YYYY-MM-DD\n\n\n\nlibrary_layout (type=string)\n\nSpecify the configuration of reads, e.g. paired-end, single\n\n\n\nlibrary_strategy (type=string)\n\nwhat the nuceloacid sequencing/amplification strategy was (common names are AMPLICON, WGS)\n\n\n\nlibrary_source (type=string)\n\nSource of amplification material (common names GENOMIC, TRANSCRIPTOMIC)\n\n\n\nlibrary_selection (type=string)\n\nhow amplification was done (common are PCR=Source material was selected by designed primers, RANDOM =Random selection by shearing or other method)\n\n\nOptional\n\nlibrary_kit (type=string)\n\nName, version, and applicable cell or cycle numbers for the kit used to prepare libraries and load cells or chips for sequencing. If possible, include a part number, e.g. MiSeq Reagent Kit v3 (150-cycle), MS-102-3001\n\n\n\nlibrary_screen (type=string)\n\nDescribe enrichment, screening, or normalization methods applied during amplification or library preparation, e.g. size selection 390bp, diluted to 1 ng DNA/sample\n\n\n\nnucl_acid_amp (type=string)\n\nLink to a reference or kit that describes the enzymatic amplification of nucleic acids\n\n\n\nnucl_acid_amp_date (type=string)\n\nthe date of the nucleoacid amplification\n\n\n\nnucl_acid_ext (type=string)\n\nLink to a reference or kit that describes the recovery of nucleic acids from the sample\n\n\n\nnucl_acid_ext_date (type=string)\n\nthe date of the nucleoacid extraction\n\n\n\npcr_cond (type=string)\n\nthe method/conditions for PCR, List PCR cycles used to amplify the target\n\n\n\nseq_center (type=string)\n\nName of facility where sequencing was performed (lab, core facility, or company)\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#specimeninfo",
    "href": "format/FormatOverview.html#specimeninfo",
    "title": "PMO fields overview",
    "section": "SpecimenInfo",
    "text": "SpecimenInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/SpecimenInfo/ Show SpecimenInfo fields  \n\n\nRequired\n\nspecimen_name (type=string)\n\nan identifier for the specimen, should be unique within this sample set\n\n\n\nspecimen_taxon_id (type= list of integer)\n\nthe NCBI taxonomy number of the organism in specimen, can list multiple if a mixed sample\n\n\n\nhost_taxon_id (type=integer)\n\nthe NCBI taxonomy number of the host that the specimen was collected from\n\n\n\ncollection_date (type=string)\n\nthe date of the specimen collection, can be YYYY, YYYY-MM, or YYYY-MM-DD\n\n\n\ncollection_country (type=string)\n\nthe name of country collected in, would be the same as admin level 0\n\n\n\nproject_id (type=integer)\n\nthe index into the project_info list\n\n\nOptional\n\nalternate_identifiers (type=list of string)\n\na list of optional alternative names for the specimens\n\n\n\ndrug_usage (type=list of string)\n\nAny drug used by subject and the frequency of usage; can include multiple drugs used\n\n\n\nenv_broad_scale (type=string)\n\nthe broad environment from which the specimen was collected, e.g. highlands, lowlands, mountainous region\n\n\n\nenv_local_scale (type=string)\n\nthe local environment from which the specimen was collected, e.g. jungle, urban, rural\n\n\n\nenv_medium (type=string)\n\nthe environment medium from which the specimen was collected from\n\n\n\ngeo_admin1 (type=string)\n\ngeographical admin level 1, the secondary large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin2 (type=string)\n\ngeographical admin level 2, the third large demarcation of a nation (nation = admin level 0)\n\n\n\ngeo_admin3 (type=string)\n\ngeographical admin level 3, the third large demarcation of a nation (nation = admin level 0)\n\n\n\nhost_age (type=number)\n\nif specimen is from a person, the age in years of the person, can be float value so for 3 month old put 0.25\n\n\n\nhost_sex (type=string)\n\nif specimen is from a person, the sex listed for that person\n\n\n\nhost_subject_id (type=integer)\n\nan identifier for the individual a specimen was collected from\n\n\n\nlat_lon (type=string)\n\nthe latitude and longitude of the collection site of the specimen\n\n\n\nmicroscopy_parasite_density_info (type=list of ParasiteDensity)\n\none or more parasite densities in microliters for this specimen\n\n\n\nspecimen_collect_device (type=string)\n\nthe way the specimen was collected, e.g. whole blood, dried blood spot\n\n\n\nspecimen_comments (type=list of string)\n\nany additional comments about the specimen\n\n\n\nspecimen_store_loc (type=string)\n\nthe specimen store site, address or facility name\n\n\n\nspecimen_type (type=string)\n\nwhat type of specimen this is, e.g. negative_control, positive_control, field_sample\n\n\n\nstorage_plate_info (type=PlateInfo)\n\nplate location of where specimen is stored if stored in a plate\n\n\n\ntravel_out_six_month (type=list of string)\n\nSpecification of the countries travelled in the last six months; can include multiple travels\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#stagereadcounts",
    "href": "format/FormatOverview.html#stagereadcounts",
    "title": "PMO fields overview",
    "section": "StageReadCounts",
    "text": "StageReadCounts\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/StageReadCounts/ Show StageReadCounts fields  \n\n\nRequired\n\nread_count (type=integer)\n\nthe read counts\n\n\n\nstage (type=string)\n\nthe stage of the pipeline, e.g. demultiplexed, denoised, etc\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverview.html#targetinfo",
    "href": "format/FormatOverview.html#targetinfo",
    "title": "PMO fields overview",
    "section": "TargetInfo",
    "text": "TargetInfo\nhttps://plasmogenepi.github.io/portable-microhaplotype-object/TargetInfo/ Show TargetInfo fields  \n\n\nRequired\n\ntarget_name (type=string)\n\nan identifier for this target\n\n\n\nforward_primer (type=PrimerInfo)\n\nthe forward primer associated with this target\n\n\n\nreverse_primer (type=PrimerInfo)\n\nthe reverse primer associated with this target\n\n\nOptional\n\ngene_name (type=string)\n\nan identifier of the gene, if any, is being covered with this targeted\n\n\n\ninsert_location (type=GenomicLocation)\n\nthe intended genomic location of the insert of the amplicon (the location between the end of the forward primer and the beginning of the reverse primer)\n\n\n\nmarkers_of_interest (type=list of MarkerOfInterest)\n\na list of covered markers of interest\n\n\n\ntarget_attributes (type=list of string)\n\na list of classification type for the primer target\n\n\nExample\n\nCode"
  },
  {
    "objectID": "format/FormatOverviewAdvanced.html",
    "href": "format/FormatOverviewAdvanced.html",
    "title": "Format Overview For Developers",
    "section": "",
    "text": "Format overview\n\n\n\nPMO\n\nPMO\nBioMethod_NODE\n\nBioMethodtypelistorsingle valuefieldsrequiredstringsingleprogram_versionstringsingleprogramoptionalstringlistadditional_argumentstringsingleprogram_description\nBioinformaticsMethodInfo_NODE\n\nBioinformaticsMethodInfotypelistorsingle valuefieldsrequiredBioMethodsingledemultiplexing_methodBioMethodsingledenoising_methodoptionalBioMethodlistadditional_methodsstringsinglebioinformatics_method_name\nBioinformaticsMethodInfo_NODE:additional_methods-&gt;BioMethod_NODE:BioMethod\n\n\nBioinformaticsMethodInfo_NODE:demultiplexing_method-&gt;BioMethod_NODE:BioMethod\n\n\nBioinformaticsMethodInfo_NODE:denoising_method-&gt;BioMethod_NODE:BioMethod\n\n\nBioinformaticsRunInfo_NODE\n\nBioinformaticsRunInfotypelistorsingle valuefieldsrequiredintegersinglebioinformatics_methods_idstringsinglerun_dateoptionalstringsinglebioinformatics_run_name\nExperimentInfo_NODE\n\nExperimentInfotypelistorsingle valuefieldsrequiredintegersinglesequencing_info_idintegersinglespecimen_idintegersinglepanel_idstringsingleexperiment_sample_nameoptionalstringsingleaccessionPlateInfosinglelibrary_prep_plate_infoParasiteDensitylistqpcr_parasite_density_info\nParasiteDensity_NODE\n\nParasiteDensitytypelistorsingle valuefieldsrequiredstringsingledensity_methodnumbersingleparasite_densityoptionalstringsingledate_measuredstringsingledensity_method_comments\nExperimentInfo_NODE:qpcr_parasite_density_info-&gt;ParasiteDensity_NODE:ParasiteDensity\n\n\nPlateInfo_NODE\n\nPlateInfotypelistorsingle valuefieldsrequiredoptionalintegersingleplate_colstringsingleplate_namestringsingleplate_row\nExperimentInfo_NODE:library_prep_plate_info-&gt;PlateInfo_NODE:PlateInfo\n\n\nGenomeInfo_NODE\n\nGenomeInfotypelistorsingle valuefieldsrequiredstringsinglenamestringsinglegenome_versionintegersingletaxon_idstringsingleurloptionalstringlistchromosomesstringsinglegff_url\nGenomicLocation_NODE\n\nGenomicLocationtypelistorsingle valuefieldsrequiredintegersinglegenome_idstringsinglechromintegersinglestartintegersingleendoptionalstringsingleref_seqstringsinglestrand\nMarkerOfInterest_NODE\n\nMarkerOfInteresttypelistorsingle valuefieldsrequiredGenomicLocationsinglemarker_locationoptionalstringlistassociations\nMarkerOfInterest_NODE:marker_location-&gt;GenomicLocation_NODE:GenomicLocation\n\n\nMaskingInfo_NODE\n\nMaskingInfotypelistorsingle valuefieldsrequiredintegersingleseq_startintegersingleseq_segment_sizeintegersinglereplacement_size\nMicrohaplotypeForTarget_NODE\n\nMicrohaplotypeForTargettypelistorsingle valuefieldsrequiredintegersinglemhap_idintegersinglereadsoptionalintegersingleumis\nMicrohaplotypesDetected_NODE\n\nMicrohaplotypesDetectedtypelistorsingle valuefieldsrequiredintegersinglebioinformatics_run_idMicrohaplotypesForSamplelistexperiment_samples\nMicrohaplotypesForSample_NODE\n\nMicrohaplotypesForSampletypelistorsingle valuefieldsrequiredintegersingleexperiment_sample_idMicrohaplotypesForTargetlisttarget_results\nMicrohaplotypesDetected_NODE:experiment_samples-&gt;MicrohaplotypesForSample_NODE:MicrohaplotypesForSample\n\n\nMicrohaplotypesForTarget_NODE\n\nMicrohaplotypesForTargettypelistorsingle valuefieldsrequiredintegersinglemhaps_target_idMicrohaplotypeForTargetlisthaps\nMicrohaplotypesForSample_NODE:target_results-&gt;MicrohaplotypesForTarget_NODE:MicrohaplotypesForTarget\n\n\nMicrohaplotypesForTarget_NODE:haps-&gt;MicrohaplotypeForTarget_NODE:MicrohaplotypeForTarget\n\n\nPanelInfo_NODE\n\nPanelInfotypelistorsingle valuefieldsrequiredReactionInfolistreactionsstringsinglepanel_name\nReactionInfo_NODE\n\nReactionInfotypelistorsingle valuefieldsrequiredintegerlistpanel_targetsstringsinglereaction_name\nPanelInfo_NODE:reactions-&gt;ReactionInfo_NODE:ReactionInfo\n\n\nPmoGenerationMethod_NODE\n\nPmoGenerationMethodtypelistorsingle valuefieldsrequiredstringsingleprogram_versionstringsingleprogram_name\nPmoHeader_NODE\n\nPmoHeadertypelistorsingle valuefieldsrequiredstringsinglepmo_versionoptionalstringsinglecreation_datePmoGenerationMethodsinglegeneration_method\nPmoHeader_NODE:generation_method-&gt;PmoGenerationMethod_NODE:PmoGenerationMethod\n\n\nPortableMicrohaplotypeObject_NODE\n\nPortableMicrohaplotypeObjecttypelistorsingle valuefieldsrequiredExperimentInfolistexperiment_infoSpecimenInfolistspecimen_infoSequencingInfolistsequencing_infoPanelInfolistpanel_infoTargetInfolisttarget_infoGenomeInfolisttargeted_genomesRepresentativeMicrohaplotypessinglemicrohaplotypes_infoBioinformaticsMethodInfolistbioinformatics_methods_infoBioinformaticsRunInfolistbioinformatics_run_infoMicrohaplotypesDetectedlistmicrohaplotypes_detectedProjectInfolistproject_infoPmoHeadersinglepmo_headeroptionalReadCountsByStagelistread_counts_by_stage\nPortableMicrohaplotypeObject_NODE:bioinformatics_methods_info-&gt;BioinformaticsMethodInfo_NODE:BioinformaticsMethodInfo\n\n\nPortableMicrohaplotypeObject_NODE:bioinformatics_run_info-&gt;BioinformaticsRunInfo_NODE:BioinformaticsRunInfo\n\n\nPortableMicrohaplotypeObject_NODE:experiment_info-&gt;ExperimentInfo_NODE:ExperimentInfo\n\n\nPortableMicrohaplotypeObject_NODE:targeted_genomes-&gt;GenomeInfo_NODE:GenomeInfo\n\n\nPortableMicrohaplotypeObject_NODE:microhaplotypes_detected-&gt;MicrohaplotypesDetected_NODE:MicrohaplotypesDetected\n\n\nPortableMicrohaplotypeObject_NODE:panel_info-&gt;PanelInfo_NODE:PanelInfo\n\n\nPortableMicrohaplotypeObject_NODE:pmo_header-&gt;PmoHeader_NODE:PmoHeader\n\n\nProjectInfo_NODE\n\nProjectInfotypelistorsingle valuefieldsrequiredstringsingleproject_namestringsingleproject_descriptionoptionalstringsingleBioProject_accessionstringsingleproject_collector_chief_scientiststringlistproject_contributorsstringsingleproject_type\nPortableMicrohaplotypeObject_NODE:project_info-&gt;ProjectInfo_NODE:ProjectInfo\n\n\nReadCountsByStage_NODE\n\nReadCountsByStagetypelistorsingle valuefieldsrequiredintegersinglebioinformatics_run_idReadCountsByStageForExperimentalSamplelistread_counts_by_experimental_sample_by_stage\nPortableMicrohaplotypeObject_NODE:read_counts_by_stage-&gt;ReadCountsByStage_NODE:ReadCountsByStage\n\n\nRepresentativeMicrohaplotypes_NODE\n\nRepresentativeMicrohaplotypestypelistorsingle valuefieldsrequiredRepresentativeMicrohaplotypesForTargetlisttargets\nPortableMicrohaplotypeObject_NODE:microhaplotypes_info-&gt;RepresentativeMicrohaplotypes_NODE:RepresentativeMicrohaplotypes\n\n\nSequencingInfo_NODE\n\nSequencingInfotypelistorsingle valuefieldsrequiredstringsinglesequencing_info_namestringsingleseq_platformstringsingleseq_instrument_modelstringsingleseq_datestringsinglelibrary_layoutstringsinglelibrary_strategystringsinglelibrary_sourcestringsinglelibrary_selectionoptionalstringsinglelibrary_kitstringsinglelibrary_screenstringsinglenucl_acid_ampstringsinglenucl_acid_amp_datestringsinglenucl_acid_extstringsinglenucl_acid_ext_datestringsinglepcr_condstringsingleseq_center\nPortableMicrohaplotypeObject_NODE:sequencing_info-&gt;SequencingInfo_NODE:SequencingInfo\n\n\nSpecimenInfo_NODE\n\nSpecimenInfotypelistorsingle valuefieldsrequiredstringsinglespecimen_nameintegerlistspecimen_taxon_idintegersinglehost_taxon_idstringsinglecollection_datestringsinglecollection_countryintegersingleproject_idoptionalstringlistalternate_identifiersstringlistdrug_usagestringsingleenv_broad_scalestringsingleenv_local_scalestringsingleenv_mediumstringsinglegeo_admin1stringsinglegeo_admin2stringsinglegeo_admin3numbersinglehost_agestringsinglehost_sexintegersinglehost_subject_idstringsinglelat_lonParasiteDensitylistmicroscopy_parasite_density_infostringsinglespecimen_collect_devicestringlistspecimen_commentsstringsinglespecimen_store_locstringsinglespecimen_typePlateInfosinglestorage_plate_infostringlisttravel_out_six_month\nPortableMicrohaplotypeObject_NODE:specimen_info-&gt;SpecimenInfo_NODE:SpecimenInfo\n\n\nTargetInfo_NODE\n\nTargetInfotypelistorsingle valuefieldsrequiredstringsingletarget_namePrimerInfosingleforward_primerPrimerInfosinglereverse_primeroptionalstringsinglegene_nameGenomicLocationsingleinsert_locationMarkerOfInterestlistmarkers_of_intereststringlisttarget_attributes\nPortableMicrohaplotypeObject_NODE:target_info-&gt;TargetInfo_NODE:TargetInfo\n\n\nPrimerInfo_NODE\n\nPrimerInfotypelistorsingle valuefieldsrequiredstringsingleseqoptionalGenomicLocationsinglelocation\nPrimerInfo_NODE:location-&gt;GenomicLocation_NODE:GenomicLocation\n\n\nReadCountsByStageForExperimentalSample_NODE\n\nReadCountsByStageForExperimentalSampletypelistorsingle valuefieldsrequiredintegersingleexperiment_sample_idintegersingletotal_raw_countoptionalReadCountsByStageForTargetlistread_counts_for_targets\nReadCountsByStage_NODE:read_counts_by_experimental_sample_by_stage-&gt;ReadCountsByStageForExperimentalSample_NODE:ReadCountsByStageForExperimentalSample\n\n\nReadCountsByStageForTarget_NODE\n\nReadCountsByStageForTargettypelistorsingle valuefieldsrequiredintegersingletarget_idStageReadCountsliststages\nReadCountsByStageForExperimentalSample_NODE:read_counts_for_targets-&gt;ReadCountsByStageForTarget_NODE:ReadCountsByStageForTarget\n\n\nStageReadCounts_NODE\n\nStageReadCountstypelistorsingle valuefieldsrequiredintegersingleread_countstringsinglestage\nReadCountsByStageForTarget_NODE:stages-&gt;StageReadCounts_NODE:StageReadCounts\n\n\nRepresentativeMicrohaplotype_NODE\n\nRepresentativeMicrohaplotypetypelistorsingle valuefieldsrequiredstringsingleseqoptionalstringlistalt_annotationsMaskingInfolistmaskingstringsinglemicrohaplotype_namestringsinglepseudocigarstringsinglequality\nRepresentativeMicrohaplotype_NODE:masking-&gt;MaskingInfo_NODE:MaskingInfo\n\n\nRepresentativeMicrohaplotypesForTarget_NODE\n\nRepresentativeMicrohaplotypesForTargettypelistorsingle valuefieldsrequiredintegersingletarget_idRepresentativeMicrohaplotypelistmicrohaplotypesoptionalGenomicLocationsinglemhap_location\nRepresentativeMicrohaplotypes_NODE:targets-&gt;RepresentativeMicrohaplotypesForTarget_NODE:RepresentativeMicrohaplotypesForTarget\n\n\nRepresentativeMicrohaplotypesForTarget_NODE:mhap_location-&gt;GenomicLocation_NODE:GenomicLocation\n\n\nRepresentativeMicrohaplotypesForTarget_NODE:microhaplotypes-&gt;RepresentativeMicrohaplotype_NODE:RepresentativeMicrohaplotype\n\n\nSpecimenInfo_NODE:microscopy_parasite_density_info-&gt;ParasiteDensity_NODE:ParasiteDensity\n\n\nSpecimenInfo_NODE:storage_plate_info-&gt;PlateInfo_NODE:PlateInfo\n\n\nTargetInfo_NODE:insert_location-&gt;GenomicLocation_NODE:GenomicLocation\n\n\nTargetInfo_NODE:markers_of_interest-&gt;MarkerOfInterest_NODE:MarkerOfInterest\n\n\nTargetInfo_NODE:forward_primer-&gt;PrimerInfo_NODE:PrimerInfo\n\n\nTargetInfo_NODE:reverse_primer-&gt;PrimerInfo_NODE:PrimerInfo\n\n\n\n\n\nPython implementation\nLinkml generates a datamodel file with all classes: https://github.com/PlasmoGenEpi/portable-micorhaplotype-object/blob/main/src/plasmo_tar_amp_schema/datamodel/plasmo_tar_amp_schema.py\nTools\nStarted development of a tool called pmotools. Python implementation can be found here: https://github.com/PlasmoGenEpi/pmotools-python/tree/develop\nFrom GEM meeting\n\nadding header with info on each field\nadding version to header\nrandom access ability"
  },
  {
    "objectID": "Tools_Installation/pmotools-python_installation.html",
    "href": "Tools_Installation/pmotools-python_installation.html",
    "title": "pmotools-python installation",
    "section": "",
    "text": "pmotools-python is a tool base for interacting with the PMO format file in python. It provides both code to include in your python package as well as a command line interface to run some basic scripts on PMO files.\n\npmotools-python code can be found on github https://github.com/PlasmoGenEpi/pmotools-python/tree/develop\n\nDownloading repo\n\nCodegit clone git@github.com:PlasmoGenEpi/pmotools-python.git\n\n\nCurrently (as 2024-10) majority of code is currently still in develop branch\n\nCodecd pmotools-python\ngit checkout develop\n\n\n\nTo set up environment that has all the python libraries install a env library is included and can be install/activated via conda or mamba\n\nCodeconda env create -f envs/pmotools-env.yml \n\nconda active pmotools\n\n\n\nFrom within repo can install with pip in a virtual environment\n\nCodepip install -e . \n\n\n\npmotools-python can be included in python scripts but also there is a command line interface that includes several utilities that uses the code base, this interface can be included by including the scripts directory in your PATH or by calling the script directory\n\nCode# navigate to git directory\ncd pmotools-python\n\n##  add to path (must be done when within the git directory, or replace $(pwd) with the full path nmae to the git repo\nexport PATH=\"$(pwd)/scripts:$PATH\"\n\n\n\nTo enable bash auto-completion for pmotools-runner.py script located in the scripts directory mentioned above, add the following to your ~/.bash_completion and make sure it’s being loaded as part of your .bashrc and/or ~/.bash_profile (on MacOS) or ~/.profile (on ubuntu)\n\nCode_comp_pmotools_runner()\n{\n    local cur prev opts base\n    COMPREPLY=()\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"\n    if [[ $COMP_CWORD -lt 2 ]] ; then\n        opts=$(for x in `${COMP_WORDS[0]} | grep \"^\\s.*-\" | sed 's/ -.*//g' | tr -d '[:blank:]'`; do echo ${x} ; done )\n        COMPREPLY=($(compgen -W \"${opts}\" -- ${cur}))\n    elif [[ ${cur} == -* ]]; then\n        opts=$(for x in `${COMP_WORDS[0]} ${COMP_WORDS[1]} -h | grep \" -\" | sed \"s/^. *-/-/g\" | sed \"s/   .*//g\" | sed \"s/, / /g\"`; do echo ${x} ; done )\n        COMPREPLY=($(compgen -W \"${opts}\" -- ${cur}))\n    else\n        _filedir\n    fi\n   return 0\n}\n\n\ncomplete -F _comp_pmotools_runner pmotools-runner.py\n\n\nThe above can also be found within the repo in the etc/ folder."
  },
  {
    "objectID": "Tools_Installation/pmotools-python_installation.html#installation",
    "href": "Tools_Installation/pmotools-python_installation.html#installation",
    "title": "pmotools-python installation",
    "section": "",
    "text": "pmotools-python code can be found on github https://github.com/PlasmoGenEpi/pmotools-python/tree/develop\n\nDownloading repo\n\nCodegit clone git@github.com:PlasmoGenEpi/pmotools-python.git\n\n\nCurrently (as 2024-10) majority of code is currently still in develop branch\n\nCodecd pmotools-python\ngit checkout develop\n\n\n\nTo set up environment that has all the python libraries install a env library is included and can be install/activated via conda or mamba\n\nCodeconda env create -f envs/pmotools-env.yml \n\nconda active pmotools\n\n\n\nFrom within repo can install with pip in a virtual environment\n\nCodepip install -e . \n\n\n\npmotools-python can be included in python scripts but also there is a command line interface that includes several utilities that uses the code base, this interface can be included by including the scripts directory in your PATH or by calling the script directory\n\nCode# navigate to git directory\ncd pmotools-python\n\n##  add to path (must be done when within the git directory, or replace $(pwd) with the full path nmae to the git repo\nexport PATH=\"$(pwd)/scripts:$PATH\"\n\n\n\nTo enable bash auto-completion for pmotools-runner.py script located in the scripts directory mentioned above, add the following to your ~/.bash_completion and make sure it’s being loaded as part of your .bashrc and/or ~/.bash_profile (on MacOS) or ~/.profile (on ubuntu)\n\nCode_comp_pmotools_runner()\n{\n    local cur prev opts base\n    COMPREPLY=()\n    cur=\"${COMP_WORDS[COMP_CWORD]}\"\n    prev=\"${COMP_WORDS[COMP_CWORD-1]}\"\n    if [[ $COMP_CWORD -lt 2 ]] ; then\n        opts=$(for x in `${COMP_WORDS[0]} | grep \"^\\s.*-\" | sed 's/ -.*//g' | tr -d '[:blank:]'`; do echo ${x} ; done )\n        COMPREPLY=($(compgen -W \"${opts}\" -- ${cur}))\n    elif [[ ${cur} == -* ]]; then\n        opts=$(for x in `${COMP_WORDS[0]} ${COMP_WORDS[1]} -h | grep \" -\" | sed \"s/^. *-/-/g\" | sed \"s/   .*//g\" | sed \"s/, / /g\"`; do echo ${x} ; done )\n        COMPREPLY=($(compgen -W \"${opts}\" -- ${cur}))\n    else\n        _filedir\n    fi\n   return 0\n}\n\n\ncomplete -F _comp_pmotools_runner pmotools-runner.py\n\n\nThe above can also be found within the repo in the etc/ folder."
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html",
    "href": "pmotools-python-usages/extracting_allele_tables.html",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "To extract allele table information from a PMO the command line interactive script with pmotools-runner.py extract_allele_table can be used\n\npmotools-runner.py extract_allele_table\n\nRequired arguments\n\n\n--file - the PMO file to extract from\n\n--bioid - the tar_amp_bioinformatics_info_id id to extract the data from\n\n--output - the output stub of the files to be created\n\n\nOptional arguments\n\nBy default only 3 fields are extracted by this extractor, 1) sampleID (experiment_sample_id), 2) locus (target_id), and 3) allele (microhaplotype_id) with those default column names. This can be controlled by --default_base_col_names and if you supply 3 comma separated values you can change the default header.\nYou can also add to the table any values from the other portions of the PMO file by using the following arguments\n\nadding fields arguments\n\n\n--specimen_info_meta_fields - Meta Fields if any to include from the specimen table\n\n--experiment_info_meta_fields - Meta Fields if any to include from the experiment table\n\n--microhap_fields - additional optional fields from the detected microhaplotype object to include\n\n--representative_haps_fields - additional optional fields from the detected representative object to include\n\n\n\nOther optional arguments have to do with the ouput file over writing and delimiter being used, use -h to see all arguments\n\nCodepmotools-runner.py extract_allele_table -h\n\nusage: pmotools-runner.py extract_allele_table [-h] --bioid BIOID --file FILE\n                                               [--delim DELIM] --output OUTPUT\n                                               [--overwrite]\n                                               [--allele_freqs_output ALLELE_FREQS_OUTPUT]\n                                               [--specimen_info_meta_fields SPECIMEN_INFO_META_FIELDS]\n                                               [--experiment_info_meta_fields EXPERIMENT_INFO_META_FIELDS]\n                                               [--microhap_fields MICROHAP_FIELDS]\n                                               [--representative_haps_fields REPRESENTATIVE_HAPS_FIELDS]\n                                               [--default_base_col_names DEFAULT_BASE_COL_NAMES]\n\noptions:\n  -h, --help            show this help message and exit\n  --bioid BIOID         bio ID to extract for\n  --file FILE           PMO file\n  --delim DELIM         the delimiter of the input text file, examples\n                        tab,comma\n  --output OUTPUT       Output allele table file name path\n  --overwrite           If output file exists, overwrite it\n  --allele_freqs_output ALLELE_FREQS_OUTPUT\n                        if also writing out allele frequencies, write to this\n                        file\n  --specimen_info_meta_fields SPECIMEN_INFO_META_FIELDS\n                        Meta Fields if any to include from the specimen table\n  --experiment_info_meta_fields EXPERIMENT_INFO_META_FIELDS\n                        Meta Fields if any to include from the experiment\n                        table\n  --microhap_fields MICROHAP_FIELDS\n                        additional optional fields from the detected\n                        microhaplotype object to include\n  --representative_haps_fields REPRESENTATIVE_HAPS_FIELDS\n                        additional optional fields from the detected\n                        representative object to include\n  --default_base_col_names DEFAULT_BASE_COL_NAMES\n                        default base column names, must be length 3\n\n\nThe python code for extract_allele_table script is below\n\n\nCode\npmotools-python/scripts/extractors_from_pmo/extract_allele_table.py\n\n#!/usr/bin/env python3\nimport argparse\n\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\nfrom pmotools.pmo_utils.PMOChecker import PMOChecker\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\n\n\n\ndef parse_args_extract_for_allele_table():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--bioid', type=str, required=True, help='bio ID to extract for')\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--delim', default=\"tab\", type=str, required=False, help='the delimiter of the input text file, examples tab,comma')\n    parser.add_argument('--output', type=str, required=True, help='Output allele table file name path')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--allele_freqs_output',type=str, help='if also writing out allele frequencies, write to this file')\n\n    parser.add_argument('--specimen_info_meta_fields', type=str, required=False, help='Meta Fields if any to include from the specimen table')\n    parser.add_argument('--experiment_info_meta_fields', type=str, required=False, help='Meta Fields if any to include from the experiment table')\n    parser.add_argument('--microhap_fields', type=str, required=False, help='additional optional fields from the detected microhaplotype object to include')\n    parser.add_argument('--representative_haps_fields', type=str, required=False, help='additional optional fields from the detected representative object to include')\n    parser.add_argument('--default_base_col_names', type=str, required=False, default=\"sampleID,locus,allele\", help='default base column names, must be length 3')\n\n    return parser.parse_args()\n\ndef extract_for_allele_table():\n    args = parse_args_extract_for_allele_table()\n\n    output_delim, output_extension = Utils.process_delimiter_and_output_extension(args.delim, gzip=args.output.endswith('.gz'))\n\n    allele_per_sample_table_out_fnp = args.output if \"STDOUT\" == args.output else Utils.appendStrAsNeeded(args.output, output_extension)\n    Utils.inputOutputFileCheck(args.file, allele_per_sample_table_out_fnp, args.overwrite)\n\n    allele_freq_output = \"\"\n    if args.allele_freqs_output is not None:\n        allele_freq_output = Utils.appendStrAsNeeded(args.allele_freqs_output, output_extension)\n        Utils.inputOutputFileCheck(args.file, allele_freq_output, args.overwrite)\n\n    checker = PMOChecker()\n    pmodata = PMOReader.read_in_pmo(args.file)\n\n    checker.check_for_required_base_fields(pmodata)\n    checker.check_bioinformatics_ids_consistency(pmodata)\n    checker.check_for_bioinformatics_id(pmodata, args.bioid)\n\n    if args.specimen_info_meta_fields is not None:\n        args.specimen_info_meta_fields = Utils.parse_delimited_input_or_file(args.specimen_info_meta_fields, \",\")\n    if args.microhap_fields is not None:\n        args.microhap_fields = Utils.parse_delimited_input_or_file(args.microhap_fields, \",\")\n    if args.experiment_info_meta_fields is not None:\n        args.experiment_info_meta_fields = Utils.parse_delimited_input_or_file(args.experiment_info_meta_fields, \",\")\n    if args.representative_haps_fields is not None:\n        args.representative_haps_fields = Utils.parse_delimited_input_or_file(args.representative_haps_fields, \",\")\n\n    PMOExtractor.write_alleles_per_sample_table(pmodata, args.bioid, allele_per_sample_table_out_fnp,\n                                                 additional_specimen_infos_fields = args.specimen_info_meta_fields,\n                                                 additional_experiment_infos_fields = args.experiment_info_meta_fields,\n                                                 additional_microhap_fields = args.microhap_fields,\n                                                 additional_representative_infos_fields = args.representative_haps_fields,\n                                                 output_delimiter=output_delim,\n                                                 default_base_col_names=args.default_base_col_names.split(\",\"))\n    if args.allele_freqs_output is not None:\n        allele_counts, allele_freqs, target_totals = PMOExtractor.extract_allele_counts_freq_from_pmo(pmodata, args.bioid)\n        PMOExtractor.write_allele_freq_output(allele_freq_output, allele_freqs, output_delimiter=output_delim)\n\nif __name__ == \"__main__\":\n    extract_for_allele_table()\n\n\n\nCan download example PMOs here\n\nCodewget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite\n\n\n\nCodecd example \n\n# changing default column names  \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --default_base_col_names sample,target,hapid\n\n\nChanging the output file delimiter\n\nCodecd example \n\npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --delim ,\n\n\nAdding on additional columns from the specimen_infos section\n\nCodecd example \n\n# adding other PMO fields \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output STDOUT --specimen_info_meta_fields collection_country,parasite_density | head  \n\n\n\n\nsampleID    locus   allele  collection_country  parasite_density\n8025874217  t1  t1.2    Mozambique  477719.34375\n8025874217  t1  t1.0    Mozambique  477719.34375\n8025874217  t10 t10.0   Mozambique  477719.34375\n8025874217  t100    t100.05 Mozambique  477719.34375\n8025874217  t11 t11.09  Mozambique  477719.34375\n8025874217  t12 t12.1   Mozambique  477719.34375\n8025874217  t12 t12.2   Mozambique  477719.34375\n8025874217  t13 t13.5   Mozambique  477719.34375\n8025874217  t14 t14.00  Mozambique  477719.34375\n\n\nCan continue to add on more columns from other sections\n\nCodecd example \n\n# adding other PMO fields including seq field \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output STDOUT --specimen_info_meta_fields collection_country,parasite_density --representative_haps_fields seq | head \n\n\n\n\nsampleID    locus   allele  collection_country  parasite_density    seq\n8025874217  t1  t1.2    Mozambique  477719.34375    AACTTTTTTTATTTTTTTTGTCAATAGATAAATGATCAATATTTTCTATATTTAATCTATCAAGTATTTTTATATATCTATTATTTCTTTCTTCGATGGATAAATTATATGAATCAATATCCTTTCTTTCATCAACAAACTTTTTTATTGTTAACTCCATTTTTTTATTTA\n8025874217  t1  t1.0    Mozambique  477719.34375    AACTTTTTTTATTTTTTTTGTCAATAGATAAATGATCAATATTTTCTATATTTAATCTATCAAGTATTTTTATATATCTATTATTTCTTTCTTCGATGGATAAATTATAAGAATCAATATCCTTTCTTTCATCAACAAACTTTTTTATTGTTAACTCCATTTTTTTATTTA\n8025874217  t10 t10.0   Mozambique  477719.34375    ACTTATGTTCATGAGCTAATTTCCCACAAATACTCCATAACGAACTTTTCATTTTATTAAATTTATCTCTCAAAAGAGAATGACTATAATGCCATATTAAATACATATCTTTCCTTTCTAATTTTCCTGGTAATTCTATTATCATTCTTTCTAAATCTTCTTCTGTAACTTTT\n8025874217  t100    t100.05 Mozambique  477719.34375    TCGTTTTGAATTGTTAGAATTTAAAATGACGGAGGATTGTTATACAAAAATGTGGTTTGATTTTATGATTGATTTTGGAATAGCTACAATGAATGAAAACGAACATACTAGATCTTTTTATGGCT\n8025874217  t11 t11.09  Mozambique  477719.34375    GAATTTTCTTTTTTATGACTTTCTTCTCCTTGTTCAGAAGCTTCTTTTTCATCCTTTTTTTCTGCTGCGTCAGATAAATTGGGGGAAGCACTTGAAGATTCATTTCCTCCAGGAGTATTACTAGTACTTACTCCTTCCACATTTGGTTTTTCTTCCCCTAGAATTCTCA\n8025874217  t12 t12.1   Mozambique  477719.34375    TACACATAAGAAAAAAAAAATTTATTTATTCTTACAAAAAGAATATAAAAACAAAATTTTGGGATTTATAAATTTTTATAAACATATAACACACAAAATAAAAAAGAAACAAGAAAATGTTCATGATAAAATCACTTTTTTAAAATGTCTAAAGGAACTCTTTTTTGTCACACATACAAATG\n8025874217  t12 t12.2   Mozambique  477719.34375    TACACATAAGAAAAAAAAAATTTATTTATTCTTACAAAAAGAATATAAAAACAAAATTTTGGGATTTATAAATTTTTATAAACATATAACACACAAAATAAAAAAGAAACAAGAAAATGTTCATGATAAAATCACTTTTTTAAAATGTCTAAAGGAACTCTTTTTTGTCACACATACAAATA\n8025874217  t13 t13.5   Mozambique  477719.34375    TAATTATGAAGACAGTCTCACGACTGCATGTTATATTGATGAAAACAAATCCGATTCATCCTATAAAACTGAAGAAGAAAATGTAAACTATAATAATAAAATGGGTAAACGCAAAAATTTA\n8025874217  t14 t14.00  Mozambique  477719.34375    ACTTTTTAACACTATCATTATAATTATGTCTTTTATTTTCATATTTTTCTTTATAATAATTTATATCCTTTAATTTTTCTTTCATCAAATTTAACCATTTATCATTTAAATTCTCTTTTTCCACAGCTCCAGCATTTTTATTTATATCATCTACAACTACATCTTCCTTCACATAATTATTTATATAAAAATTATTATCATCTA\n\n\n\nMOIRE is a program that can be used to estimate COI and other population estimates from a population. See it’s github for full usage.\n\nCodemkdir -p example\ncd example \n\n# default table is all moire needs \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite\n\n\n\nCodedf &lt;- read.csv(\"example/extraction_allele_table.tsv\", sep = \"\\t\")\n\ndata &lt;- load_long_form_data(df)\n\n# With data in appropriate format, run MCMC as follows\nmcmc_results &lt;- moire::run_mcmc(data, is_missing = data$is_missing)\n\n\n\ndcifer is a program that can estimate IBD even from mixed infections. See it’s github for full usage\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --delim ,\n\n# dcifer can calculate allele frequencies if not provided or you can have extract_allele_table write them as well \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --allele_freqs_output allele_freqs_extraction --delim ,\n\n\n\nCodedsmp &lt;- readDat(\"example/extraction_allele_table.csv\", svar = \"sampleID\", lvar = \"locus\", avar = \"allele\")\n\nlrank &lt;- 2\ncoi   &lt;- getCOI(dsmp, lrank = lrank)\n\nafreq &lt;- calcAfreq(dsmp, coi, tol = 1e-5) \n\ndres0 &lt;- ibdDat(dsmp, coi, afreq, pval = TRUE, confint = TRUE, rnull = 0, \n                alpha = 0.05, nr = 1e3)"
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-moire",
    "href": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-moire",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "MOIRE is a program that can be used to estimate COI and other population estimates from a population. See it’s github for full usage.\n\nCodemkdir -p example\ncd example \n\n# default table is all moire needs \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite\n\n\n\nCodedf &lt;- read.csv(\"example/extraction_allele_table.tsv\", sep = \"\\t\")\n\ndata &lt;- load_long_form_data(df)\n\n# With data in appropriate format, run MCMC as follows\nmcmc_results &lt;- moire::run_mcmc(data, is_missing = data$is_missing)"
  },
  {
    "objectID": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-dcifer",
    "href": "pmotools-python-usages/extracting_allele_tables.html#creating-output-for-dcifer",
    "title": "Extracting allele tables using pmotools-python",
    "section": "",
    "text": "dcifer is a program that can estimate IBD even from mixed infections. See it’s github for full usage\n\nCodemkdir -p example\ncd example \n\n# default \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --delim ,\n\n# dcifer can calculate allele frequencies if not provided or you can have extract_allele_table write them as well \npmotools-runner.py extract_allele_table --file ../../format/moz2018_PMO.json.gz --bioid Mozambique2018-SeekDeep --output extraction --overwrite --allele_freqs_output allele_freqs_extraction --delim ,\n\n\n\nCodedsmp &lt;- readDat(\"example/extraction_allele_table.csv\", svar = \"sampleID\", lvar = \"locus\", avar = \"allele\")\n\nlrank &lt;- 2\ncoi   &lt;- getCOI(dsmp, lrank = lrank)\n\nafreq &lt;- calcAfreq(dsmp, coi, tol = 1e-5) \n\ndres0 &lt;- ibdDat(dsmp, coi, afreq, pval = TRUE, confint = TRUE, rnull = 0, \n                alpha = 0.05, nr = 1e3)"
  },
  {
    "objectID": "pmotools-python-usages/handling_multiple_pmos.html",
    "href": "pmotools-python-usages/handling_multiple_pmos.html",
    "title": "Handling multiple PMOs pmotools-python",
    "section": "",
    "text": "pmotools-runner.py combine_pmos\nCan download multiple PMOs here\nhttps://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nhttps://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\nCodepmotools-runner.py combine_pmos --help\n\nusage: pmotools-runner.py combine_pmos [-h] --pmo_files PMO_FILES --output\n                                       OUTPUT [--overwrite]\n\noptions:\n  -h, --help            show this help message and exit\n  --pmo_files PMO_FILES\n                        a list of PMO files to combine into 1 PMO file, must\n                        be from same amplicon panel\n  --output OUTPUT       Output new combined PMO file\n  --overwrite           If output file exists, overwrite it\n\n\nThe list of PMO files can be given comma separated to thier relative paths from where you run the script or in a file where each line is a different file to combine\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\npmotools-runner.py combine_pmos --pmo_files moz2018_PMO.json.gz,PathWeaverHeome1_PMO.json.gz --output combined_Heome1_PMO.json.gz --overwrite\n\n\nThe python code for combine_pmos script is below\n\n\nCode\npmotools-python/scripts/pmo_utils/combine_pmos.py\n\n#!/usr/bin/env python3\nimport gzip\nimport os, argparse, json\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOWriter import PMOWriter\nfrom pmotools.utils.small_utils import Utils\nfrom pmotools.pmo_utils.PMOReader import PMOReader\n\n\n\ndef parse_args_combine_pmos():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--pmo_files', type=str, required=True, help='a list of PMO files to combine into 1 PMO file, must be from same amplicon panel')\n    parser.add_argument('--output', type=str, required=True, help='Output new combined PMO file')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n\n    return parser.parse_args()\n\ndef combine_pmos():\n    args = parse_args_combine_pmos()\n\n    # set up output\n    args.output = PMOWriter.add_pmo_extension_as_needed(args.output, args.output.endswith(\".gz\"))\n    Utils.outputfile_check(args.output, args.overwrite)\n\n    # check if at least 2 PMO files supplied\n    pmo_files_list = Utils.parse_delimited_input_or_file(args.pmo_files, \",\")\n    if len(pmo_files_list) &lt; 2:\n        raise Exception(\"Only supplied \" + str(len(pmo_files_list)) + \" but multiple PMO files were expected\")\n\n    # read in the PMOs\n    pmos = PMOReader.read_in_pmos(pmo_files_list)\n\n    # combine PMOs\n    pmo_out = PMOReader.combine_multiple_pmos(pmos)\n\n    # write\n    PMOWriter.write_out_pmo(pmo_out, args.output, args.overwrite)\n\n\nif __name__ == \"__main__\":\n    combine_pmos()"
  },
  {
    "objectID": "pmotools-python-usages/extracting_panel_info_from_pmo.html",
    "href": "pmotools-python-usages/extracting_panel_info_from_pmo.html",
    "title": "Getting panel info out of PMO using pmotools-python",
    "section": "",
    "text": "Most of these basic panel info can be found underneath extract_panel_info_from_pmo\n\nCodepmotools-runner.py\n\n\n\n\npmotools v1.0.0 - A suite of tools for interacting with Portable Microhaplotype Object (pmo) file format\n\nAvailable functions organized by groups are\nconvertors_to_json\n    text_meta_to_json_meta - Convert text file meta to JSON Meta\n    excel_meta_to_json_meta - Convert excel file meta to JSON Meta\n    microhaplotype_table_to_json_file - Convert microhaplotype table to JSON Meta\n    terra_amp_output_to_json - Convert terra output table to JSON seq table\n\nextractors_from_pmo\n    extract_pmo_with_selected_meta - Extract from PMO samples and associated haplotypes with selected meta\n    extract_pmo_with_select_specimen_ids - Extract from PMO specific samples from the specimens table\n    extract_pmo_with_select_experiment_sample_ids - Extract from PMO specific experiment sample ids from the experiment_info table\n    extract_pmo_with_select_targets - Extract from PMO specific targets\n    extract_pmo_with_read_filter - Extract from PMO with a read filter\n    extract_allele_table - Extract allele tables which can be as used as input to such tools as dcifer or moire\n\nworking_with_multiple_pmos\n    combine_pmos - Combine multiple pmos of the same panel into a single pmo\n\nextract_basic_info_from_pmo\n    list_experiment_sample_ids_per_specimen_id - Each specimen_id can have multiple experiment_sample_ids, list out all in a PMO\n    list_specimen_meta_fields - List out the specimen meta fields in the specimen_info section\n    list_tar_amp_bioinformatics_info_ids - List out all the tar_amp_bioinformatics_info_ids in a PMO file\n    count_specimen_meta - Count the values of specific specimen meta fields in the specimen_info section\n    count_targets_per_sample - Count the number of targets per sample\n    count_samples_per_target - Count the number of samples per target\n\nextract_panel_info_from_pmo\n    extract_insert_of_panels - Extract the insert of panels from a PMO\n    extract_refseq_of_inserts_of_panels - Extract the ref_seq of panels from a PMO\n\n\nGetting files for examples\n\nCodecd example \n\nwget https://plasmogenepi.github.io/PMO_Docs/format/moz2018_PMO.json.gz\nwget https://plasmogenepi.github.io/PMO_Docs/format/PathWeaverHeome1_PMO.json.gz\n\n\nExtract insert locations of panels from PMO\nThis will extract the insert location of targets of the panel infos out of a PMO and write it out as a bed file\n\nCodepmotools-runner.py extract_insert_of_panels -h \n\nusage: pmotools-runner.py extract_insert_of_panels [-h] --file FILE\n                                                   [--output OUTPUT]\n                                                   [--overwrite]\n                                                   [--add_ref_seqs]\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n  --add_ref_seqs   add ref seqs to the output as ref_seq\n\n\nThe python code for extract_insert_of_panels script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/extract_insert_of_panels.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_insert_of_panels():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.add_argument('--add_ref_seqs', action = 'store_true', help='add ref seqs to the output as ref_seq')\n\n    return parser.parse_args()\n\ndef extract_insert_of_panels():\n    args = parse_args_extract_insert_of_panels()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # get panel insert locations\n    panel_bed_locs = PMOExtractor.extract_panels_insert_bed_loc(pmo)\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\t\".join([\"#chrom\", \"start\", \"end\", \"target_id\", \"length\", \"strand\", \"extra_info\"]))\n        if args.add_ref_seqs:\n            f.write(\"\\tref_seq\")\n        f.write(\"\\n\")\n        for panel_id, bed_locs in panel_bed_locs.items():\n            for loc in bed_locs:\n                f.write(\"\\t\".join([loc.chrom, str(loc.start), str(loc.end), loc.name, str(loc.score), loc.strand, loc.extra_info]))\n                if args.add_ref_seqs:\n                    f.write(\"\\t\" + str(loc.ref_seq))\n                f.write(\"\\n\")\n\nif __name__ == \"__main__\":\n    extract_insert_of_panels()\n\n\n\n\nCodecd example \npmotools-runner.py extract_insert_of_panels --file ../../format/moz2018_PMO.json.gz\n\n#chrom  start   end target_id   length  strand  extra_info\nPf3D7_01_v3 145449  145622  t1  173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_02_v3 109807  109982  t10 175 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 3214351 3214478 t100    127 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_02_v3 278165  278336  t11 171 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_02_v3 470492  470676  t12 184 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_02_v3 805822  805942  t13 120 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 85440   85646   t14 206 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 141963  142181  t15 218 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 221363  221495  t16 132 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 618396  618581  t17 185 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 654002  654175  t18 173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_03_v3 850816  850989  t19 173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 179903  180115  t2  212 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 109912  110087  t20 175 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 133491  133701  t21 210 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 141778  141945  t22 167 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 415653  415826  t23 173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 544718  544861  t24 143 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 748230  748436  t25 206 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 748533  748696  t26 163 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 802525  802713  t27 188 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 1037634 1037844 t28 210 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 1100656 1100831 t29 175 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 181557  181673  t3  116 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 1102389 1102578 t30 189 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 1113450 1113604 t31 154 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_04_v3 1128489 1128673 t32 184 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_05_v3 329378  329550  t33 172 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_05_v3 958059  958221  t34 162 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_05_v3 958389  958506  t35 117 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_05_v3 1042162 1042281 t36 119 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_05_v3 1309609 1309744 t37 135 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_06_v3 145343  145501  t38 158 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_06_v3 532195  532378  t39 183 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 495971  496143  t4  172 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 165235  165422  t40 187 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 166035  166167  t41 132 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 298886  299005  t42 119 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 729975  730088  t43 113 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 1149415 1149585 t44 170 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_07_v3 1358694 1358911 t45 217 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 102326  102500  t46 174 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 336468  336647  t47 179 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 339168  339357  t48 189 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 549993  550218  t49 225 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 512199  512388  t5  189 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 933023  933143  t50 120 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 1269320 1269456 t51 136 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 1344686 1344819 t52 133 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_08_v3 1362891 1363087 t53 196 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 516928  517092  t54 164 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 596133  596334  t55 201 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 685601  685792  t56 191 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 1178894 1179078 t57 184 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 1406405 1406541 t58 136 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_09_v3 1437114 1437303 t59 189 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 531682  531900  t6  218 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_10_v3 377095  377209  t60 114 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_10_v3 992371  992544  t61 173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_10_v3 1386700 1386869 t62 169 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_10_v3 1399544 1399711 t63 167 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_10_v3 1436479 1436682 t64 203 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 119486  119693  t65 207 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1009856 1010038 t66 182 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1018953 1019085 t67 132 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1376185 1376372 t68 187 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1552430 1552640 t69 210 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 532690  532844  t7  154 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1750865 1751055 t70 190 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_11_v3 1816211 1816425 t71 214 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 63166   63280   t72 114 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 659891  660010  t73 119 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 684088  684261  t74 173 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 943258  943428  t75 170 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 1237431 1237603 t76 172 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_12_v3 2050130 2050314 t77 184 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 103659  103879  t78 220 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 156566  156722  t79 156 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 534215  534368  t8  153 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 1150303 1150493 t80 190 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 1419543 1419670 t81 127 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 1725365 1725570 t82 205 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 1876352 1876534 t83 182 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 2114975 2115142 t84 167 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 2124634 2124847 t85 213 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 2479086 2479246 t86 160 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 2481106 2481288 t87 182 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_13_v3 2669135 2669307 t88 172 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 39953   40137   t89 184 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_01_v3 534941  535110  t9  169 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 120215  120351  t90 136 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 150105  150294  t91 189 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 279663  279786  t92 123 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 407379  407571  t93 192 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 564208  564377  t94 169 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 1038369 1038486 t95 117 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 1956129 1956286 t96 157 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 1992289 1992426 t97 137 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 2524962 2525089 t98 127 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\nPf3D7_14_v3 3124642 3124842 t99 200 +   [genome_name_version=3D7_2020-09-01;panel_id=heomev1;]\n\n\n\nCodecd example \npmotools-runner.py extract_insert_of_panels --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_panel_insert_locs.bed --overwrite\n\n\nExtract ref sequences of insert locations of panels from PMO\nThis will extract the reference sequence of the insert location of the targets within the panel info out of a PMO and write it out as a table. The reference sequence is an optional field and so if no reference sequence is loaded then just blanks will be extracted\n\nCodepmotools-runner.py extract_refseq_of_inserts_of_panels -h \n\nusage: pmotools-runner.py extract_refseq_of_inserts_of_panels\n       [-h] --file FILE [--output OUTPUT] [--overwrite]\n\nextract ref_seq of inserts of panels, but if no ref_seq is save in the PMO\nwill just be blank\n\noptions:\n  -h, --help       show this help message and exit\n  --file FILE      PMO file\n  --output OUTPUT  output file\n  --overwrite      If output file exists, overwrite it\n\n\nThe python code for extract_refseq_of_inserts_of_panels script is below\n\n\nCode\npmotools-python/scripts/extract_info_from_pmo/extract_refseq_of_inserts_of_panels.py\n\n#!/usr/bin/env python3\nimport os, argparse, json\nimport sys\nfrom collections import defaultdict\n\nimport pandas as pd\n\nfrom pmotools.pmo_utils.PMOExtractor import PMOExtractor\nfrom pmotools.pmo_utils.PMOReader import PMOReader\nfrom pmotools.utils.small_utils import Utils\n\n\ndef parse_args_extract_refseq_of_inserts_of_panels():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--file', type=str, required=True, help='PMO file')\n    parser.add_argument('--output', type=str, default=\"STDOUT\", required=False, help='output file')\n    parser.add_argument('--overwrite', action = 'store_true', help='If output file exists, overwrite it')\n    parser.description = \"extract ref_seq of inserts of panels, but if no ref_seq is save in the PMO will just be blank\"\n    return parser.parse_args()\n\ndef extract_refseq_of_inserts_of_panels():\n    args = parse_args_extract_refseq_of_inserts_of_panels()\n\n    # check files\n    Utils.inputOutputFileCheck(args.file, args.output, args.overwrite)\n\n    # read in PMO\n    pmo = PMOReader.read_in_pmo(args.file)\n\n    # get panel insert locations\n    panel_bed_locs = PMOExtractor.extract_panels_insert_bed_loc(pmo)\n\n    # write\n    output_target = sys.stdout if args.output == \"STDOUT\" else open(args.output, \"w\")\n    with output_target as f:\n        f.write(\"\\t\".join([\"panel_id\", \"target_id\", \"ref_seq\"]) + \"\\n\")\n        for panel_id, bed_locs in panel_bed_locs.items():\n            for loc in bed_locs:\n                f.write(\"\\t\".join([str(panel_id), loc.name, loc.ref_seq]) + \"\\n\")\n\nif __name__ == \"__main__\":\n    extract_refseq_of_inserts_of_panels()\n\n\n\n\nCodecd example \npmotools-runner.py extract_refseq_of_inserts_of_panels --file ../../format/moz2018_PMO.json.gz\n\npanel_id    target_id   ref_seq\nheomev1 t1  \nheomev1 t10 \nheomev1 t100    \nheomev1 t11 \nheomev1 t12 \nheomev1 t13 \nheomev1 t14 \nheomev1 t15 \nheomev1 t16 \nheomev1 t17 \nheomev1 t18 \nheomev1 t19 \nheomev1 t2  \nheomev1 t20 \nheomev1 t21 \nheomev1 t22 \nheomev1 t23 \nheomev1 t24 \nheomev1 t25 \nheomev1 t26 \nheomev1 t27 \nheomev1 t28 \nheomev1 t29 \nheomev1 t3  \nheomev1 t30 \nheomev1 t31 \nheomev1 t32 \nheomev1 t33 \nheomev1 t34 \nheomev1 t35 \nheomev1 t36 \nheomev1 t37 \nheomev1 t38 \nheomev1 t39 \nheomev1 t4  \nheomev1 t40 \nheomev1 t41 \nheomev1 t42 \nheomev1 t43 \nheomev1 t44 \nheomev1 t45 \nheomev1 t46 \nheomev1 t47 \nheomev1 t48 \nheomev1 t49 \nheomev1 t5  \nheomev1 t50 \nheomev1 t51 \nheomev1 t52 \nheomev1 t53 \nheomev1 t54 \nheomev1 t55 \nheomev1 t56 \nheomev1 t57 \nheomev1 t58 \nheomev1 t59 \nheomev1 t6  \nheomev1 t60 \nheomev1 t61 \nheomev1 t62 \nheomev1 t63 \nheomev1 t64 \nheomev1 t65 \nheomev1 t66 \nheomev1 t67 \nheomev1 t68 \nheomev1 t69 \nheomev1 t7  \nheomev1 t70 \nheomev1 t71 \nheomev1 t72 \nheomev1 t73 \nheomev1 t74 \nheomev1 t75 \nheomev1 t76 \nheomev1 t77 \nheomev1 t78 \nheomev1 t79 \nheomev1 t8  \nheomev1 t80 \nheomev1 t81 \nheomev1 t82 \nheomev1 t83 \nheomev1 t84 \nheomev1 t85 \nheomev1 t86 \nheomev1 t87 \nheomev1 t88 \nheomev1 t89 \nheomev1 t9  \nheomev1 t90 \nheomev1 t91 \nheomev1 t92 \nheomev1 t93 \nheomev1 t94 \nheomev1 t95 \nheomev1 t96 \nheomev1 t97 \nheomev1 t98 \nheomev1 t99 \n\n\n\nCodecd example \npmotools-runner.py extract_refseq_of_inserts_of_panels --file ../../format/moz2018_PMO.json.gz --output moz2018_PMO_panel_ref_seqs.tsv --overwrite"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html",
    "href": "pmotools-python-usages-notebooks/build_pmo.html",
    "title": "Creating a PMO File",
    "section": "",
    "text": "In this tutorial we will go through the steps to build a PMO, utilising the functions within the pmo-tools package.\nFor more information on any of the fields mentioned please see the documentation."
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html#setup",
    "href": "pmotools-python-usages-notebooks/build_pmo.html#setup",
    "title": "Creating a PMO File",
    "section": "Setup",
    "text": "Setup\nFirst we will import the functions that we will need to run this notebook.\n\n\nCode\nfrom pmotools.json_convertors.microhaplotype_table_to_pmo_dict import microhaplotype_table_to_pmo_dict\nfrom pmotools.json_convertors.metatable_to_json_meta import experiment_info_table_to_json, specimen_info_table_to_json\nfrom pmotools.json_convertors.panel_information_to_pmo_dict import panel_info_table_to_pmo_dict\nfrom pmotools.json_convertors.demultiplexed_targets_to_pmo_dict import demultiplexed_targets_to_pmo_dict\n\n\n\n\nCode\nimport pandas as pd\nimport json \n\n\nHere we define a function that will be used to print a few lines from the data we will be creating.\n\n\nCode\ndef print_json_head(dict, n=10):\n    json_object = json.dumps(dict, indent=4)\n    for i, l in enumerate(json_object.split('\\n')):\n        if i &gt;= n:\n            break\n        print(l)"
  },
  {
    "objectID": "pmotools-python-usages-notebooks/build_pmo.html#creating-pmo",
    "href": "pmotools-python-usages-notebooks/build_pmo.html#creating-pmo",
    "title": "Creating a PMO File",
    "section": "Creating PMO",
    "text": "Creating PMO\nTo create the full PMO we will need a few sets of information. These include:\n\nPanel Information : A table including data on the targets that make up the panel.\nAllele table : A table containing the alleles called for each of the samples for each of the targets and the reads associated.\nDemultiplexed reads : A table containing the raw reads for each sample, for each target after demultiplexing, before any filtering.\nExperimental metadata : Information on the sequencing run, for example where each sample was located on the plate.\nSpecimen Information : metadata on the biological samples\n\nWe will specify the paths to the example data we will use below, but if you would like to try and use your own data then replace the following paths:\n\n\nCode\npanel_information_path = 'example_data/mad4hatter_panel_info_example.tsv'\nallele_table_path = 'example_data/mad4hatter_allele_data_example.txt'\ndemultiplexed_reads_path = 'example_data/mad4hatter_amplicon_coverage.txt'\n\n\n\nPanel Information\nFirst we will work on putting the panel information into PMO format. Although labs may store this information in a variety of ways and this process may seem cumbersome, you will only have to do this once for each panel that you work with.\nThe panel information consists of 2 parts; The panel_targets (information on the targets) and the target_genome (information on the reference genome being targeted).\nTo include details of the reference genome we need the following information.\n\nname : name of the genome\nversion : the genome version\ntaxon_id : the NCBI taxonomy number\nurl : a link to the where this genome file could be downloaded\n\nOptionally, you can also include a link to genomes annotation file, as we have below. Below is an example of compiling this information into the json format manually:\n\n\nCode\ntarget_genome_info = {\n            \"gff_url\" : \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n            \"name\" : \"3D7\",\n            \"taxon_id\" : 5833,\n            \"url\" : \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n            \"version\" : \"2020-09-01\"\n        }\n\n\nFields that are required to define the target information are …\n\ntarget_id : a unique identifier for each of the targets\nforward primer seq : The sequence for the forward primer associated with this target\nreverse primer sequence : The sequence for the reverse primer associated with this target\n\nNote: in the case that you have multiple primers to target the same region, please include these on separate lines in the table with the same target_id.\nOptionally you can also include location information for the primers. To include this information you will need to include in the table:\n\nchrom : the chromosome name\nstart : the start of the location, 0-based positioning\nend : the end of the location, 0-based positioning\n\nFor more information on optional fields that can be included, check the documentation.\nHere we show how to take panel information that is used to run the MAD4HatTeR pipeline and convert it to PMO.\n\n\nCode\nmadhatter_panel_info = pd.read_csv(panel_information_path, sep='\\t')\nmadhatter_panel_info.head()\n\n\n\n\n\n\n\n\n\namplicon\namplicon_start\namplicon_end\nampInsert_start\nampInsert_end\nrev_primer\namplicon_length\nampInsert_length\nfwd_primer\ntarget_type\nstrand\ngene_id\n\n\n\n\n0\nPf3D7_01_v3-145388-145662-1A\n145388\n145662\n145421\n145630\nAAAATGTCCAATATGTCAAGGTATATTAAAGT\n274\n209\nCCTGAGTTTTAAGTGAATGAATATATTTTTGTT\ndiversity\n+\nPF3D7_0103300\n\n\n1\nPf3D7_01_v3-162867-163115-1A\n162867\n163115\n162889\n163092\nTGTGTGCTTTGTCGTTGATTCAT\n248\n203\nTACTACCGATCATCAAGCCGAA\ndiversity\n+\nPF3D7_0103600\n\n\n2\nPf3D7_01_v3-181512-181761-1A\n181512\n181761\n181545\n181729\nTAGTTTAAATCTATACTTGTCTCACCTGAACA\n249\n184\nCTTTTCATATTTGTCTATTAGCTTTTTCAAACC\ndiversity\n+\nPF3D7_0104100\n\n\n3\nPf3D7_01_v3-455794-456054-1A\n455794\n456054\n455827\n456021\nGTGTTTCATTATTTTAGACACATTCAGGAATTT\n260\n194\nACAATGTAGAACAATATATAAAACTGGAAAAGA\ndiversity\n+\nNaN\n\n\n4\nPf3D7_01_v3-528859-529104-1A\n528859\n529104\n528890\n529073\nAATCATTTTATCCCACTTATTTATCTCGTCT\n245\n183\nCTTAGTTTAGATTTGCCTACAATATTTGCAC\ndiversity\n+\nPF3D7_0113800\n\n\n\n\n\n\n\nWe can use the panel_info_table_to_pmo_dict function to convert this into the correct format for PMO.\n\n\nCode\nprint(panel_info_table_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe containing panel information into dictionary of targets and reference information\n\n\n    :param target_table: The dataframe containing the target information\n    :param panel_id: the panel ID assigned to the panel\n    :param genome_info: A dictionary containing the genome information\n    :param target_id_col: the name of the column containing the target IDs\n    :param forward_primers_seq_col: the name of the column containing the sequence of the forward primer\n    :param reverse_primers_seq_col: the name of the column containing the sequence of the reverse primer\n    :param forward_primers_start_col (Optional): the name of the column containing the 0-based start coordinate of the forward primer\n    :param forward_primers_end_col (Optional): the name of the column containing the 0-based end coordinate of the forward primer\n    :param reverse_primers_start_col (Optional): the name of the column containing the 0-based start coordinate of the reverse primer\n    :param reverse_primers_end_col (Optional): the name of the column containing the 0-based end coordinate of the reverse primer\n    :param insert_start_col (Optional): the name of the column containing the 0-based start coordinate of the insert\n    :param insert_end_col (Optional): the name of the column containing the 0-based end coordinate of the insert\n    :param chrom_col (Optional): the name of the column containing the chromosome for the target\n    :param gene_id_col (Optional): the name of the column containing the gene id\n    :param strand_col (Optional): the name of the column containing the strand for the target\n    :param target_type_col (Optional): A classification type for the target\n    :param additional_target_info_cols (Optional): dictionary of optional additional columns to add to the target information dictionary. Keys are column names and values are the type.\n    :return: a dict of the panel information\n    \n\n\nWe will use this first just to include the most basic required information.\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info,\n    \"mad4hatter_poolsD1R1R2\",\n    target_genome_info,\n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n)\n\n\nLet’s take a look at the first 30 rows of the information we put together…\n\n\nCode\nprint_json_head(panel_information_pmo,30)\n\n\n{\n    \"panel_info\": {\n        \"mad4hatter_poolsD1R1R2\": {\n            \"panel_id\": \"mad4hatter_poolsD1R1R2\",\n            \"target_genome\": {\n                \"gff_url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n                \"name\": \"3D7\",\n                \"taxon_id\": 5833,\n                \"url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n                \"version\": \"2020-09-01\"\n            },\n            \"targets\": {\n                \"Pf3D7_01_v3-145388-145662-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"CCTGAGTTTTAAGTGAATGAATATATTTTTGTT\"\n                        }\n                    ],\n                    \"reverse_primers\": [\n                        {\n                            \"seq\": \"AAAATGTCCAATATGTCAAGGTATATTAAAGT\"\n                        }\n                    ]\n                },\n                \"Pf3D7_01_v3-162867-163115-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-162867-163115-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"TACTACCGATCATCAAGCCGAA\"\n\n\nOptionally we can include some more information. You can see that some of the fields in the table above don’t directly match the optional fields. Therefore, we must first wrangle the data slightly to fit the requirements.\nNote: You may not have to apply all of the following steps to your panel information, this is just an example and is specific to the MAD4HatTeR panel information.\nThe chromosome for each target is stored within the locus name, so we extract that and put it in it’s own column below.\n\n\nCode\nmadhatter_panel_info['chrom'] = [chr[0] for chr in madhatter_panel_info.amplicon.str.split('-')]\n\n\nNext we need to generate 0-based coordinates of the location the primers are targetting. The panel information we have only includes the full target start and end (including the primer) and is 1-based, so we do the conversion as follows.\n\n\nCode\n# Create 0-based coordinate for start of forward primer\nmadhatter_panel_info['fwd_primer_start_0_based'] = madhatter_panel_info.amplicon_start-1\n# Calculate the length of the forward primer, add this to the primer start coordinate to get the end coordinate \nmadhatter_panel_info['fwd_primer_len'] = [len(p) for p in madhatter_panel_info.fwd_primer]\nmadhatter_panel_info['fwd_primer_end_0_based'] = madhatter_panel_info.fwd_primer_start_0_based+madhatter_panel_info.fwd_primer_len\n\n# Calculate the length of the reverse primer. Subtract this from the end coordinate of the target to get the start coordinate of the reverse primer\nmadhatter_panel_info['rev_primer_len'] = [len(p) for p in madhatter_panel_info.rev_primer]\nmadhatter_panel_info['rev_primer_start_0_based'] = madhatter_panel_info.amplicon_end-madhatter_panel_info.rev_primer_len\n# The 0-based reverse primer end would be the same as the amplicon end \nmadhatter_panel_info['rev_primer_end_0_based'] = madhatter_panel_info.amplicon_end\n\n\nIn the MAD4HatTeR pipeline, we trim one base from each end of the amplicon insert because the base following a primer is often erroneous. We can create insert coordinates with this adjustment, as shown below. If you choose not to apply this trimming step, you can instead use the coordinate at the end of the forward primer and the beginning of the reverse primer to define the start and end of the insert.\n\n\nCode\nmadhatter_panel_info['insert_start_0_based'] = madhatter_panel_info.fwd_primer_end_0_based+1\nmadhatter_panel_info['insert_end_0_based'] = madhatter_panel_info.rev_primer_start_0_based-1\n\n\nNow we can create panel information to go into PMO with all of the optional fields we just created.\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info, \n    \"mad4hatter_poolsD1R1R2\", \n    target_genome_info, \n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n    forward_primers_start_col=\"fwd_primer_start_0_based\",\n    forward_primers_end_col=\"fwd_primer_end_0_based\",\n    reverse_primers_start_col=\"rev_primer_start_0_based\",\n    reverse_primers_end_col=\"rev_primer_end_0_based\",\n    insert_start_col=\"insert_start_0_based\",\n    insert_end_col=\"insert_end_0_based\",\n    chrom_col=\"chrom\",\n    strand_col=\"strand\",\n    gene_id_col=\"gene_id\",\n    target_type_col=\"target_type\",\n)\n\n\nYou can also add on your own custom fields using the additional_target_info_cols parameter. Below we add on the amplicon insert length information. If there is a field that you want to add and think others would find useful please contact us and we can add it in. This way we can make sure to keep ontologies consistent!\n\n\nCode\npanel_information_pmo = panel_info_table_to_pmo_dict(\n    madhatter_panel_info,\n    \"mad4hatter_poolsD1R1R2\",\n    target_genome_info,\n    target_id_col=\"amplicon\",\n    forward_primers_seq_col=\"fwd_primer\",\n    reverse_primers_seq_col=\"rev_primer\",\n    forward_primers_start_col=\"fwd_primer_start_0_based\",\n    forward_primers_end_col=\"fwd_primer_end_0_based\",\n    reverse_primers_start_col=\"rev_primer_start_0_based\",\n    reverse_primers_end_col=\"rev_primer_end_0_based\",\n    insert_start_col=\"insert_start_0_based\",\n    insert_end_col=\"insert_end_0_based\",\n    chrom_col=\"chrom\",\n    strand_col=\"strand\",\n    gene_id_col=\"gene_id\",\n    target_type_col=\"target_type\",\n    additional_target_info_cols=[\"ampInsert_length\"]\n)\n\n\nLet’s have a look at this now with the extra information added to the panel information\n\n\nCode\nprint_json_head(panel_information_pmo,46)\n\n\n{\n    \"panel_info\": {\n        \"mad4hatter_poolsD1R1R2\": {\n            \"panel_id\": \"mad4hatter_poolsD1R1R2\",\n            \"target_genome\": {\n                \"gff_url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/gff/data/PlasmoDB-65_Pfalciparum3D7.gff\",\n                \"name\": \"3D7\",\n                \"taxon_id\": 5833,\n                \"url\": \"https://plasmodb.org/common/downloads/release-65/Pfalciparum3D7/fasta/data/PlasmoDB-65_Pfalciparum3D7_Genome.fasta\",\n                \"version\": \"2020-09-01\"\n            },\n            \"targets\": {\n                \"Pf3D7_01_v3-145388-145662-1A\": {\n                    \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\",\n                    \"forward_primers\": [\n                        {\n                            \"seq\": \"CCTGAGTTTTAAGTGAATGAATATATTTTTGTT\",\n                            \"location\": {\n                                \"chrom\": \"Pf3D7_01_v3\",\n                                \"end\": 145420,\n                                \"start\": 145387,\n                                \"strand\": \"+\"\n                            }\n                        }\n                    ],\n                    \"reverse_primers\": [\n                        {\n                            \"seq\": \"AAAATGTCCAATATGTCAAGGTATATTAAAGT\",\n                            \"location\": {\n                                \"chrom\": \"Pf3D7_01_v3\",\n                                \"end\": 145662,\n                                \"start\": 145630,\n                                \"strand\": \"+\"\n                            }\n                        }\n                    ],\n                    \"gene_id\": \"PF3D7_0103300\",\n                    \"target_type\": \"diversity\",\n                    \"ampInsert_length\": 209,\n                    \"insert_location\": {\n                        \"chrom\": \"Pf3D7_01_v3\",\n                        \"start\": 145421,\n                        \"end\": 145629,\n                        \"strand\": \"+\"\n                    }\n                },\n\n\n\n\nMetadata\nThis section will compile metadata on two levels:\n\nSpecimen Level: Information about specimen that was collected.\nExperiment Level: Information about the sequencing or amplification runs performed on a specimen.\n\nIt’s important to note that a single specimen may be linked to multiple experiments.\nIn our example this is stored in one table, but may be stored in multiple places for you.\n\n\nCode\nmetadata = pd.read_excel('example_data/mad4hatter_metadata_example.xlsx')\nmetadata.head()\n\n\n\n\n\n\n\n\n\nspecimen_id\ncollection_date\ncollection_country\nsamp_collect_device\nlat_lon\ncollector\ngeo_admin3\nhost_taxon_id\nproject_name\nsamp_store_loc\nsamp_taxon_id\nexperiment_sample_id\npanel_id\nplate_name\nplate_row\nplate_col\nsequencing_info_id\n\n\n\n\n0\nSAMN38241219\n2019-01\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819135\nMad4hatter\nplate1\nA\n1\nrun1\n\n\n1\nSAMN38241215\n2017-02\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819139\nMad4hatter\nplate1\nA\n2\nrun1\n\n\n2\nSAMN38241214\n2016-05\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819141\nMad4hatter\nplate1\nA\n3\nrun1\n\n\n3\nSAMN38241052\n2015-05\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819151\nMad4hatter\nplate1\nA\n4\nrun1\n\n\n4\nSAMN38241112\n2019-06\nMozambique\ndried blood spot\n25.58,32.35\nBrokhattingen, Nanna\nMaputo\n1758\nPRJNA1040019\nUCSF Greenhouse Lab\n5833\nSRR26819200\nMad4hatter\nplate1\nA\n5\nrun1\n\n\n\n\n\n\n\n\nSpecimen Level Metadata\nNow we put together the specimen level metadata. This is the metadata associated with the sample collected from the host. For more information on this section see the documentation.\n\n\nCode\nprint(specimen_info_table_to_json.__doc__)\n\n\n\n    Converts a DataFrame containing specimen information into JSON.\n\n    :param contents (pd.DataFrame): The input DataFrame containing experiment data.\n    :param specimen_id_col (str): The column name for specimen sample IDs. Default: specimen_id\n    :param samp_taxon_id (int): NCBI taxonomy number of the organism. Default: samp_taxon_id\n    :param collection_date (string): Date of the sample collection. Default: collection_date\n    :param collection_country (string): Name of country collected in (admin level 0). Default : collection_country\n    :param collector (string): Name of the primary person managing the specimen. Default: collector\n    :param samp_store_loc (string): Sample storage site. Default: samp_store_loc\n    :param samp_collect_device (string): The way the sample was collected. Default : samp_collect_device\n    :param project_name (string): Name of the project. Default : project_name\n    :param alternate_identifiers (Optional[str]): List of optional alternative names for the samples\n    :param geo_admin1 (Optional[str]): Geographical admin level 1\n    :param geo_admin2 (Optional[str]): Geographical admin level 2\n    :param geo_admin3 (Optional[str]): Geographical admin level 3\n    :param host_taxon_id (Optional[int]): NCBI taxonomy number of the host\n    :param individual_id (Optional[str]): ID for the individual a specimen was collected from\n    :param lat_lon (Optional[str]): Latitude and longitude of the collection site\n    :param parasite_density (Optional[float]): The parasite density\n    :param plate_col (Optional[int]): Column the specimen was in in the plate\n    :param plate_name (Optional[str]): Name of plate the specimen was in\n    :param plate_row (Optional[str]): Row the specimen was in in the plate\n    :param sample_comments (Optional[str]): Additional comments about the sample\n    :param additional_specimen_cols (Optional[List[str], None]]): Additional column names to include\n\n    :return: JSON format where keys are `specimen_id` and values are corresponding row data.\n    \n\n\n\n\nCode\nspecimen_info_json = specimen_info_table_to_json(metadata, geo_admin3='geo_admin3',host_taxon_id='host_taxon_id', lat_lon='lat_lon')\nprint_json_head(specimen_info_json, 20)\n\n\n{\n    \"SAMN38241219\": {\n        \"specimen_id\": \"SAMN38241219\",\n        \"samp_taxon_id\": 5833,\n        \"collection_date\": \"2019-01\",\n        \"collection_country\": \"Mozambique\",\n        \"collector\": \"Brokhattingen, Nanna\",\n        \"samp_store_loc\": \"UCSF Greenhouse Lab\",\n        \"samp_collect_device\": \"dried blood spot\",\n        \"project_name\": \"PRJNA1040019\",\n        \"geo_admin3\": \"Maputo\",\n        \"host_taxon_id\": 1758,\n        \"lat_lon\": \"25.58,32.35\"\n    },\n    \"SAMN38241215\": {\n        \"specimen_id\": \"SAMN38241215\",\n        \"samp_taxon_id\": 5833,\n        \"collection_date\": \"2017-02\",\n        \"collection_country\": \"Mozambique\",\n        \"collector\": \"Brokhattingen, Nanna\",\n\n\n\n\nExperiment Level Metadata\nThis section shows how to put together the experiment level metadata. More information on this table can be found [here](pd.read_excel(‘example_data/mad4hatter_experiment_info_table_example.xlsx’).\n\n\nCode\nprint(experiment_info_table_to_json.__doc__)\n\n\n\n    Converts a DataFrame containing experiment information into JSON.\n\n    :param contents (pd.DataFrame): Input DataFrame containing experiment data.\n    :param experiment_sample_id_col (str): Column name for experiment sample IDs. Default: experiment_sample_id\n    :param sequencing_info_id (str): Column name for sequencing information IDs. Default: sequencing_info_id\n    :param specimen_id (str): Column name for specimen IDs. Default: specimen_id\n    :param panel_id (str): Column name for panel IDs. Default: panel_id\n    :param accession (Optional[str]): Column name for accession information.\n    :param plate_col (Optional[int]): Column index for plate information.\n    :param plate_name (Optional[str]): Column name for plate names.\n    :param plate_row (Optional[str]): Column name for plate rows.\n    :param additional_experiment_cols (Optional[List[str], None]]): Additional column names to include.\n\n    :return: JSON format where keys are `experiment_sample_id` and values are corresponding row data.\n    \n\n\n\n\nCode\nexperiment_info_json = experiment_info_table_to_json(metadata, plate_name='plate_name', plate_col='plate_col',plate_row='plate_row', additional_experiment_cols=['collection_date','collection_country'])\nprint_json_head(experiment_info_json, 20)\n\n\n{\n    \"SRR26819135\": {\n        \"experiment_sample_id\": \"SRR26819135\",\n        \"sequencing_info_id\": \"run1\",\n        \"specimen_id\": \"SAMN38241219\",\n        \"panel_id\": \"Mad4hatter\",\n        \"plate_col\": 1,\n        \"plate_name\": \"plate1\",\n        \"plate_row\": \"A\",\n        \"collection_date\": \"2019-01\",\n        \"collection_country\": \"Mozambique\"\n    },\n    \"SRR26819139\": {\n        \"experiment_sample_id\": \"SRR26819139\",\n        \"sequencing_info_id\": \"run1\",\n        \"specimen_id\": \"SAMN38241215\",\n        \"panel_id\": \"Mad4hatter\",\n        \"plate_col\": 2,\n        \"plate_name\": \"plate1\",\n        \"plate_row\": \"A\",\n\n\n\n\n\nMicrohaplotype Information\nNext, we’ll organize the microhaplotype information into the required format.\nThis involves two components that we will generate from one table(click on the links to find out more information about each part):\n\nThe representative microhaplotype details: A summary of all of unique microhaplotypes called within the population you have included in your PMO for each target. Each unique microhaplotype will be assigned a short ID within PMO to improve the scalability of the format.\nThe detected microhaplotypes: Microhaplotypes called for each sample for each target and the associated reads. This will be linked to the above table using the generated microhaplotype ID instead of the full microhaplotype sequence.\n\nFirst we will load an example allele table that may be similar to something you have from your own microhaplotype pipeline. This table includes a sampleID, the target, and the ASV and number of reads detected for each of these.\n\n\nCode\nexample_allele_table = pd.read_csv(allele_table_path, sep='\\t')\nexample_allele_table.head()\n\n\n\n\n\n\n\n\n\nSampleID\nLocus\nASV\nReads\nAllele\nPseudoCIGAR\n\n\n\n\n0\nSRR26819553\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n13\nPf3D7_01_v3-145388-145662-1A.1\n25+25N169+8N188+9N\n\n\n1\nSRR26819207\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n4\nPf3D7_01_v3-145388-145662-1A.2\n25+25N94A139T169+8N188+9N\n\n\n2\nSRR26819545\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n22\nPf3D7_01_v3-145388-145662-1A.1\n25+25N169+8N188+9N\n\n\n3\nSRR26819527\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n1\nPf3D7_01_v3-145388-145662-1A.2\n25+25N94A139T169+8N188+9N\n\n\n4\nSRR26819214\nPf3D7_01_v3-145388-145662-1A\nGATATGTTTAAATATATGATTCTCGAAAAAACTTTTTTTATTTTTT...\n14\nPf3D7_01_v3-145388-145662-1A.3\n25+25N139T169+8N188+9N\n\n\n\n\n\n\n\nLet’s have a look at the function we will use to create this part of PMO microhaplotype_table_to_pmo_dict\n\n\nCode\nprint(microhaplotype_table_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe of a microhaplotype calls into a dictionary containing a dictionary for the haplotypes_detected and a dictionary for the representative_haplotype_sequences.\n\n    :param contents: The dataframe containing microhaplotype calls\n    :param bioinfo_id: the bioinformatics ID of the microhaplotype table\n    :param sampleID_col: the name of the column containing the sample IDs\n    :param locus_col: the name of the column containing the locus IDs\n    :param mhap_col: the name of the column containing the microhaplotype sequence\n    :param reads_col: the name of the column containing the reads counts\n    :param additional_hap_detected_cols: optional additional columns to add to the microhaplotype detected dictionary, the key is the pandas column and the value is what to name it in the output\n    :return: a dict of both the haplotypes_detected and representative_haplotype_sequences\n    \n\n\nWe can see that we need a dataframe with columns for sample IDs, locus names, microhaplotype sequences, and their corresponding read counts. We also need to supply a unique bioinformatics ID. Including this ID allows us to store results from multiple bioinformatics pipelines run on the same sequencing data in a unified format if necessary.\nHere we set a bioinformatics ID, so we can use the same one when generating other tables later on.\n\n\nCode\nbioinfo_id = \"Mozambique2018-MAD4HatTeR\"\n\n\nThe function has default column names that align with the standard output from DADA2. However, since we’re using MAD4HatTeR data, which has slightly different column headers, we’ll need to specify these column names explicitly in the function.\n\n\nCode\nmicrohaplotype_info = microhaplotype_table_to_pmo_dict(\n    example_allele_table,\n    sampleID_col=\"SampleID\",\n    locus_col=\"Locus\",\n    mhap_col=\"ASV\",\n    reads_col=\"Reads\",\n    bioinfo_id=bioinfo_id,\n)\n\n\n\n\nDemultiplexed Experiment Samples\nWe also include information on the demultiplexed reads for each Sample for each target using a function called demultiplexed_targets_to_pmo_dict.\n\n\nCode\nprint(demultiplexed_targets_to_pmo_dict.__doc__)\n\n\n\n    Convert a dataframe of microhaplotype calls into a dictionary for detected haplotypes \n    and representative haplotype sequences.\n\n    :param contents: DataFrame containing demultiplexed sample information\n    :param bioinfo_id: Bioinformatics ID of the demultiplexed targets\n    :param sampleID_col: Name of the column containing sample IDs\n    :param target_id_col: Name of the column containing locus IDs\n    :param read_count_col: Name of the column containing read counts\n    :param additional_hap_detected_cols: Optional columns to include in the output,\n                                         with keys as column names and values as their output names\n    :return: JSON string containing the processed data\n    \n\n\n\n\nCode\namplicon_coverage = pd.read_csv(demultiplexed_reads_path, sep='\\t')\namplicon_coverage.head()\n\n\n\n\n\n\n\n\n\nSampleID\nLocus\nReads\nOutputDada2\nOutputPostprocessing\n\n\n\n\n0\nSRR26819135\nPf3D7_01_v3-145388-145662-1A\n54\n54\n54\n\n\n1\nSRR26819135\nPf3D7_01_v3-162867-163115-1A\n400\n398\n398\n\n\n2\nSRR26819135\nPf3D7_01_v3-181512-181761-1A\n266\n266\n266\n\n\n3\nSRR26819135\nPf3D7_01_v3-455794-456054-1A\n81\n80\n80\n\n\n4\nSRR26819135\nPf3D7_01_v3-528859-529104-1A\n485\n485\n485\n\n\n\n\n\n\n\nNote that we use the same bioinfo_id that we set above.\n\n\nCode\ndemultiplexed_targets_pmo = demultiplexed_targets_to_pmo_dict(amplicon_coverage, bioinfo_id,  sampleID_col = 'SampleID', target_id_col='Locus',read_count_col ='Reads')\n\n\n\n\nCode\nprint_json_head(demultiplexed_targets_pmo, 15)\n\n\n{\n    \"target_demultiplexed_experiment_samples\": {\n        \"Mozambique2018-MAD4HatTeR\": {\n            \"demultiplexed_experiment_samples\": {\n                \"SRR26819135\": {\n                    \"demultiplexed_targets\": {\n                        \"experiment_sample_id\": \"SRR26819135\",\n                        \"Pf3D7_01_v3-145388-145662-1A\": {\n                            \"raw_read_count\": 54,\n                            \"target_id\": \"Pf3D7_01_v3-145388-145662-1A\"\n                        },\n                        \"Pf3D7_01_v3-162867-163115-1A\": {\n                            \"raw_read_count\": 400,\n                            \"target_id\": \"Pf3D7_01_v3-162867-163115-1A\"\n                        },\n\n\n\n\nSequencing info\nPMO includes details of the sequencing run. Below is an example and more information on the required fields can be found here\n\n\nCode\nsequencing_infos ={\n        \"Mozambique2018\" : \n        {\n            \"lib_kit\" : \"TruSeq i5/i7 barcode primers\",\n            \"lib_layout\" : \"paired-end\",\n            \"lib_screen\" : \"40 µL reaction containing 10 µL of bead purified digested product, 18μL of nuclease-free water, 8μL of 5X secondary PCR master mix, and 5 µL of 10 µM TruSeq i5/i7 barcode primers\",\n            \"nucl_acid_amp\" : \"https://www.paragongenomics.com/targeted-sequencing/amplicon-sequencing/cleanplex-ngs-amplicon-sequencing/\",\n            \"nucl_acid_date\" : \"2019-07-15\",\n            \"nucl_acid_ext\" : \"https://www.paragongenomics.com/targeted-sequencing/amplicon-sequencing/cleanplex-ngs-amplicon-sequencing/\",\n            \"pcr_cond\" : \"10 min at 95°C, 13 cycles for high density samples (or 15 cycles for low density samples) of 15 sec at 98°C and 75 sec at 60°C\",\n            \"seq_center\" : \"UCSF\",\n            \"seq_date\" : \"2019-07-15\",\n            \"seq_instrument\" : \"NextSeq 550 instrument\",\n            \"sequencing_info_id\" : \"run1\"\n        }\n    }\n\n\n\n\nBioinformatics Info\nNow we manually enter some information on the bioinformatics run. More information on the fields can be found here. Below is an example from the MAD4HatTeR pipeline.\n\n\nCode\ntaramp_bioinformatics_infos = {\n    bioinfo_id : \n    {\n        \"demultiplexing_method\" : \n        {\n            \"program\" : \"Cutadapt extractorPairedEnd\",\n            \"purpose\" : \"Takes raw paired-end reads and demultiplexes on primers and does QC filtering\",\n            \"version\" : \"v4.4\"\n        },\n        \"denoising_method\" : \n        {\n            \"program\" : \"DADA2\",\n            \"purpose\" : \"Takes sequences per sample per target and clusters them\",\n            \"version\" : \"v3.16\"\n        },\n        \"tar_amp_bioinformatics_info_id\" : bioinfo_id\n    }\n}"
  }
]